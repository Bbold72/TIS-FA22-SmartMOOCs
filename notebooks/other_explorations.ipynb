{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Explorations\n",
    "Things I tried that didn't go anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "\n",
    "from src import utils\n",
    "from src.data.make_corpus import Corpus, Vocabulary\n",
    "\n",
    "ROOT_DIR = utils.get_project_root()\n",
    "DATA_DIR = Path.joinpath(ROOT_DIR, 'data')\n",
    "INTERMEDATE_DATA_DIR = Path.joinpath(DATA_DIR, 'intermediate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(Path.joinpath(INTERMEDATE_DATA_DIR, 'corpuses.pkl'), 'rb') as f:\n",
    "        corpuses = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print('File Not Found: Run entire project to produce required intermediate data file. Run \"make run\" from the terminal')\n",
    "\n",
    "corpus_times_4_1 = corpuses['04_week-4/02_week-4-lessons/01_lesson-4-1-probabilistic-retrieval-model-basic-idea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Markov Switching Model\n",
    "Doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "mod = sm.tsa.MarkovAutoregression(\n",
    "    np.diff(corpus_times_4_1[30].ts_cos_similarity), k_regimes=2, order=3, switching_ar=False\n",
    ")\n",
    "res = mod.fit()\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 2\n",
    "time_index = 60\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_texts = [doc.tokens for doc in corpus_times_4_1[time_index].documents]\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=num_topics)\n",
    "\n",
    "# topic probabilities for each document\n",
    "for t in range(len(corpus_times_4_1[time_index].documents)):\n",
    "    print(lda.get_document_topics(common_corpus[t]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tis-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85a5c2dc979ec021335ff2758cc7fbdc3d2baa50f6cf88c303f22e6e76e98821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
