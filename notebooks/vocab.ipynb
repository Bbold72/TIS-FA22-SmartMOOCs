{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bxjxrx7/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/bxjxrx7/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.text import TextCollection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "import re\n",
    "\n",
    "from typing import List\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "from src import utils\n",
    "from src.data import process_transcripts\n",
    "from src.data.make_corpus import Corpus, Vocabulary\n",
    "\n",
    "\n",
    "ROOT_DIR = utils.get_project_root()\n",
    "DATA_DIR = Path.joinpath(ROOT_DIR, 'data')\n",
    "DATA_RAW_DIR = Path.joinpath(DATA_DIR, 'raw/cs-410')\n",
    "INTERMEDATE_DATA_DIR = Path.joinpath(DATA_DIR, 'intermediate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.joinpath(INTERMEDATE_DATA_DIR, 'transcripts.pkl'), 'rb') as f:\n",
    "        transcripts = pickle.load(f)\n",
    "\n",
    "all_segments = [] \n",
    "for transcript_segments in transcripts.values():\n",
    "        all_segments.extend(transcript_segments)\n",
    "vocab = Vocabulary(all_segments, remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.joinpath(INTERMEDATE_DATA_DIR, 'transcripts.pkl'), 'rb') as f:\n",
    "        transcripts = pickle.load(f)\n",
    "\n",
    "all_text = [] \n",
    "\n",
    "for transcript_segments in transcripts.values():\n",
    "    for segment in transcript_segments:\n",
    "        all_text.append(segment.text)\n",
    "all_text = ' '.join(all_text).lower().split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and so how can we leverage the skewed distributions of values to compress these values well in general we will use few bits to encode those frequent words at the cost of using longer bit string code those rare values\n",
      "therefore we can use fewer bits for the small but highly frequent integers and thats cost of using more bits for larger integers\n",
      "we can save on average even though sometimes when we see a large number we have to use a lot of bits\n",
      "so now you can imagine how many bits do we have to use for a large number like 100 so how many bits do you have to use exactly for a number like 100 well exactly we have to use 100 bits\n",
      "so its the same number of bits as the value of this number\n",
      "imagine if you occasionally see a number like 1000 you have to use 1000 bits\n",
      "now how do you decode this code now since these are variable length encoding methods you cant just count how many bits and then just stop\n",
      "you cant say 8bits or 32bits then you will start another code\n",
      "and its easy to show that for this difference we only need to use up to this many bits and the floor of log of x bits\n",
      "but this time were going to use 2 bits because with this level of flow of log of x\n",
      "so in order to differentiate them we have to use 2 bits in the end to differentiate them\n",
      "its also true that the form of a gamma code is always the first odd number of bits and in the center there is a 0\n",
      "once you hit 0 you have got the unary code and this also tell you how many bits you have to read further to decode the uniform code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['sound', 'lecture', 'natural', 'language', 'content', 'analysis'],\n",
       " ['natural',\n",
       "  'language',\n",
       "  'content',\n",
       "  'analysis',\n",
       "  'foundation',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['going', 'first', 'talk'],\n",
       " ['particular',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'factor',\n",
       "  'present',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['determines', 'algorithms', 'used', 'analyze', 'mine', 'text', 'data'],\n",
       " ['going',\n",
       "  'take',\n",
       "  'look',\n",
       "  'basic',\n",
       "  'concepts',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'first'],\n",
       " ['im',\n",
       "  'going',\n",
       "  'explain',\n",
       "  'concepts',\n",
       "  'using',\n",
       "  'similar',\n",
       "  'example',\n",
       "  'youve',\n",
       "  'seen'],\n",
       " ['dog', 'chasing', 'boy', 'playground'],\n",
       " ['simple', 'sentence'],\n",
       " ['read', 'sentence', 'dont', 'think', 'get', 'meaning'],\n",
       " ['computer', 'understand', 'sentence', 'computer', 'go', 'several', 'steps'],\n",
       " ['first',\n",
       "  'computer',\n",
       "  'needs',\n",
       "  'know',\n",
       "  'words',\n",
       "  'segment',\n",
       "  'words',\n",
       "  'english'],\n",
       " ['easy', 'look', 'space'],\n",
       " ['computer',\n",
       "  'need',\n",
       "  'know',\n",
       "  'categories',\n",
       "  'words',\n",
       "  'syntactical',\n",
       "  'categories'],\n",
       " ['example',\n",
       "  'dog',\n",
       "  'noun',\n",
       "  'chasings',\n",
       "  'verb',\n",
       "  'boy',\n",
       "  'another',\n",
       "  'noun',\n",
       "  'etc'],\n",
       " ['called', 'lexical', 'analysis'],\n",
       " ['particular',\n",
       "  'tagging',\n",
       "  'words',\n",
       "  'syntactic',\n",
       "  'categories',\n",
       "  'called',\n",
       "  'partofspeech',\n",
       "  'tagging'],\n",
       " ['computer', 'also', 'needs', 'figure', 'relationship', 'words'],\n",
       " ['dog', 'would', 'form', 'noun', 'phrase'],\n",
       " ['playground', 'would', 'prepositional', 'phrase', 'etc'],\n",
       " ['certain', 'way', 'connected', 'together', 'order', 'create', 'meaning'],\n",
       " ['combinations', 'may', 'make', 'sense'],\n",
       " ['called',\n",
       "  'syntactical',\n",
       "  'parsing',\n",
       "  'syntactical',\n",
       "  'analysis',\n",
       "  'parsing',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'sentence'],\n",
       " ['outcome', 'parse', 'tree', 'seeing'],\n",
       " ['tells', 'us', 'structure', 'sentence', 'know', 'interpret', 'sentence'],\n",
       " ['semantics', 'yet'],\n",
       " ['order',\n",
       "  'get',\n",
       "  'meaning',\n",
       "  'would',\n",
       "  'map',\n",
       "  'phrases',\n",
       "  'structures',\n",
       "  'real',\n",
       "  'world',\n",
       "  'antithesis',\n",
       "  'mind'],\n",
       " ['dog', 'concept', 'know', 'boy', 'concept', 'know'],\n",
       " ['connecting', 'phrases', 'know', 'understanding'],\n",
       " ['computer',\n",
       "  'would',\n",
       "  'formally',\n",
       "  'represent',\n",
       "  'entities',\n",
       "  'using',\n",
       "  'symbols'],\n",
       " ['dog', 'd1', 'means', 'd1', 'dog'],\n",
       " ['boy', 'b1', 'means', 'b1', 'refers', 'boy', 'etc'],\n",
       " ['also', 'represents', 'chasing', 'action', 'predicate'],\n",
       " ['chasing', 'predicate', 'three', 'arguments', 'd1', 'b1', 'p1'],\n",
       " ['playground'],\n",
       " ['formal', 'rendition', 'semantics', 'sentence'],\n",
       " ['reach', 'level', 'understanding', 'might', 'also', 'make', 'inferences'],\n",
       " ['example',\n",
       "  'assume',\n",
       "  'theres',\n",
       "  'rule',\n",
       "  'says',\n",
       "  'someones',\n",
       "  'chased',\n",
       "  'person',\n",
       "  'get',\n",
       "  'scared',\n",
       "  'infer',\n",
       "  'boy',\n",
       "  'might',\n",
       "  'scared'],\n",
       " ['inferred', 'meaning', 'based', 'additional', 'knowledge'],\n",
       " ['finally',\n",
       "  'might',\n",
       "  'even',\n",
       "  'infer',\n",
       "  'sentence',\n",
       "  'requesting',\n",
       "  'person',\n",
       "  'say',\n",
       "  'sentence',\n",
       "  'saying',\n",
       "  'sentence'],\n",
       " ['purpose', 'saying', 'sentence'],\n",
       " ['called', 'speech', 'act', 'analysis', 'pragmatic', 'analysis'],\n",
       " ['first', 'use', 'language'],\n",
       " ['case',\n",
       "  'person',\n",
       "  'saying',\n",
       "  'may',\n",
       "  'reminding',\n",
       "  'another',\n",
       "  'person',\n",
       "  'bring',\n",
       "  'back',\n",
       "  'dog'],\n",
       " ['means', 'saying', 'sentence', 'person', 'actually', 'takes', 'action'],\n",
       " ['action', 'make', 'request'],\n",
       " ['slide',\n",
       "  'clearly',\n",
       "  'shows',\n",
       "  'order',\n",
       "  'really',\n",
       "  'understand',\n",
       "  'sentence',\n",
       "  'lot',\n",
       "  'things',\n",
       "  'computer'],\n",
       " ['general',\n",
       "  'hard',\n",
       "  'computer',\n",
       "  'everything',\n",
       "  'especially',\n",
       "  'would',\n",
       "  'want',\n",
       "  'everything',\n",
       "  'correctly'],\n",
       " ['difficult'],\n",
       " ['main',\n",
       "  'reason',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'difficult',\n",
       "  'designed',\n",
       "  'make',\n",
       "  'human',\n",
       "  'communications',\n",
       "  'efficient'],\n",
       " ['result', 'example', 'lot', 'common', 'sense', 'knowledge'],\n",
       " ['assume', 'us', 'knowledge', 'theres', 'need', 'encode', 'knowledge'],\n",
       " ['makes', 'communication', 'efficient'],\n",
       " ['also', 'keep', 'lot', 'ambiguities', 'like', 'ambiguities', 'words'],\n",
       " ['assume', 'ability', 'disambiguate', 'word'],\n",
       " ['theres',\n",
       "  'problem',\n",
       "  'word',\n",
       "  'mean',\n",
       "  'possibly',\n",
       "  'different',\n",
       "  'things',\n",
       "  'different',\n",
       "  'context'],\n",
       " ['yet',\n",
       "  'computer',\n",
       "  'would',\n",
       "  'difficult',\n",
       "  'computer',\n",
       "  'common',\n",
       "  'sense',\n",
       "  'knowledge'],\n",
       " ['computer', 'confused', 'indeed'],\n",
       " ['makes', 'hard', 'natural', 'language', 'processing'],\n",
       " ['indeed', 'makes', 'hard', 'every', 'step', 'slide', 'showed', 'earlier'],\n",
       " ['ambiguity', 'main', 'killer'],\n",
       " ['meaning',\n",
       "  'every',\n",
       "  'step',\n",
       "  'multiple',\n",
       "  'choices',\n",
       "  'computer',\n",
       "  'would',\n",
       "  'decide',\n",
       "  'whats',\n",
       "  'right',\n",
       "  'choice',\n",
       "  'decision',\n",
       "  'difficult',\n",
       "  'see',\n",
       "  'also',\n",
       "  'moment'],\n",
       " ['general',\n",
       "  'need',\n",
       "  'common',\n",
       "  'sense',\n",
       "  'reasoning',\n",
       "  'order',\n",
       "  'fully',\n",
       "  'understand',\n",
       "  'natural',\n",
       "  'language'],\n",
       " ['computers', 'today', 'dont', 'yet'],\n",
       " ['thats',\n",
       "  'hard',\n",
       "  'computers',\n",
       "  'precisely',\n",
       "  'understand',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'point'],\n",
       " ['specific', 'examples', 'challenges'],\n",
       " ['think', 'worldlevel', 'ambiguity'],\n",
       " ['word',\n",
       "  'like',\n",
       "  'design',\n",
       "  'noun',\n",
       "  'verb',\n",
       "  'weve',\n",
       "  'got',\n",
       "  'ambiguous',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tag'],\n",
       " ['root',\n",
       "  'also',\n",
       "  'multiple',\n",
       "  'meanings',\n",
       "  'mathematical',\n",
       "  'sense',\n",
       "  'like',\n",
       "  'square',\n",
       "  'root',\n",
       "  'plant'],\n",
       " ['syntactic',\n",
       "  'ambiguity',\n",
       "  'refers',\n",
       "  'different',\n",
       "  'interpretations',\n",
       "  'sentence',\n",
       "  'terms',\n",
       "  'structures'],\n",
       " ['example',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'actually',\n",
       "  'interpreted',\n",
       "  'two',\n",
       "  'ways'],\n",
       " ['one', 'ordinary', 'meaning', 'getting', 'talking', 'topic'],\n",
       " ['processing', 'natural', 'language'],\n",
       " ['theres',\n",
       "  'also',\n",
       "  'another',\n",
       "  'possible',\n",
       "  'interpretation',\n",
       "  'say',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'natural'],\n",
       " ['dont',\n",
       "  'generally',\n",
       "  'problem',\n",
       "  'imagine',\n",
       "  'computer',\n",
       "  'determine',\n",
       "  'structure',\n",
       "  'computer',\n",
       "  'would',\n",
       "  'make',\n",
       "  'choice',\n",
       "  'two'],\n",
       " ['another', 'classic', 'example', 'man', 'saw', 'boy', 'telescope'],\n",
       " ['ambiguity',\n",
       "  'lies',\n",
       "  'question',\n",
       "  'telescope',\n",
       "  'called',\n",
       "  'prepositional',\n",
       "  'phrase',\n",
       "  'attachment',\n",
       "  'ambiguity'],\n",
       " ['meaning', 'attach', 'prepositional', 'phrase', 'telescope'],\n",
       " ['modify', 'boy', 'modifying', 'saw', 'verb'],\n",
       " ['another', 'problem', 'anaphora', 'resolution'],\n",
       " ['john', 'persuaded', 'bill', 'buy', 'tv'],\n",
       " ['refer', 'john', 'bill', 'presupposition', 'another', 'difficulty'],\n",
       " ['quit',\n",
       "  'smoking',\n",
       "  'implies',\n",
       "  'smoked',\n",
       "  'need',\n",
       "  'knowledge',\n",
       "  'order',\n",
       "  'understand',\n",
       "  'languages'],\n",
       " ['problems',\n",
       "  'state',\n",
       "  'art',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'anything',\n",
       "  'perfectly'],\n",
       " ['even',\n",
       "  'simplest',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tagging',\n",
       "  'still',\n",
       "  'solve',\n",
       "  'whole',\n",
       "  'problem'],\n",
       " ['accuracy', 'listed', 'NUMBER', 'taken', 'studies', 'earlier'],\n",
       " ['studies',\n",
       "  'obviously',\n",
       "  'using',\n",
       "  'particular',\n",
       "  'data',\n",
       "  'sets',\n",
       "  'numbers',\n",
       "  'really',\n",
       "  'meaningful',\n",
       "  'take',\n",
       "  'context',\n",
       "  'data',\n",
       "  'set',\n",
       "  'used',\n",
       "  'evaluation'],\n",
       " ['show',\n",
       "  'numbers',\n",
       "  'mainly',\n",
       "  'give',\n",
       "  'sense',\n",
       "  'accuracy',\n",
       "  'well',\n",
       "  'things',\n",
       "  'like'],\n",
       " ['doesnt', 'mean', 'data', 'set', 'accuracy', 'would', 'precisely', 'NUMBER'],\n",
       " ['general',\n",
       "  'parsing',\n",
       "  'speech',\n",
       "  'tagging',\n",
       "  'fairly',\n",
       "  'well',\n",
       "  'although',\n",
       "  'perfect'],\n",
       " ['parsing',\n",
       "  'would',\n",
       "  'difficult',\n",
       "  'partial',\n",
       "  'parsing',\n",
       "  'meaning',\n",
       "  'get',\n",
       "  'phrases',\n",
       "  'correct',\n",
       "  'probably',\n",
       "  'achieve',\n",
       "  'NUMBER',\n",
       "  'better',\n",
       "  'accuracy'],\n",
       " ['get', 'complete', 'parse', 'tree', 'correctly', 'still', 'difficult'],\n",
       " ['semantic',\n",
       "  'analysis',\n",
       "  'also',\n",
       "  'aspects',\n",
       "  'semantic',\n",
       "  'analysis',\n",
       "  'particularly',\n",
       "  'extraction',\n",
       "  'entities',\n",
       "  'relations'],\n",
       " ['example',\n",
       "  'recognizing',\n",
       "  'person',\n",
       "  'thats',\n",
       "  'location',\n",
       "  'person',\n",
       "  'person',\n",
       "  'met',\n",
       "  'place',\n",
       "  'etc'],\n",
       " ['also', 'word', 'sense', 'extent'],\n",
       " ['occurrence', 'root', 'sentence', 'refers', 'mathematical', 'sense', 'etc'],\n",
       " ['sentiment', 'analysis', 'another', 'aspect', 'semantic', 'analysis'],\n",
       " ['means',\n",
       "  'tag',\n",
       "  'senses',\n",
       "  'generally',\n",
       "  'positive',\n",
       "  'talking',\n",
       "  'product',\n",
       "  'talking',\n",
       "  'person'],\n",
       " ['inference',\n",
       "  'however',\n",
       "  'hard',\n",
       "  'generally',\n",
       "  'big',\n",
       "  'domain',\n",
       "  'feasible',\n",
       "  'limited',\n",
       "  'domain'],\n",
       " ['thats', 'generally', 'difficult', 'problem', 'artificial', 'intelligence'],\n",
       " ['speech',\n",
       "  'act',\n",
       "  'analysis',\n",
       "  'also',\n",
       "  'difficult',\n",
       "  'probably',\n",
       "  'specialized',\n",
       "  'cases'],\n",
       " ['lot', 'help', 'humans', 'annotate', 'enough', 'data', 'computers', 'learn'],\n",
       " ['slide',\n",
       "  'also',\n",
       "  'shows',\n",
       "  'computers',\n",
       "  'far',\n",
       "  'able',\n",
       "  'understand',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'precisely'],\n",
       " ['also', 'explains', 'text', 'mining', 'problem', 'difficult'],\n",
       " ['rely',\n",
       "  'mechanical',\n",
       "  'approaches',\n",
       "  'computational',\n",
       "  'methods',\n",
       "  'understand',\n",
       "  'language',\n",
       "  'precisely'],\n",
       " ['therefore', 'use', 'whatever', 'today'],\n",
       " ['particular',\n",
       "  'statistical',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'method',\n",
       "  'statistical',\n",
       "  'analysis',\n",
       "  'methods',\n",
       "  'try',\n",
       "  'get',\n",
       "  'much',\n",
       "  'meaning',\n",
       "  'text',\n",
       "  'possible'],\n",
       " ['later',\n",
       "  'see',\n",
       "  'actually',\n",
       "  'many',\n",
       "  'algorithms',\n",
       "  'indeed',\n",
       "  'extract',\n",
       "  'interesting',\n",
       "  'model',\n",
       "  'text',\n",
       "  'even',\n",
       "  'though',\n",
       "  'really',\n",
       "  'fully',\n",
       "  'understand'],\n",
       " ['meaning', 'natural', 'language', 'sentences', 'precisely'],\n",
       " ['lecture', 'textual', 'representation'],\n",
       " ['lecture',\n",
       "  'going',\n",
       "  'discuss',\n",
       "  'textual',\n",
       "  'representation',\n",
       "  'discuss',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'allow',\n",
       "  'us',\n",
       "  'represent',\n",
       "  'text',\n",
       "  'many',\n",
       "  'different',\n",
       "  'ways'],\n",
       " ['lets', 'take', 'look', 'example', 'sentence'],\n",
       " ['represent', 'sentence', 'many', 'different', 'ways'],\n",
       " ['first', 'always', 'represent', 'sentence', 'string', 'characters'],\n",
       " ['true', 'languages', 'store', 'computer'],\n",
       " ['store',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'sentence',\n",
       "  'string',\n",
       "  'characters',\n",
       "  'perhaps',\n",
       "  'general',\n",
       "  'way',\n",
       "  'representing',\n",
       "  'text',\n",
       "  'since',\n",
       "  'always',\n",
       "  'use',\n",
       "  'approach',\n",
       "  'represent',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['unfortunately',\n",
       "  'using',\n",
       "  'representation',\n",
       "  'help',\n",
       "  'us',\n",
       "  'semantic',\n",
       "  'analysis',\n",
       "  'often',\n",
       "  'needed',\n",
       "  'many',\n",
       "  'applications',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['reason', 'even', 'recognizing', 'words'],\n",
       " ['string', 'going', 'keep', 'spaces', 'ascii', 'symbols'],\n",
       " ['perhaps',\n",
       "  'count',\n",
       "  'whats',\n",
       "  'frequent',\n",
       "  'character',\n",
       "  'english',\n",
       "  'text',\n",
       "  'correlation',\n",
       "  'characters',\n",
       "  'cant',\n",
       "  'really',\n",
       "  'analyze',\n",
       "  'semantics'],\n",
       " ['yet',\n",
       "  'general',\n",
       "  'way',\n",
       "  'representing',\n",
       "  'text',\n",
       "  'use',\n",
       "  'represent',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'text'],\n",
       " ['try',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'word',\n",
       "  'segmentation',\n",
       "  'obtain',\n",
       "  'representation',\n",
       "  'text',\n",
       "  'form',\n",
       "  'sequence',\n",
       "  'words'],\n",
       " ['see', 'identify', 'words', 'like', 'dog', 'chasing', 'etc'],\n",
       " ['level',\n",
       "  'representation',\n",
       "  'certainly',\n",
       "  'lot',\n",
       "  'things',\n",
       "  'mainly',\n",
       "  'words',\n",
       "  'basic',\n",
       "  'units',\n",
       "  'human',\n",
       "  'communication',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'powerful'],\n",
       " ['identifying',\n",
       "  'words',\n",
       "  'example',\n",
       "  'easily',\n",
       "  'count',\n",
       "  'frequent',\n",
       "  'words',\n",
       "  'document',\n",
       "  'whole',\n",
       "  'collection',\n",
       "  'etc'],\n",
       " ['words',\n",
       "  'used',\n",
       "  'form',\n",
       "  'topics',\n",
       "  'combine',\n",
       "  'related',\n",
       "  'words',\n",
       "  'together',\n",
       "  'words',\n",
       "  'positive',\n",
       "  'words',\n",
       "  'negative',\n",
       "  'also',\n",
       "  'sentiment',\n",
       "  'analysis'],\n",
       " ['representing',\n",
       "  'text',\n",
       "  'data',\n",
       "  'sequence',\n",
       "  'words',\n",
       "  'opens',\n",
       "  'lot',\n",
       "  'interesting',\n",
       "  'analysis',\n",
       "  'possibilities'],\n",
       " ['however',\n",
       "  'level',\n",
       "  'representation',\n",
       "  'slightly',\n",
       "  'less',\n",
       "  'general',\n",
       "  'string',\n",
       "  'characters',\n",
       "  'languages',\n",
       "  'chinese',\n",
       "  'actually',\n",
       "  'easy',\n",
       "  'identify',\n",
       "  'word',\n",
       "  'boundaries',\n",
       "  'language',\n",
       "  'see',\n",
       "  'text',\n",
       "  'sequence',\n",
       "  'characters',\n",
       "  'space'],\n",
       " ['youll', 'rely', 'special', 'techniques', 'identify', 'words'],\n",
       " ['language', 'course', 'might', 'make', 'mistakes', 'segmenting', 'words'],\n",
       " ['sequence', 'words', 'representation', 'robust', 'string', 'characters'],\n",
       " ['english', 'easy', 'obtain', 'level', 'representation', 'time'],\n",
       " ['go',\n",
       "  'naturally',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'add',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tags'],\n",
       " ['count',\n",
       "  'example',\n",
       "  'frequent',\n",
       "  'nouns',\n",
       "  'kind',\n",
       "  'nouns',\n",
       "  'associated',\n",
       "  'kind',\n",
       "  'verbs',\n",
       "  'etc'],\n",
       " ['opens', 'little', 'bit', 'interesting', 'opportunities', 'analysis'],\n",
       " ['note',\n",
       "  'use',\n",
       "  'plus',\n",
       "  'sign',\n",
       "  'representing',\n",
       "  'text',\n",
       "  'sequence',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tags',\n",
       "  'dont',\n",
       "  'necessarily',\n",
       "  'replace',\n",
       "  'original',\n",
       "  'word',\n",
       "  'sequence',\n",
       "  'written'],\n",
       " ['instead',\n",
       "  'add',\n",
       "  'additional',\n",
       "  'way',\n",
       "  'representing',\n",
       "  'text',\n",
       "  'data',\n",
       "  'data',\n",
       "  'represented',\n",
       "  'sequence',\n",
       "  'words',\n",
       "  'sequence',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tags'],\n",
       " ['enriches',\n",
       "  'representation',\n",
       "  'text',\n",
       "  'data',\n",
       "  'thus',\n",
       "  'also',\n",
       "  'enables',\n",
       "  'interesting',\n",
       "  'analysis'],\n",
       " ['go',\n",
       "  'well',\n",
       "  'pausing',\n",
       "  'sentence',\n",
       "  'often',\n",
       "  'obtain',\n",
       "  'syntactic',\n",
       "  'structure'],\n",
       " ['course',\n",
       "  'open',\n",
       "  'interesting',\n",
       "  'analysis',\n",
       "  'example',\n",
       "  'writing',\n",
       "  'styles',\n",
       "  'correcting',\n",
       "  'grammar',\n",
       "  'mistakes'],\n",
       " ['go',\n",
       "  'semantic',\n",
       "  'analysis',\n",
       "  'might',\n",
       "  'able',\n",
       "  'recognize',\n",
       "  'dog',\n",
       "  'animal',\n",
       "  'also',\n",
       "  'recognize',\n",
       "  'boy',\n",
       "  'person',\n",
       "  'playground',\n",
       "  'location'],\n",
       " ['analyze',\n",
       "  'relations',\n",
       "  'example',\n",
       "  'dog',\n",
       "  'chasing',\n",
       "  'boy',\n",
       "  'boy',\n",
       "  'playground'],\n",
       " ['add', 'entities', 'relations', 'entity', 'relation', 'recreation'],\n",
       " ['level', 'even', 'interesting', 'things'],\n",
       " ['example',\n",
       "  'count',\n",
       "  'easily',\n",
       "  'frequent',\n",
       "  'person',\n",
       "  'thats',\n",
       "  'mentioning',\n",
       "  'whole',\n",
       "  'collection',\n",
       "  'news',\n",
       "  'articles',\n",
       "  'whenever',\n",
       "  'mention',\n",
       "  'person',\n",
       "  'also',\n",
       "  'tend',\n",
       "  'see',\n",
       "  'mentioning',\n",
       "  'another',\n",
       "  'person',\n",
       "  'etc'],\n",
       " ['useful',\n",
       "  'representation',\n",
       "  'also',\n",
       "  'related',\n",
       "  'knowledge',\n",
       "  'graph',\n",
       "  'may',\n",
       "  'heard',\n",
       "  'google',\n",
       "  'semantic',\n",
       "  'way',\n",
       "  'representing',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['however',\n",
       "  'also',\n",
       "  'less',\n",
       "  'robust',\n",
       "  'sequence',\n",
       "  'words',\n",
       "  'even',\n",
       "  'syntactical',\n",
       "  'analysis',\n",
       "  'always',\n",
       "  'easy',\n",
       "  'identify',\n",
       "  'entities',\n",
       "  'right',\n",
       "  'types',\n",
       "  'might',\n",
       "  'make',\n",
       "  'mistakes',\n",
       "  'relations',\n",
       "  'even',\n",
       "  'harder',\n",
       "  'find',\n",
       "  'might',\n",
       "  'make',\n",
       "  'mistakes'],\n",
       " ['makes', 'level', 'representation', 'less', 'robust', 'yet', 'useful'],\n",
       " ['move', 'logical', 'condition', 'predicates', 'even', 'inference', 'rules'],\n",
       " ['inference',\n",
       "  'rules',\n",
       "  'infer',\n",
       "  'interesting',\n",
       "  'derived',\n",
       "  'facts',\n",
       "  'text',\n",
       "  'thats',\n",
       "  'useful'],\n",
       " ['unfortunately',\n",
       "  'level',\n",
       "  'representation',\n",
       "  'even',\n",
       "  'less',\n",
       "  'robust',\n",
       "  'make',\n",
       "  'mistakes',\n",
       "  'cant',\n",
       "  'time',\n",
       "  'kinds',\n",
       "  'sentences'],\n",
       " ['finally',\n",
       "  'speech',\n",
       "  'acts',\n",
       "  'would',\n",
       "  'add',\n",
       "  'yet',\n",
       "  'another',\n",
       "  'level',\n",
       "  'repetition',\n",
       "  'intent',\n",
       "  'saying',\n",
       "  'sentence'],\n",
       " ['case', 'might', 'request'],\n",
       " ['knowing',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'us',\n",
       "  'analyze',\n",
       "  'even',\n",
       "  'interesting',\n",
       "  'things',\n",
       "  'observer',\n",
       "  'author',\n",
       "  'sentence'],\n",
       " ['whats',\n",
       "  'intention',\n",
       "  'saying',\n",
       "  'whats',\n",
       "  'scenarios',\n",
       "  'kind',\n",
       "  'actions',\n",
       "  'would',\n",
       "  'made',\n",
       "  'another',\n",
       "  'level',\n",
       "  'analysis',\n",
       "  'would',\n",
       "  'interesting'],\n",
       " ['picture',\n",
       "  'shows',\n",
       "  'move',\n",
       "  'generally',\n",
       "  'see',\n",
       "  'sophisticated',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'used'],\n",
       " ['unfortunately',\n",
       "  'techniques',\n",
       "  'would',\n",
       "  'require',\n",
       "  'human',\n",
       "  'effort',\n",
       "  'less',\n",
       "  'accurate'],\n",
       " ['means', 'mistakes'],\n",
       " ['add',\n",
       "  'texts',\n",
       "  'levels',\n",
       "  'representing',\n",
       "  'deeper',\n",
       "  'analysis',\n",
       "  'language',\n",
       "  'tolerate',\n",
       "  'errors'],\n",
       " ['also',\n",
       "  'means',\n",
       "  'still',\n",
       "  'necessary',\n",
       "  'combine',\n",
       "  'deep',\n",
       "  'analysis',\n",
       "  'shallow',\n",
       "  'analysis',\n",
       "  'based',\n",
       "  'example',\n",
       "  'sequence',\n",
       "  'words'],\n",
       " ['right', 'side', 'youll', 'see', 'arrow', 'points', 'indicate'],\n",
       " ['go',\n",
       "  'representation',\n",
       "  'text',\n",
       "  'closer',\n",
       "  'knowledge',\n",
       "  'representation',\n",
       "  'mind',\n",
       "  'need',\n",
       "  'solving',\n",
       "  'lot',\n",
       "  'problems'],\n",
       " ['desirable',\n",
       "  'represent',\n",
       "  'text',\n",
       "  'level',\n",
       "  'knowledge',\n",
       "  'easily',\n",
       "  'extract',\n",
       "  'knowledge'],\n",
       " ['thats', 'purpose', 'textmining'],\n",
       " ['tradeoff',\n",
       "  'deeper',\n",
       "  'analysis',\n",
       "  'might',\n",
       "  'errors',\n",
       "  'would',\n",
       "  'give',\n",
       "  'us',\n",
       "  'direct',\n",
       "  'knowledge',\n",
       "  'extracted',\n",
       "  'text'],\n",
       " ['shallow',\n",
       "  'analysis',\n",
       "  'robust',\n",
       "  'wouldnt',\n",
       "  'actually',\n",
       "  'give',\n",
       "  'us',\n",
       "  'necessary',\n",
       "  'deeper',\n",
       "  'representation',\n",
       "  'knowledge'],\n",
       " ['also',\n",
       "  'say',\n",
       "  'text',\n",
       "  'data',\n",
       "  'generated',\n",
       "  'humans',\n",
       "  'meant',\n",
       "  'consumed',\n",
       "  'humans'],\n",
       " ['result',\n",
       "  'text',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'textmining',\n",
       "  'humans',\n",
       "  'play',\n",
       "  'important',\n",
       "  'role',\n",
       "  'always',\n",
       "  'loop'],\n",
       " ['meaning', 'optimize', 'collaboration', 'humans', 'computers'],\n",
       " ['sense',\n",
       "  'okay',\n",
       "  'computers',\n",
       "  'may',\n",
       "  'able',\n",
       "  'compute',\n",
       "  'accurately',\n",
       "  'representation',\n",
       "  'text',\n",
       "  'data',\n",
       "  'patterns',\n",
       "  'extracted',\n",
       "  'text',\n",
       "  'data',\n",
       "  'interpreted',\n",
       "  'humans',\n",
       "  'humans',\n",
       "  'guide',\n",
       "  'computers',\n",
       "  'accurate',\n",
       "  'analysis',\n",
       "  'annotating',\n",
       "  'data',\n",
       "  'providing',\n",
       "  'features',\n",
       "  'guide',\n",
       "  'machine',\n",
       "  'sound'],\n",
       " ['explained',\n",
       "  'different',\n",
       "  'text',\n",
       "  'representation',\n",
       "  'tends',\n",
       "  'enable',\n",
       "  'different',\n",
       "  'analysis'],\n",
       " ['particular',\n",
       "  'gradually',\n",
       "  'add',\n",
       "  'deeper',\n",
       "  'analysis',\n",
       "  'results',\n",
       "  'represent',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['would',\n",
       "  'open',\n",
       "  'interesting',\n",
       "  'representation',\n",
       "  'opportunities',\n",
       "  'also',\n",
       "  'analysis',\n",
       "  'capacities'],\n",
       " ['table', 'summarizes', 'seen'],\n",
       " ['first', 'column', 'shows', 'text', 'representation'],\n",
       " ['second', 'visualizes', 'generality', 'representation'],\n",
       " ['meaning',\n",
       "  'whether',\n",
       "  'kind',\n",
       "  'representation',\n",
       "  'accurately',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['third', 'column', 'shows', 'enabled', 'analysis', 'techniques'],\n",
       " ['final',\n",
       "  'column',\n",
       "  'shows',\n",
       "  'examples',\n",
       "  'application',\n",
       "  'achieved',\n",
       "  'level',\n",
       "  'representation'],\n",
       " ['lets', 'take', 'look'],\n",
       " ['stream', 'text', 'processed', 'stream', 'processing', 'algorithms'],\n",
       " ['robust', 'general'],\n",
       " ['still', 'interesting', 'applications', 'level'],\n",
       " ['example', 'compression', 'text'],\n",
       " ['doesnt', 'necessarily', 'need', 'know', 'word', 'boundaries'],\n",
       " ['although',\n",
       "  'knowing',\n",
       "  'word',\n",
       "  'boundaries',\n",
       "  'might',\n",
       "  'actually',\n",
       "  'also',\n",
       "  'help'],\n",
       " ['word', 'base', 'repetition', 'important', 'level', 'representation'],\n",
       " ['quite',\n",
       "  'general',\n",
       "  'relatively',\n",
       "  'robust',\n",
       "  'indicating',\n",
       "  'lot',\n",
       "  'analysis',\n",
       "  'techniques'],\n",
       " ['word',\n",
       "  'relation',\n",
       "  'analysis',\n",
       "  'topic',\n",
       "  'analysis',\n",
       "  'sentiment',\n",
       "  'analysis'],\n",
       " ['many', 'applications', 'enabled', 'kind', 'analysis'],\n",
       " ['example', 'thesaurus', 'discovery', 'discovering', 'related', 'words'],\n",
       " ['topic', 'opinion', 'related', 'applications', 'abounded'],\n",
       " ['example',\n",
       "  'people',\n",
       "  'might',\n",
       "  'interesting',\n",
       "  'knowing',\n",
       "  'major',\n",
       "  'topics',\n",
       "  'covered',\n",
       "  'collection',\n",
       "  'texts'],\n",
       " ['case', 'research', 'literature'],\n",
       " ['scientists', 'want', 'know', 'important', 'research', 'topics', 'today'],\n",
       " ['customer',\n",
       "  'service',\n",
       "  'people',\n",
       "  'might',\n",
       "  'want',\n",
       "  'know',\n",
       "  'major',\n",
       "  'complaints',\n",
       "  'customers',\n",
       "  'mining',\n",
       "  'email',\n",
       "  'messages'],\n",
       " ['business',\n",
       "  'intelligence',\n",
       "  'people',\n",
       "  'might',\n",
       "  'interested',\n",
       "  'understanding',\n",
       "  'consumers',\n",
       "  'opinions',\n",
       "  'products',\n",
       "  'competitors',\n",
       "  'products',\n",
       "  'figure',\n",
       "  'winning',\n",
       "  'features',\n",
       "  'products'],\n",
       " ['general', 'many', 'applications', 'enabled', 'representation', 'level'],\n",
       " ['moving',\n",
       "  'well',\n",
       "  'see',\n",
       "  'gradually',\n",
       "  'add',\n",
       "  'additional',\n",
       "  'representations'],\n",
       " ['adding',\n",
       "  'syntactical',\n",
       "  'structures',\n",
       "  'enable',\n",
       "  'course',\n",
       "  'syntactical',\n",
       "  'graph',\n",
       "  'analysis'],\n",
       " ['use', 'graph', 'mining', 'algorithms', 'analyze', 'syntactic', 'graphs'],\n",
       " ['applications', 'related', 'kind', 'representation'],\n",
       " ['example',\n",
       "  'stylistic',\n",
       "  'analysis',\n",
       "  'generally',\n",
       "  'requires',\n",
       "  'syntactical',\n",
       "  'structure',\n",
       "  'representation'],\n",
       " ['also', 'generate', 'structure', 'based', 'features'],\n",
       " ['features',\n",
       "  'might',\n",
       "  'help',\n",
       "  'us',\n",
       "  'classify',\n",
       "  'text',\n",
       "  'objects',\n",
       "  'different',\n",
       "  'categories',\n",
       "  'looking',\n",
       "  'structures',\n",
       "  'sometimes',\n",
       "  'classification'],\n",
       " ['accurate'],\n",
       " ['example',\n",
       "  'want',\n",
       "  'classify',\n",
       "  'articles',\n",
       "  'different',\n",
       "  'categories',\n",
       "  'corresponding',\n",
       "  'different',\n",
       "  'authors'],\n",
       " ['want',\n",
       "  'figure',\n",
       "  'k',\n",
       "  'authors',\n",
       "  'actually',\n",
       "  'written',\n",
       "  'article',\n",
       "  'generally',\n",
       "  'need',\n",
       "  'look',\n",
       "  'syntactic',\n",
       "  'structures'],\n",
       " ['add',\n",
       "  'entities',\n",
       "  'relations',\n",
       "  'enable',\n",
       "  'techniques',\n",
       "  'knowledge',\n",
       "  'graph',\n",
       "  'answers',\n",
       "  'information',\n",
       "  'network',\n",
       "  'answers',\n",
       "  'general'],\n",
       " ['analysis', 'enable', 'applications', 'entities'],\n",
       " ['example',\n",
       "  'discovery',\n",
       "  'knowledge',\n",
       "  'opinions',\n",
       "  'real',\n",
       "  'world',\n",
       "  'entities'],\n",
       " ['also',\n",
       "  'use',\n",
       "  'level',\n",
       "  'representation',\n",
       "  'integrate',\n",
       "  'everything',\n",
       "  'anything',\n",
       "  'scaled',\n",
       "  'resources'],\n",
       " ['finally',\n",
       "  'add',\n",
       "  'logical',\n",
       "  'predicates',\n",
       "  'would',\n",
       "  'enable',\n",
       "  'large',\n",
       "  'inference',\n",
       "  'course'],\n",
       " ['useful', 'integrating', 'analysis', 'scattered', 'knowledge'],\n",
       " ['example',\n",
       "  'also',\n",
       "  'add',\n",
       "  'ontology',\n",
       "  'top',\n",
       "  'extracted',\n",
       "  'information',\n",
       "  'text',\n",
       "  'make',\n",
       "  'inferences'],\n",
       " ['good',\n",
       "  'example',\n",
       "  'application',\n",
       "  'enabled',\n",
       "  'level',\n",
       "  'representation',\n",
       "  'knowledge',\n",
       "  'assistant',\n",
       "  'biologists'],\n",
       " ['program',\n",
       "  'help',\n",
       "  'biologist',\n",
       "  'manage',\n",
       "  'relevant',\n",
       "  'knowledge',\n",
       "  'literature',\n",
       "  'research',\n",
       "  'problem',\n",
       "  'understanding',\n",
       "  'functions',\n",
       "  'genes'],\n",
       " ['computer',\n",
       "  'make',\n",
       "  'inferences',\n",
       "  'hypothesis',\n",
       "  'biologist',\n",
       "  'might',\n",
       "  'interesting'],\n",
       " ['example',\n",
       "  'whether',\n",
       "  'gene',\n",
       "  'certain',\n",
       "  'function',\n",
       "  'intelligent',\n",
       "  'program',\n",
       "  'read',\n",
       "  'literature',\n",
       "  'extract',\n",
       "  'relevant',\n",
       "  'facts',\n",
       "  'compiling',\n",
       "  'information',\n",
       "  'extracting'],\n",
       " ['using',\n",
       "  'logic',\n",
       "  'system',\n",
       "  'actually',\n",
       "  'track',\n",
       "  'thats',\n",
       "  'answers',\n",
       "  'researchers',\n",
       "  'questioning',\n",
       "  'genes',\n",
       "  'related',\n",
       "  'functions'],\n",
       " ['order',\n",
       "  'support',\n",
       "  'level',\n",
       "  'application',\n",
       "  'need',\n",
       "  'go',\n",
       "  'far',\n",
       "  'logical',\n",
       "  'representation'],\n",
       " ['course',\n",
       "  'covering',\n",
       "  'techniques',\n",
       "  'mainly',\n",
       "  'based',\n",
       "  'word',\n",
       "  'based',\n",
       "  'representation'],\n",
       " ['techniques',\n",
       "  'general',\n",
       "  'robust',\n",
       "  'thats',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'various',\n",
       "  'applications'],\n",
       " ['fact',\n",
       "  'virtually',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'applications',\n",
       "  'need',\n",
       "  'level',\n",
       "  'representation',\n",
       "  'techniques',\n",
       "  'support',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'level'],\n",
       " ['obviously',\n",
       "  'levels',\n",
       "  'combined',\n",
       "  'combined',\n",
       "  'order',\n",
       "  'support',\n",
       "  'sophisticated',\n",
       "  'applications'],\n",
       " ['summarize', 'major', 'takeaway', 'points'],\n",
       " ['text',\n",
       "  'representation',\n",
       "  'determines',\n",
       "  'kind',\n",
       "  'mining',\n",
       "  'algorithms',\n",
       "  'applied'],\n",
       " ['multiple',\n",
       "  'ways',\n",
       "  'represent',\n",
       "  'text',\n",
       "  'strings',\n",
       "  'words',\n",
       "  'syntactic',\n",
       "  'structures',\n",
       "  'entityrelation',\n",
       "  'graphs',\n",
       "  'knowledge',\n",
       "  'predicates',\n",
       "  'etc'],\n",
       " ['different',\n",
       "  'representations',\n",
       "  'general',\n",
       "  'combined',\n",
       "  'real',\n",
       "  'applications',\n",
       "  'extent'],\n",
       " ['example',\n",
       "  'even',\n",
       "  'accurate',\n",
       "  'representations',\n",
       "  'syntactic',\n",
       "  'structures',\n",
       "  'state',\n",
       "  'partial',\n",
       "  'structures',\n",
       "  'strictly'],\n",
       " ['recognize', 'entities', 'would', 'great'],\n",
       " ['general', 'want', 'much'],\n",
       " ['different',\n",
       "  'levels',\n",
       "  'combined',\n",
       "  'together',\n",
       "  'enable',\n",
       "  'richer',\n",
       "  'analysis',\n",
       "  'powerful',\n",
       "  'analysis'],\n",
       " ['course', 'however', 'focuses', 'wordbased', 'representation'],\n",
       " ['techniques',\n",
       "  'also',\n",
       "  'several',\n",
       "  'advantage',\n",
       "  'first',\n",
       "  'general',\n",
       "  'robust',\n",
       "  'applicable',\n",
       "  'natural',\n",
       "  'language'],\n",
       " ['thats',\n",
       "  'big',\n",
       "  'advantage',\n",
       "  'approaches',\n",
       "  'rely',\n",
       "  'fragile',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques'],\n",
       " ['secondly',\n",
       "  'require',\n",
       "  'much',\n",
       "  'manual',\n",
       "  'effort',\n",
       "  'sometimes',\n",
       "  'require',\n",
       "  'manual',\n",
       "  'effort'],\n",
       " ['thats',\n",
       "  'important',\n",
       "  'benefit',\n",
       "  'means',\n",
       "  'apply',\n",
       "  'directly',\n",
       "  'application'],\n",
       " ['third',\n",
       "  'techniques',\n",
       "  'actually',\n",
       "  'surprisingly',\n",
       "  'powerful',\n",
       "  'effective',\n",
       "  'form',\n",
       "  'implications'],\n",
       " ['although', 'course', 'explained'],\n",
       " ['effective',\n",
       "  'partly',\n",
       "  'words',\n",
       "  'invented',\n",
       "  'humans',\n",
       "  'basically',\n",
       "  'units',\n",
       "  'communications'],\n",
       " ['actually', 'quite', 'sufficient', 'representing', 'kinds', 'semantics'],\n",
       " ['makes', 'kind', 'wordbased', 'representation', 'powerful'],\n",
       " ['finally',\n",
       "  'wordbased',\n",
       "  'representation',\n",
       "  'techniques',\n",
       "  'enable',\n",
       "  'representation',\n",
       "  'combined',\n",
       "  'many',\n",
       "  'sophisticated',\n",
       "  'approaches'],\n",
       " ['theyre', 'competing'],\n",
       " ['sound',\n",
       "  'specific',\n",
       "  'examples',\n",
       "  'cant',\n",
       "  'today',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tagging',\n",
       "  'still',\n",
       "  'easy',\n",
       "  'NUMBER',\n",
       "  'correctly'],\n",
       " ['example',\n",
       "  'turned',\n",
       "  'highway',\n",
       "  'verses',\n",
       "  'turned',\n",
       "  'fan',\n",
       "  'two',\n",
       "  'offs',\n",
       "  'actually',\n",
       "  'somewhat',\n",
       "  'differentness',\n",
       "  'active',\n",
       "  'categories',\n",
       "  'also',\n",
       "  'difficult',\n",
       "  'get',\n",
       "  'complete',\n",
       "  'parsing',\n",
       "  'correct'],\n",
       " ['example',\n",
       "  'man',\n",
       "  'saw',\n",
       "  'boy',\n",
       "  'telescope',\n",
       "  'actually',\n",
       "  'difficult',\n",
       "  'parse',\n",
       "  'depending',\n",
       "  'context'],\n",
       " ['precise', 'deep', 'semantic', 'analysis', 'also', 'hard'],\n",
       " ['example',\n",
       "  'define',\n",
       "  'meaning',\n",
       "  'precisely',\n",
       "  'difficult',\n",
       "  'sentence',\n",
       "  'like',\n",
       "  'john',\n",
       "  'owns',\n",
       "  'restaurant'],\n",
       " ['state', 'summarized', 'follows'],\n",
       " ['robust',\n",
       "  'general',\n",
       "  'nlp',\n",
       "  'tends',\n",
       "  'shallow',\n",
       "  'deep',\n",
       "  'understanding',\n",
       "  'scale'],\n",
       " ['reason',\n",
       "  'course',\n",
       "  'techniques',\n",
       "  'cover',\n",
       "  'general',\n",
       "  'shallow',\n",
       "  'techniques',\n",
       "  'analyzing',\n",
       "  'text',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'text',\n",
       "  'data',\n",
       "  'generally',\n",
       "  'based',\n",
       "  'statistical',\n",
       "  'analysis'],\n",
       " ['robust', 'general', 'category', 'shallow', 'analysis'],\n",
       " ['techniques',\n",
       "  'advantage',\n",
       "  'able',\n",
       "  'applied',\n",
       "  'text',\n",
       "  'data',\n",
       "  'natural',\n",
       "  'topic'],\n",
       " ['downside', 'dont', 'give', 'use', 'deeper', 'understanding', 'text'],\n",
       " ['rely', 'deeper', 'natural', 'language', 'analysis'],\n",
       " ['typically',\n",
       "  'would',\n",
       "  'require',\n",
       "  'human',\n",
       "  'effort',\n",
       "  'annotate',\n",
       "  'lot',\n",
       "  'examples',\n",
       "  'analysis',\n",
       "  'would',\n",
       "  'like',\n",
       "  'computers',\n",
       "  'use',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniques',\n",
       "  'learn',\n",
       "  'training',\n",
       "  'examples',\n",
       "  'task'],\n",
       " ['practical',\n",
       "  'applications',\n",
       "  'generally',\n",
       "  'combine',\n",
       "  'two',\n",
       "  'kinds',\n",
       "  'techniques',\n",
       "  'general',\n",
       "  'statistical',\n",
       "  'methods',\n",
       "  'backbone',\n",
       "  'basis'],\n",
       " ['applied', 'text', 'data'],\n",
       " ['top',\n",
       "  'going',\n",
       "  'use',\n",
       "  'humans',\n",
       "  'take',\n",
       "  'data',\n",
       "  'use',\n",
       "  'supervised',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'tasks',\n",
       "  'well',\n",
       "  'especially',\n",
       "  'important',\n",
       "  'tasks',\n",
       "  'bring',\n",
       "  'humans',\n",
       "  'loop',\n",
       "  'analyze',\n",
       "  'text',\n",
       "  'data',\n",
       "  'precisely'],\n",
       " ['course',\n",
       "  'cover',\n",
       "  'general',\n",
       "  'statistical',\n",
       "  'approaches',\n",
       "  'generally',\n",
       "  'dont',\n",
       "  'require',\n",
       "  'much',\n",
       "  'human',\n",
       "  'effort'],\n",
       " ['theyre',\n",
       "  'practically',\n",
       "  'useful',\n",
       "  'deeper',\n",
       "  'analysis',\n",
       "  'techniques',\n",
       "  'require',\n",
       "  'lot',\n",
       "  'human',\n",
       "  'effort',\n",
       "  'annotate',\n",
       "  'text',\n",
       "  'today'],\n",
       " ['summarize',\n",
       "  'main',\n",
       "  'points',\n",
       "  'take',\n",
       "  'first',\n",
       "  'nlp',\n",
       "  'foundation',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['obviously',\n",
       "  'better',\n",
       "  'understand',\n",
       "  'text',\n",
       "  'data',\n",
       "  'better',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['computers', 'today', 'far', 'able', 'understand', 'natural', 'language'],\n",
       " ['deep', 'nlp', 'requires', 'common', 'sense', 'knowledge', 'inferences'],\n",
       " ['thus',\n",
       "  'working',\n",
       "  'limited',\n",
       "  'domains',\n",
       "  'feasible',\n",
       "  'large',\n",
       "  'scale',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['shallow',\n",
       "  'nlp',\n",
       "  'based',\n",
       "  'statistical',\n",
       "  'methods',\n",
       "  'done',\n",
       "  'large',\n",
       "  'scale',\n",
       "  'main',\n",
       "  'topic',\n",
       "  'course',\n",
       "  'generally',\n",
       "  'applicable',\n",
       "  'lot',\n",
       "  'applications'],\n",
       " ['sense', 'also', 'useful', 'techniques'],\n",
       " ['practice',\n",
       "  'use',\n",
       "  'statistical',\n",
       "  'nlp',\n",
       "  'basis',\n",
       "  'well',\n",
       "  'humans',\n",
       "  'help',\n",
       "  'needed',\n",
       "  'various',\n",
       "  'ways'],\n",
       " ['sound', 'lecture', 'word', 'association', 'mining', 'analysis'],\n",
       " ['lecture', 'going', 'talk', 'mine', 'associations', 'words', 'text'],\n",
       " ['example', 'knowledge', 'natural', 'language', 'mine', 'text', 'data'],\n",
       " ['heres', 'outline'],\n",
       " ['going',\n",
       "  'first',\n",
       "  'talk',\n",
       "  'word',\n",
       "  'association',\n",
       "  'explain',\n",
       "  'discovering',\n",
       "  'relations',\n",
       "  'useful',\n",
       "  'finally',\n",
       "  'going',\n",
       "  'talk',\n",
       "  'general',\n",
       "  'ideas',\n",
       "  'mine',\n",
       "  'word',\n",
       "  'associations'],\n",
       " ['general', 'two', 'word', 'relations', 'quite', 'basic'],\n",
       " ['one', 'called', 'paradigmatic', 'relation'],\n",
       " ['syntagmatic', 'relation'],\n",
       " ['b', 'paradigmatic', 'relation', 'substituted'],\n",
       " ['means',\n",
       "  'two',\n",
       "  'words',\n",
       "  'paradigmatic',\n",
       "  'relation',\n",
       "  'would',\n",
       "  'semantic',\n",
       "  'class',\n",
       "  'syntactic',\n",
       "  'class'],\n",
       " ['general',\n",
       "  'replace',\n",
       "  'one',\n",
       "  'without',\n",
       "  'affecting',\n",
       "  'understanding',\n",
       "  'sentence'],\n",
       " ['means', 'would', 'still', 'valid', 'sentence'],\n",
       " ['example',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'two',\n",
       "  'words',\n",
       "  'paradigmatic',\n",
       "  'relation',\n",
       "  'class',\n",
       "  'animal'],\n",
       " ['general',\n",
       "  'replace',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'sentence',\n",
       "  'sentence',\n",
       "  'would',\n",
       "  'still',\n",
       "  'valid',\n",
       "  'sentence',\n",
       "  'make',\n",
       "  'sense'],\n",
       " ['similarly', 'monday', 'tuesday', 'paradigmatical', 'relation'],\n",
       " ['second', 'kind', 'relation', 'called', 'syntagmatical', 'relation'],\n",
       " ['case', 'two', 'words', 'relation', 'combined'],\n",
       " ['b',\n",
       "  'syntagmatic',\n",
       "  'relation',\n",
       "  'combined',\n",
       "  'sentence',\n",
       "  'means',\n",
       "  'two',\n",
       "  'words',\n",
       "  'semantically',\n",
       "  'related'],\n",
       " ['example', 'cat', 'sit', 'related', 'cat', 'sit', 'somewhere'],\n",
       " ['similarly',\n",
       "  'car',\n",
       "  'drive',\n",
       "  'related',\n",
       "  'semantically',\n",
       "  'combined',\n",
       "  'convey',\n",
       "  'meaning'],\n",
       " ['however',\n",
       "  'general',\n",
       "  'replace',\n",
       "  'cat',\n",
       "  'sit',\n",
       "  'sentence',\n",
       "  'car',\n",
       "  'drive',\n",
       "  'sentence',\n",
       "  'still',\n",
       "  'get',\n",
       "  'valid',\n",
       "  'sentence',\n",
       "  'meaning',\n",
       "  'sentence',\n",
       "  'become',\n",
       "  'somewhat',\n",
       "  'meaningless'],\n",
       " ['different', 'paradigmatic', 'relation'],\n",
       " ['two',\n",
       "  'relations',\n",
       "  'fact',\n",
       "  'fundamental',\n",
       "  'generalized',\n",
       "  'capture',\n",
       "  'basic',\n",
       "  'relations',\n",
       "  'units',\n",
       "  'arbitrary',\n",
       "  'sequences'],\n",
       " ['definitely', 'generalized', 'describe', 'relations', 'items', 'language'],\n",
       " ['b', 'dont', 'words', 'phrases', 'example'],\n",
       " ['even', 'complex', 'phrases', 'nonphrase'],\n",
       " ['think',\n",
       "  'general',\n",
       "  'problem',\n",
       "  'sequence',\n",
       "  'mining',\n",
       "  'think',\n",
       "  'units',\n",
       "  'sequence',\n",
       "  'data'],\n",
       " ['think',\n",
       "  'paradigmatic',\n",
       "  'relation',\n",
       "  'relations',\n",
       "  'applied',\n",
       "  'units',\n",
       "  'tend',\n",
       "  'occur',\n",
       "  'singular',\n",
       "  'locations',\n",
       "  'sentence',\n",
       "  'sequence',\n",
       "  'data',\n",
       "  'elements',\n",
       "  'general'],\n",
       " ['occur', 'similar', 'locations', 'relative', 'neighbors', 'sequence'],\n",
       " ['syntagmatical',\n",
       "  'relation',\n",
       "  'hand',\n",
       "  'related',\n",
       "  'cooccurrent',\n",
       "  'elements',\n",
       "  'tend',\n",
       "  'show',\n",
       "  'sequence'],\n",
       " ['two', 'complimentary', 'basic', 'relations', 'words'],\n",
       " ['interested', 'discovering', 'automatically', 'text', 'data'],\n",
       " ['discovering', 'worded', 'relations', 'many', 'applications'],\n",
       " ['first',\n",
       "  'relations',\n",
       "  'directly',\n",
       "  'useful',\n",
       "  'improving',\n",
       "  'accuracy',\n",
       "  'many',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'part',\n",
       "  'knowledge',\n",
       "  'language'],\n",
       " ['know', 'two', 'words', 'synonyms', 'example', 'help', 'lot', 'tasks'],\n",
       " ['grammar', 'learning', 'also', 'done', 'using', 'techniques'],\n",
       " ['learn',\n",
       "  'paradigmatic',\n",
       "  'relations',\n",
       "  'form',\n",
       "  'classes',\n",
       "  'words',\n",
       "  'syntactic',\n",
       "  'classes',\n",
       "  'example'],\n",
       " ['learn',\n",
       "  'syntagmatic',\n",
       "  'relations',\n",
       "  'would',\n",
       "  'able',\n",
       "  'know',\n",
       "  'rules',\n",
       "  'putting',\n",
       "  'together',\n",
       "  'larger',\n",
       "  'expression',\n",
       "  'based',\n",
       "  'component',\n",
       "  'expressions'],\n",
       " ['learn', 'structure', 'go', 'else'],\n",
       " ['word',\n",
       "  'relations',\n",
       "  'also',\n",
       "  'useful',\n",
       "  'many',\n",
       "  'applications',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'mining'],\n",
       " ['example',\n",
       "  'search',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'use',\n",
       "  'word',\n",
       "  'associations',\n",
       "  'modify',\n",
       "  'query',\n",
       "  'used',\n",
       "  'introduce',\n",
       "  'additional',\n",
       "  'related',\n",
       "  'words',\n",
       "  'query',\n",
       "  'make',\n",
       "  'query',\n",
       "  'effective'],\n",
       " ['often', 'called', 'query', 'expansion'],\n",
       " ['use',\n",
       "  'related',\n",
       "  'words',\n",
       "  'suggest',\n",
       "  'related',\n",
       "  'queries',\n",
       "  'user',\n",
       "  'explore',\n",
       "  'information',\n",
       "  'space'],\n",
       " ['another',\n",
       "  'application',\n",
       "  'use',\n",
       "  'word',\n",
       "  'associations',\n",
       "  'automatically',\n",
       "  'construct',\n",
       "  'top',\n",
       "  'map',\n",
       "  'browsing'],\n",
       " ['words', 'nodes', 'associations', 'edges'],\n",
       " ['user',\n",
       "  'could',\n",
       "  'navigate',\n",
       "  'one',\n",
       "  'word',\n",
       "  'another',\n",
       "  'find',\n",
       "  'information',\n",
       "  'information',\n",
       "  'space'],\n",
       " ['finally',\n",
       "  'word',\n",
       "  'associations',\n",
       "  'also',\n",
       "  'used',\n",
       "  'compare',\n",
       "  'summarize',\n",
       "  'opinions'],\n",
       " ['example',\n",
       "  'might',\n",
       "  'interested',\n",
       "  'understanding',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  'opinions',\n",
       "  'iphone',\n",
       "  'NUMBER'],\n",
       " ['order',\n",
       "  'look',\n",
       "  'words',\n",
       "  'strongly',\n",
       "  'associated',\n",
       "  'feature',\n",
       "  'word',\n",
       "  'like',\n",
       "  'battery',\n",
       "  'positive',\n",
       "  'versus',\n",
       "  'negative',\n",
       "  'reviews'],\n",
       " ['syntagmatical',\n",
       "  'relations',\n",
       "  'would',\n",
       "  'help',\n",
       "  'us',\n",
       "  'show',\n",
       "  'detailed',\n",
       "  'opinions',\n",
       "  'product'],\n",
       " ['discover', 'associations', 'automatically', 'intuitions'],\n",
       " ['lets', 'first', 'look', 'paradigmatic', 'relation'],\n",
       " ['essentially', 'take', 'advantage', 'similar', 'context'],\n",
       " ['see', 'simple', 'sentences', 'cat', 'dog'],\n",
       " ['see',\n",
       "  'generally',\n",
       "  'occur',\n",
       "  'similar',\n",
       "  'context',\n",
       "  'definition',\n",
       "  'paradigmatic',\n",
       "  'relation'],\n",
       " ['right',\n",
       "  'side',\n",
       "  'kind',\n",
       "  'see',\n",
       "  'extracted',\n",
       "  'expressly',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'small',\n",
       "  'sample',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['ive', 'taken', 'away', 'cat', 'dog', 'sentences', 'see', 'context'],\n",
       " ['course', 'different', 'perspectives', 'look', 'context'],\n",
       " ['example', 'look', 'words', 'occur', 'left', 'part', 'context'],\n",
       " ['call', 'left', 'context'],\n",
       " ['words',\n",
       "  'occur',\n",
       "  'see',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'see',\n",
       "  'case',\n",
       "  'clearly',\n",
       "  'dog',\n",
       "  'cat',\n",
       "  'similar',\n",
       "  'left',\n",
       "  'context'],\n",
       " ['generally', 'say', 'cat', 'cat', 'say', 'also', 'dog', 'dog'],\n",
       " ['makes', 'similar', 'left', 'context'],\n",
       " ['similarly',\n",
       "  'look',\n",
       "  'words',\n",
       "  'occur',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'call',\n",
       "  'right',\n",
       "  'context',\n",
       "  'also',\n",
       "  'similar',\n",
       "  'case'],\n",
       " ['course', 'extreme', 'case', 'see', 'eats'],\n",
       " ['general',\n",
       "  'youll',\n",
       "  'see',\n",
       "  'many',\n",
       "  'words',\n",
       "  'course',\n",
       "  'cant',\n",
       "  'follow',\n",
       "  'cat',\n",
       "  'dog'],\n",
       " ['also', 'even', 'look', 'general', 'context'],\n",
       " ['might', 'include', 'words', 'sentence', 'sentences', 'around', 'word'],\n",
       " ['even', 'general', 'context', 'also', 'see', 'similarity', 'two', 'words'],\n",
       " ['suggestion',\n",
       "  'discover',\n",
       "  'paradigmatic',\n",
       "  'relation',\n",
       "  'looking',\n",
       "  'similarity',\n",
       "  'context',\n",
       "  'words'],\n",
       " ['example', 'think', 'following', 'questions'],\n",
       " ['similar',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'context',\n",
       "  'dog',\n",
       "  'contrast',\n",
       "  'similar',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'context',\n",
       "  'computer',\n",
       "  'intuitively',\n",
       "  'imagine',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'context',\n",
       "  'dog',\n",
       "  'would',\n",
       "  'similar',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'context',\n",
       "  'computer'],\n",
       " ['means',\n",
       "  'first',\n",
       "  'case',\n",
       "  'similarity',\n",
       "  'value',\n",
       "  'would',\n",
       "  'high',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'second',\n",
       "  'similarity',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'computer',\n",
       "  'would',\n",
       "  'low',\n",
       "  'paradigmatic',\n",
       "  'relationship',\n",
       "  'imagine',\n",
       "  'words',\n",
       "  'occur',\n",
       "  'computer',\n",
       "  'general'],\n",
       " ['would', 'different', 'words', 'occur', 'cat'],\n",
       " ['basic', 'idea', 'covering', 'paradigmatic', 'relation'],\n",
       " ['syntagmatic',\n",
       "  'relation',\n",
       "  'well',\n",
       "  'going',\n",
       "  'explore',\n",
       "  'correlated',\n",
       "  'occurrences',\n",
       "  'based',\n",
       "  'definition',\n",
       "  'syntagmatic',\n",
       "  'relation'],\n",
       " ['see', 'sample', 'text'],\n",
       " ['interested',\n",
       "  'knowing',\n",
       "  'words',\n",
       "  'correlated',\n",
       "  'verb',\n",
       "  'eats',\n",
       "  'words',\n",
       "  'go',\n",
       "  'eats'],\n",
       " ['look',\n",
       "  'right',\n",
       "  'side',\n",
       "  'slide',\n",
       "  'see',\n",
       "  'ive',\n",
       "  'taken',\n",
       "  'away',\n",
       "  'two',\n",
       "  'words',\n",
       "  'around',\n",
       "  'eats'],\n",
       " ['ive', 'taken', 'away', 'word', 'left', 'also', 'word', 'right', 'sentence'],\n",
       " ['ask',\n",
       "  'question',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'occur',\n",
       "  'left',\n",
       "  'eats',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'occur',\n",
       "  'right',\n",
       "  'eats',\n",
       "  'thinking',\n",
       "  'question',\n",
       "  'would',\n",
       "  'help',\n",
       "  'us',\n",
       "  'discover',\n",
       "  'syntagmatic',\n",
       "  'relations',\n",
       "  'syntagmatic',\n",
       "  'relations',\n",
       "  'essentially',\n",
       "  'captures',\n",
       "  'correlations'],\n",
       " ['important',\n",
       "  'question',\n",
       "  'ask',\n",
       "  'syntagmatical',\n",
       "  'relation',\n",
       "  'whenever',\n",
       "  'eats',\n",
       "  'occurs',\n",
       "  'words',\n",
       "  'also',\n",
       "  'tend',\n",
       "  'occur',\n",
       "  'question',\n",
       "  'whether',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'cooccur',\n",
       "  'together'],\n",
       " ['meaning', 'whenever', 'see', 'eats', 'tend', 'see', 'words'],\n",
       " ['dont',\n",
       "  'see',\n",
       "  'eats',\n",
       "  'probably',\n",
       "  'dont',\n",
       "  'see',\n",
       "  'words',\n",
       "  'often',\n",
       "  'either'],\n",
       " ['intuition', 'help', 'discover', 'syntagmatic', 'relations'],\n",
       " ['consider', 'example'],\n",
       " ['helpful',\n",
       "  'occurrence',\n",
       "  'eats',\n",
       "  'predicting',\n",
       "  'occurrence',\n",
       "  'meat',\n",
       "  'right'],\n",
       " ['right',\n",
       "  'knowing',\n",
       "  'whether',\n",
       "  'eats',\n",
       "  'occurs',\n",
       "  'sentence',\n",
       "  'would',\n",
       "  'generally',\n",
       "  'help',\n",
       "  'us',\n",
       "  'predict',\n",
       "  'whether',\n",
       "  'meat',\n",
       "  'also',\n",
       "  'occurs',\n",
       "  'indeed'],\n",
       " ['see',\n",
       "  'eats',\n",
       "  'occur',\n",
       "  'sentence',\n",
       "  'increase',\n",
       "  'chance',\n",
       "  'meat',\n",
       "  'would',\n",
       "  'also',\n",
       "  'occur'],\n",
       " ['contrast',\n",
       "  'look',\n",
       "  'question',\n",
       "  'bottom',\n",
       "  'helpful',\n",
       "  'occurrence',\n",
       "  'eats',\n",
       "  'predicting',\n",
       "  'occurrence',\n",
       "  'text',\n",
       "  'eats',\n",
       "  'text',\n",
       "  'really',\n",
       "  'related',\n",
       "  'knowing',\n",
       "  'whether',\n",
       "  'eats',\n",
       "  'occurred',\n",
       "  'sentence',\n",
       "  'doesnt',\n",
       "  'really',\n",
       "  'help',\n",
       "  'us',\n",
       "  'predict',\n",
       "  'weather',\n",
       "  'text',\n",
       "  'also',\n",
       "  'occurs',\n",
       "  'sentence'],\n",
       " ['contrast', 'question', 'eats', 'meat'],\n",
       " ['also',\n",
       "  'helps',\n",
       "  'explain',\n",
       "  'intuition',\n",
       "  'behind',\n",
       "  'methods',\n",
       "  'discovering',\n",
       "  'syntagmatic',\n",
       "  'relations'],\n",
       " ['mainly', 'need', 'capture', 'correlation', 'occurrences', 'two', 'words'],\n",
       " ['summarize',\n",
       "  'general',\n",
       "  'ideas',\n",
       "  'discovering',\n",
       "  'word',\n",
       "  'associations',\n",
       "  'following'],\n",
       " ['paradigmatic', 'relation', 'present', 'word', 'context'],\n",
       " ['compute', 'context', 'similarity'],\n",
       " ['going',\n",
       "  'assume',\n",
       "  'words',\n",
       "  'high',\n",
       "  'context',\n",
       "  'similarity',\n",
       "  'paradigmatic',\n",
       "  'relation'],\n",
       " ['syntagmatic',\n",
       "  'relation',\n",
       "  'count',\n",
       "  'many',\n",
       "  'times',\n",
       "  'two',\n",
       "  'words',\n",
       "  'occur',\n",
       "  'together',\n",
       "  'context',\n",
       "  'sentence',\n",
       "  'paragraph',\n",
       "  'document',\n",
       "  'even'],\n",
       " ['going', 'compare', 'cooccurrences', 'individual', 'occurrences'],\n",
       " ['going',\n",
       "  'assume',\n",
       "  'words',\n",
       "  'high',\n",
       "  'cooccurrences',\n",
       "  'relatively',\n",
       "  'low',\n",
       "  'individual',\n",
       "  'occurrences',\n",
       "  'syntagmatic',\n",
       "  'relations',\n",
       "  'attempt',\n",
       "  'occur',\n",
       "  'together',\n",
       "  'dont',\n",
       "  'usually',\n",
       "  'occur',\n",
       "  'alone'],\n",
       " ['note',\n",
       "  'paradigmatic',\n",
       "  'relation',\n",
       "  'syntagmatic',\n",
       "  'relation',\n",
       "  'actually',\n",
       "  'closely',\n",
       "  'related',\n",
       "  'paradigmatically',\n",
       "  'related',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'syntagmatic',\n",
       "  'relation',\n",
       "  'word'],\n",
       " ['tend',\n",
       "  'associated',\n",
       "  'word',\n",
       "  'suggests',\n",
       "  'also',\n",
       "  'join',\n",
       "  'discovery',\n",
       "  'two',\n",
       "  'relations'],\n",
       " ['general', 'ideas', 'implemented', 'many', 'different', 'ways'],\n",
       " ['course',\n",
       "  'wont',\n",
       "  'cover',\n",
       "  'cover',\n",
       "  'least',\n",
       "  'methods',\n",
       "  'effective',\n",
       "  'discovering',\n",
       "  'relations'],\n",
       " ['lecture',\n",
       "  'continue',\n",
       "  'discussing',\n",
       "  'paradigmatical',\n",
       "  'relation',\n",
       "  'discovery'],\n",
       " ['earlier',\n",
       "  'introduced',\n",
       "  'method',\n",
       "  'called',\n",
       "  'expected',\n",
       "  'overlap',\n",
       "  'words',\n",
       "  'context'],\n",
       " ['method',\n",
       "  'represent',\n",
       "  'context',\n",
       "  'word',\n",
       "  'vector',\n",
       "  'represents',\n",
       "  'probability',\n",
       "  'word',\n",
       "  'context'],\n",
       " ['measure', 'similarity', 'using'],\n",
       " ['product',\n",
       "  'interpreted',\n",
       "  'probability',\n",
       "  'two',\n",
       "  'randomly',\n",
       "  'picked',\n",
       "  'words',\n",
       "  'two',\n",
       "  'contexts',\n",
       "  'identical'],\n",
       " ['also', 'discussed', 'two', 'problems', 'method'],\n",
       " ['first',\n",
       "  'favors',\n",
       "  'matching',\n",
       "  'one',\n",
       "  'frequent',\n",
       "  'term',\n",
       "  'well',\n",
       "  'matching',\n",
       "  'distinct',\n",
       "  'terms'],\n",
       " ['put', 'much', 'emphasis', 'matching', 'one', 'term', 'well'],\n",
       " ['second', 'treats', 'every', 'word', 'equally'],\n",
       " ['even',\n",
       "  'common',\n",
       "  'word',\n",
       "  'like',\n",
       "  'contribute',\n",
       "  'equally',\n",
       "  'content',\n",
       "  'word',\n",
       "  'like',\n",
       "  'eats'],\n",
       " ['going', 'talk', 'solve', 'problems'],\n",
       " ['specifically',\n",
       "  'going',\n",
       "  'introduce',\n",
       "  'retrieval',\n",
       "  'heuristics',\n",
       "  'used',\n",
       "  'text',\n",
       "  'retrieval'],\n",
       " ['heuristics',\n",
       "  'effectively',\n",
       "  'solve',\n",
       "  'problems',\n",
       "  'problems',\n",
       "  'also',\n",
       "  'occur',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'match',\n",
       "  'query',\n",
       "  'though',\n",
       "  'document',\n",
       "  'vector'],\n",
       " ['address',\n",
       "  'first',\n",
       "  'problem',\n",
       "  'use',\n",
       "  'sublinear',\n",
       "  'transformation',\n",
       "  'tone',\n",
       "  'frequency'],\n",
       " ['dont', 'use', 'raw', 'frequency', 'count', 'term', 'represent', 'context'],\n",
       " ['transform', 'form', 'wouldnt', 'emphasize', 'much', 'raw', 'frequency'],\n",
       " ['address', 'synchronous', 'problem', 'put', 'weight', 'rare', 'terms'],\n",
       " ['reward', 'matching', 'realworld'],\n",
       " ['heuristic', 'called', 'idf', 'term', 'weighting', 'text', 'retrieval'],\n",
       " ['idf', 'stands', 'inverse', 'document', 'frequency'],\n",
       " ['going', 'talk', 'two', 'heuristics', 'detail'],\n",
       " ['first', 'lets', 'talk', 'tf', 'transformation'],\n",
       " ['convert',\n",
       "  'raw',\n",
       "  'count',\n",
       "  'word',\n",
       "  'document',\n",
       "  'weight',\n",
       "  'reflects',\n",
       "  'belief',\n",
       "  'important',\n",
       "  'word',\n",
       "  'document'],\n",
       " ['denoted', 'tf', 'wd'],\n",
       " ['thats', 'shown', 'yaxis'],\n",
       " ['general', 'many', 'ways', 'map'],\n",
       " ['lets', 'first', 'look', 'simple', 'way', 'mapping'],\n",
       " ['case',\n",
       "  'going',\n",
       "  'say',\n",
       "  'well',\n",
       "  'nonzero',\n",
       "  'counts',\n",
       "  'mapped',\n",
       "  'one',\n",
       "  'zero',\n",
       "  'count',\n",
       "  'mapped',\n",
       "  'zero'],\n",
       " ['mapping', 'frequencies', 'mapped', 'two', 'values', 'zero', 'one'],\n",
       " ['mapping', 'function', 'shown', 'flat', 'line'],\n",
       " ['naive', 'frequency', 'words'],\n",
       " ['however',\n",
       "  'actually',\n",
       "  'advantage',\n",
       "  'emphasizing',\n",
       "  'matching',\n",
       "  'words',\n",
       "  'context'],\n",
       " ['allow', 'frequency', 'word', 'dominate', 'matching'],\n",
       " ['approach',\n",
       "  'taken',\n",
       "  'earlier',\n",
       "  'expected',\n",
       "  'overlap',\n",
       "  'count',\n",
       "  'approach',\n",
       "  'linear',\n",
       "  'transformation'],\n",
       " ['basically', 'take', 'x'],\n",
       " ['use', 'raw', 'count', 'representation'],\n",
       " ['created',\n",
       "  'problem',\n",
       "  'talked',\n",
       "  'namely',\n",
       "  'emphasize',\n",
       "  'much',\n",
       "  'matching',\n",
       "  'one',\n",
       "  'frequent',\n",
       "  'term'],\n",
       " ['matching', 'one', 'frequent', 'term', 'contribute', 'lot'],\n",
       " ['lot',\n",
       "  'interesting',\n",
       "  'transformations',\n",
       "  'two',\n",
       "  'extremes',\n",
       "  'generally',\n",
       "  'form',\n",
       "  'sublinear',\n",
       "  'transformation'],\n",
       " ['example',\n",
       "  'one',\n",
       "  'possibility',\n",
       "  'take',\n",
       "  'logarithm',\n",
       "  'raw',\n",
       "  'count',\n",
       "  'give',\n",
       "  'us',\n",
       "  'curve',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'seeing'],\n",
       " ['case', 'see', 'high', 'frequency', 'counts'],\n",
       " ['high',\n",
       "  'counts',\n",
       "  'penalize',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'curve',\n",
       "  'sublinear',\n",
       "  'curve',\n",
       "  'brings',\n",
       "  'weight',\n",
       "  'really',\n",
       "  'high',\n",
       "  'counts'],\n",
       " ['want', 'prevents', 'terms', 'dominating', 'scoring', 'function'],\n",
       " ['also',\n",
       "  'another',\n",
       "  'interesting',\n",
       "  'transformation',\n",
       "  'called',\n",
       "  'bm25',\n",
       "  'transformation',\n",
       "  'shown',\n",
       "  'effective',\n",
       "  'retrieval'],\n",
       " ['transformation', 'form', 'looks', 'like'],\n",
       " ['k',\n",
       "  'plus',\n",
       "  'one',\n",
       "  'multiplied',\n",
       "  'x',\n",
       "  'divided',\n",
       "  'x',\n",
       "  'plus',\n",
       "  'k',\n",
       "  'k',\n",
       "  'parameter',\n",
       "  'x',\n",
       "  'count',\n",
       "  'raw',\n",
       "  'count',\n",
       "  'word'],\n",
       " ['transformation',\n",
       "  'interesting',\n",
       "  'actually',\n",
       "  'go',\n",
       "  'one',\n",
       "  'extreme',\n",
       "  'extreme',\n",
       "  'varying',\n",
       "  'k'],\n",
       " ['also', 'interesting', 'upper', 'bound', 'k', 'plus', 'one', 'case'],\n",
       " ['puts',\n",
       "  'strict',\n",
       "  'constraint',\n",
       "  'high',\n",
       "  'frequency',\n",
       "  'terms',\n",
       "  'weight',\n",
       "  'would',\n",
       "  'never',\n",
       "  'exceed',\n",
       "  'k',\n",
       "  'plus',\n",
       "  'one'],\n",
       " ['vary', 'k', 'simulate', 'two', 'extremes'],\n",
       " ['k', 'set', 'zero', 'roughly', 'NUMBER', 'vector'],\n",
       " ['whereas',\n",
       "  'set',\n",
       "  'k',\n",
       "  'large',\n",
       "  'value',\n",
       "  'behave',\n",
       "  'like',\n",
       "  'linear',\n",
       "  'transformation'],\n",
       " ['transformation',\n",
       "  'function',\n",
       "  'far',\n",
       "  'effective',\n",
       "  'transformation',\n",
       "  'function',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'also',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  'problem',\n",
       "  'setup'],\n",
       " ['talked',\n",
       "  'solve',\n",
       "  'problem',\n",
       "  'overemphasizing',\n",
       "  'frequency',\n",
       "  'term',\n",
       "  'lets',\n",
       "  'look',\n",
       "  'second',\n",
       "  'problem',\n",
       "  'penalize',\n",
       "  'popular',\n",
       "  'terms'],\n",
       " ['matching', 'surprising', 'occurs', 'everywhere'],\n",
       " ['matching', 'eats', 'would', 'count', 'lot'],\n",
       " ['address', 'problem', 'case', 'use', 'idf', 'weighting'],\n",
       " ['thats', 'commonly', 'used', 'retrieval'],\n",
       " ['idf', 'stands', 'inverse', 'document', 'frequency'],\n",
       " ['document',\n",
       "  'frequency',\n",
       "  'means',\n",
       "  'count',\n",
       "  'total',\n",
       "  'number',\n",
       "  'documents',\n",
       "  'contain',\n",
       "  'particular',\n",
       "  'word'],\n",
       " ['show',\n",
       "  'idf',\n",
       "  'measure',\n",
       "  'defined',\n",
       "  'logarithm',\n",
       "  'function',\n",
       "  'number',\n",
       "  'documents',\n",
       "  'match',\n",
       "  'term',\n",
       "  'document',\n",
       "  'frequency'],\n",
       " ['k',\n",
       "  'number',\n",
       "  'documents',\n",
       "  'containing',\n",
       "  'word',\n",
       "  'document',\n",
       "  'frequency',\n",
       "  'total',\n",
       "  'number',\n",
       "  'documents',\n",
       "  'collection'],\n",
       " ['idf',\n",
       "  'function',\n",
       "  'giving',\n",
       "  'higher',\n",
       "  'value',\n",
       "  'lower',\n",
       "  'k',\n",
       "  'meaning',\n",
       "  'rewards',\n",
       "  'rare',\n",
       "  'term'],\n",
       " ['maximum', 'value', 'log', 'plus', 'one'],\n",
       " ['thats', 'word', 'occurred', 'context'],\n",
       " ['thats', 'rare', 'term', 'rare', 'term', 'whole', 'collection'],\n",
       " ['lowest', 'value', 'see', 'k', 'reaches', 'maximum', 'would'],\n",
       " ['would', 'low', 'value', 'close', 'zero', 'fact'],\n",
       " ['course', 'measure', 'used', 'search', 'naturally', 'collection'],\n",
       " ['case',\n",
       "  'would',\n",
       "  'collection',\n",
       "  'well',\n",
       "  'also',\n",
       "  'use',\n",
       "  'context',\n",
       "  'collect',\n",
       "  'words',\n",
       "  'collection'],\n",
       " ['say',\n",
       "  'word',\n",
       "  'thats',\n",
       "  'popular',\n",
       "  'collection',\n",
       "  'general',\n",
       "  'would',\n",
       "  'also',\n",
       "  'low',\n",
       "  'idf'],\n",
       " ['depending',\n",
       "  'dataset',\n",
       "  'construct',\n",
       "  'context',\n",
       "  'vectors',\n",
       "  'different',\n",
       "  'ways'],\n",
       " ['end',\n",
       "  'term',\n",
       "  'frequent',\n",
       "  'original',\n",
       "  'dataset',\n",
       "  'still',\n",
       "  'frequent',\n",
       "  'collective',\n",
       "  'context',\n",
       "  'documents'],\n",
       " ['add',\n",
       "  'heuristics',\n",
       "  'improve',\n",
       "  'similarity',\n",
       "  'function',\n",
       "  'well',\n",
       "  'heres',\n",
       "  'one',\n",
       "  'way',\n",
       "  'many',\n",
       "  'ways',\n",
       "  'possible'],\n",
       " ['reasonable',\n",
       "  'way',\n",
       "  'adapt',\n",
       "  'bm25',\n",
       "  'retrieval',\n",
       "  'model',\n",
       "  'paradigmatical',\n",
       "  'relation',\n",
       "  'mining'],\n",
       " ['case',\n",
       "  'define',\n",
       "  'document',\n",
       "  'vector',\n",
       "  'containing',\n",
       "  'elements',\n",
       "  'representing',\n",
       "  'normalized',\n",
       "  'bm25',\n",
       "  'values'],\n",
       " ['normalization',\n",
       "  'function',\n",
       "  'take',\n",
       "  'sum',\n",
       "  'words',\n",
       "  'normalize',\n",
       "  'weight',\n",
       "  'word',\n",
       "  'sum',\n",
       "  'weights',\n",
       "  'words'],\n",
       " ['ensure', 'xis', 'sum', 'one', 'vector'],\n",
       " ['would',\n",
       "  'similar',\n",
       "  'vector',\n",
       "  'actually',\n",
       "  'something',\n",
       "  'similar',\n",
       "  'word',\n",
       "  'distribution',\n",
       "  'xis',\n",
       "  'sum',\n",
       "  'one'],\n",
       " ['weight', 'bm25', 'word', 'defined'],\n",
       " ['compare',\n",
       "  'old',\n",
       "  'definition',\n",
       "  'normalized',\n",
       "  'count',\n",
       "  'one',\n",
       "  'right',\n",
       "  'one',\n",
       "  'document',\n",
       "  'lens',\n",
       "  'total',\n",
       "  'counts',\n",
       "  'words',\n",
       "  'context',\n",
       "  'document',\n",
       "  'thats'],\n",
       " ['bm25', 'transformation', 'introduced', 'something', 'else'],\n",
       " ['first',\n",
       "  'course',\n",
       "  'extra',\n",
       "  'occurrence',\n",
       "  'count',\n",
       "  'achieve',\n",
       "  'sublinear',\n",
       "  'normalization'],\n",
       " ['also',\n",
       "  'see',\n",
       "  'introduced',\n",
       "  'parameter',\n",
       "  'k',\n",
       "  'parameter',\n",
       "  'generally',\n",
       "  'nonactive',\n",
       "  'number',\n",
       "  'although',\n",
       "  'zero',\n",
       "  'also',\n",
       "  'possible'],\n",
       " ['controls',\n",
       "  'upper',\n",
       "  'bound',\n",
       "  'also',\n",
       "  'controls',\n",
       "  'extent',\n",
       "  'simulates',\n",
       "  'linear',\n",
       "  'transformation'],\n",
       " ['one',\n",
       "  'parameter',\n",
       "  'also',\n",
       "  'see',\n",
       "  'another',\n",
       "  'parameter',\n",
       "  'b',\n",
       "  'would',\n",
       "  'within',\n",
       "  'zero',\n",
       "  'one'],\n",
       " ['parameter', 'control', 'lens', 'normalization'],\n",
       " ['case', 'normalization', 'formula', 'average', 'document', 'lens'],\n",
       " ['computed', 'taking', 'average', 'lenses', 'documents', 'collection'],\n",
       " ['case', 'lenses', 'context', 'documents', 'considering'],\n",
       " ['average', 'documents', 'constant', 'given', 'collection'],\n",
       " ['actually', 'affecting', 'effect', 'parameter', 'b', 'constant'],\n",
       " ['kept',\n",
       "  'constant',\n",
       "  'thats',\n",
       "  'used',\n",
       "  'retrieval',\n",
       "  'would',\n",
       "  'give',\n",
       "  'us',\n",
       "  'stabilized',\n",
       "  'interpretation',\n",
       "  'parameter',\n",
       "  'b'],\n",
       " ['purpose',\n",
       "  'constant',\n",
       "  'would',\n",
       "  'affecting',\n",
       "  'lens',\n",
       "  'normalization',\n",
       "  'together',\n",
       "  'parameter',\n",
       "  'b'],\n",
       " ['definition',\n",
       "  'new',\n",
       "  'way',\n",
       "  'define',\n",
       "  'document',\n",
       "  'vectors',\n",
       "  'compute',\n",
       "  'vector',\n",
       "  'd2',\n",
       "  'way'],\n",
       " ['difference', 'highfrequency', 'terms', 'somewhat', 'lower', 'weights'],\n",
       " ['would', 'help', 'us', 'control', 'inference', 'highfrequency', 'terms'],\n",
       " ['idea', 'added', 'scoring', 'function'],\n",
       " ['means', 'well', 'introduce', 'weight', 'matching', 'term'],\n",
       " ['may',\n",
       "  'recall',\n",
       "  'sum',\n",
       "  'indicates',\n",
       "  'possible',\n",
       "  'words',\n",
       "  'overlap',\n",
       "  'two',\n",
       "  'contexts'],\n",
       " ['xi', 'yi', 'probabilities', 'picking', 'word', 'contexts'],\n",
       " ['therefore', 'indicates', 'likely', 'well', 'see', 'match', 'word'],\n",
       " ['idf', 'would', 'give', 'us', 'importance', 'matching', 'word'],\n",
       " ['common', 'word', 'worth', 'less', 'rare', 'word'],\n",
       " ['emphasize', 'matching', 'rare', 'words'],\n",
       " ['modification', 'new', 'function', 'likely', 'address', 'two', 'problems'],\n",
       " ['interestingly',\n",
       "  'also',\n",
       "  'use',\n",
       "  'approach',\n",
       "  'discover',\n",
       "  'syntagmatic',\n",
       "  'relations'],\n",
       " ['general',\n",
       "  'rebrand',\n",
       "  'context',\n",
       "  'term',\n",
       "  'vector',\n",
       "  'would',\n",
       "  'likely',\n",
       "  'see',\n",
       "  'terms',\n",
       "  'high',\n",
       "  'weights',\n",
       "  'terms',\n",
       "  'low',\n",
       "  'weights'],\n",
       " ['depending',\n",
       "  'assign',\n",
       "  'weights',\n",
       "  'terms',\n",
       "  'might',\n",
       "  'able',\n",
       "  'use',\n",
       "  'weights',\n",
       "  'discover',\n",
       "  'words',\n",
       "  'strongly',\n",
       "  'associated',\n",
       "  'candidate',\n",
       "  'word',\n",
       "  'context'],\n",
       " ['lets', 'take', 'look', 'term', 'vector', 'detail'],\n",
       " ['xi', 'defined', 'normalized', 'weight', 'bm25'],\n",
       " ['weight', 'alone', 'reflects', 'frequent', 'word', 'occurs', 'context'],\n",
       " ['cant',\n",
       "  'say',\n",
       "  'frequent',\n",
       "  'term',\n",
       "  'context',\n",
       "  'would',\n",
       "  'correlated',\n",
       "  'candidate',\n",
       "  'word',\n",
       "  'many',\n",
       "  'common',\n",
       "  'words',\n",
       "  'like',\n",
       "  'occur',\n",
       "  'frequently',\n",
       "  'context'],\n",
       " ['apply', 'idf', 'weighting', 'see', 'reweight', 'terms', 'based', 'idf'],\n",
       " ['means', 'words', 'common', 'like', 'get', 'penalized'],\n",
       " ['highest', 'weighted', 'terms', 'common', 'terms', 'lower', 'idfs'],\n",
       " ['instead',\n",
       "  'terms',\n",
       "  'would',\n",
       "  'terms',\n",
       "  'frequent',\n",
       "  'context',\n",
       "  'frequent',\n",
       "  'collection'],\n",
       " ['clearly',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'occur',\n",
       "  'context',\n",
       "  'candidate',\n",
       "  'word',\n",
       "  'example',\n",
       "  'cat'],\n",
       " ['reason',\n",
       "  'highly',\n",
       "  'weighted',\n",
       "  'terms',\n",
       "  'idea',\n",
       "  'weighted',\n",
       "  'vector',\n",
       "  'also',\n",
       "  'assumed',\n",
       "  'candidates',\n",
       "  'syntagmatic',\n",
       "  'relations'],\n",
       " ['course',\n",
       "  'byproduct',\n",
       "  'approach',\n",
       "  'discovering',\n",
       "  'paradigmatic',\n",
       "  'relations'],\n",
       " ['next', 'lecture', 'going', 'talk', 'discover', 'syntagmatic', 'relations'],\n",
       " ['clearly', 'shows', 'relation', 'discovering', 'two', 'relations'],\n",
       " ['indeed', 'discovered', 'joint', 'manner', 'leveraging', 'associations'],\n",
       " ['summarize',\n",
       "  'main',\n",
       "  'idea',\n",
       "  'discovering',\n",
       "  'paradigmatic',\n",
       "  'relations',\n",
       "  'collect',\n",
       "  'context',\n",
       "  'candidate',\n",
       "  'word',\n",
       "  'form',\n",
       "  'pseudo',\n",
       "  'document'],\n",
       " ['typically', 'represented', 'bag', 'words'],\n",
       " ['compute',\n",
       "  'similarity',\n",
       "  'corresponding',\n",
       "  'context',\n",
       "  'documents',\n",
       "  'two',\n",
       "  'candidate',\n",
       "  'words'],\n",
       " ['take',\n",
       "  'highly',\n",
       "  'similar',\n",
       "  'word',\n",
       "  'pairs',\n",
       "  'treat',\n",
       "  'paradigmatic',\n",
       "  'relations'],\n",
       " ['words', 'share', 'similar', 'contexts'],\n",
       " ['many', 'different', 'ways', 'implement', 'general', 'idea'],\n",
       " ['talked', 'approaches'],\n",
       " ['specifically',\n",
       "  'talked',\n",
       "  'using',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'models',\n",
       "  'help',\n",
       "  'us',\n",
       "  'design',\n",
       "  'effective',\n",
       "  'similarity',\n",
       "  'function',\n",
       "  'compute',\n",
       "  'paradigmatic',\n",
       "  'relations'],\n",
       " ['specifically',\n",
       "  'used',\n",
       "  'bm25',\n",
       "  'idf',\n",
       "  'weighting',\n",
       "  'discover',\n",
       "  'paradigmatic',\n",
       "  'relation'],\n",
       " ['approaches',\n",
       "  'also',\n",
       "  'represent',\n",
       "  'state',\n",
       "  'art',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'techniques'],\n",
       " ['finally',\n",
       "  'syntagmatic',\n",
       "  'relations',\n",
       "  'also',\n",
       "  'discovered',\n",
       "  'sound',\n",
       "  'looking',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'problem',\n",
       "  'closely',\n",
       "  'see',\n",
       "  'problem',\n",
       "  'similar',\n",
       "  'general',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'except',\n",
       "  'well',\n",
       "  'focusing',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['going',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'algorithms',\n",
       "  'help',\n",
       "  'us',\n",
       "  'turn',\n",
       "  'text',\n",
       "  'data',\n",
       "  'actionable',\n",
       "  'knowledge',\n",
       "  'use',\n",
       "  'real',\n",
       "  'world',\n",
       "  'especially',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'completing',\n",
       "  'whatever',\n",
       "  'tasks',\n",
       "  'require',\n",
       "  'text',\n",
       "  'data',\n",
       "  'support'],\n",
       " ['general',\n",
       "  'many',\n",
       "  'real',\n",
       "  'world',\n",
       "  'problems',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'also',\n",
       "  'tend',\n",
       "  'kinds',\n",
       "  'data',\n",
       "  'nontextual'],\n",
       " ['general', 'picture', 'would', 'include', 'nontext', 'data', 'well'],\n",
       " ['reason',\n",
       "  'might',\n",
       "  'concerned',\n",
       "  'joint',\n",
       "  'mining',\n",
       "  'text',\n",
       "  'nontext',\n",
       "  'data'],\n",
       " ['course',\n",
       "  'going',\n",
       "  'focus',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'also',\n",
       "  'going',\n",
       "  'also',\n",
       "  'touch',\n",
       "  'joint',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'data',\n",
       "  'nontext',\n",
       "  'data'],\n",
       " ['problem',\n",
       "  'definition',\n",
       "  'look',\n",
       "  'landscape',\n",
       "  'topics',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'analytics'],\n",
       " ['slide', 'shows', 'process', 'generating', 'text', 'data', 'detail'],\n",
       " ['specifically',\n",
       "  'human',\n",
       "  'sensor',\n",
       "  'human',\n",
       "  'observer',\n",
       "  'would',\n",
       "  'look',\n",
       "  'word',\n",
       "  'perspective'],\n",
       " ['different',\n",
       "  'people',\n",
       "  'would',\n",
       "  'looking',\n",
       "  'world',\n",
       "  'different',\n",
       "  'angles',\n",
       "  'theyll',\n",
       "  'pay',\n",
       "  'attention',\n",
       "  'different',\n",
       "  'things'],\n",
       " ['person',\n",
       "  'different',\n",
       "  'times',\n",
       "  'might',\n",
       "  'also',\n",
       "  'pay',\n",
       "  'attention',\n",
       "  'different',\n",
       "  'aspects',\n",
       "  'observed',\n",
       "  'world'],\n",
       " ['humans', 'able', 'perceive', 'world', 'perspective'],\n",
       " ['human', 'sensor', 'would', 'form', 'view', 'world'],\n",
       " ['called', 'observed', 'world'],\n",
       " ['course',\n",
       "  'would',\n",
       "  'different',\n",
       "  'real',\n",
       "  'world',\n",
       "  'perspective',\n",
       "  'person',\n",
       "  'taken',\n",
       "  'often',\n",
       "  'biased',\n",
       "  'also'],\n",
       " ['observed',\n",
       "  'world',\n",
       "  'represented',\n",
       "  'example',\n",
       "  'entityrelation',\n",
       "  'graphs',\n",
       "  'general',\n",
       "  'way',\n",
       "  'using',\n",
       "  'knowledge',\n",
       "  'representation',\n",
       "  'language'],\n",
       " ['general', 'basically', 'person', 'mind', 'world'],\n",
       " ['dont', 'really', 'know', 'exactly', 'looks', 'like', 'course'],\n",
       " ['human',\n",
       "  'would',\n",
       "  'express',\n",
       "  'person',\n",
       "  'observed',\n",
       "  'using',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'english'],\n",
       " ['result', 'text', 'data'],\n",
       " ['course',\n",
       "  'person',\n",
       "  'could',\n",
       "  'used',\n",
       "  'different',\n",
       "  'language',\n",
       "  'express',\n",
       "  'observed'],\n",
       " ['case',\n",
       "  'might',\n",
       "  'text',\n",
       "  'data',\n",
       "  'mixed',\n",
       "  'languages',\n",
       "  'different',\n",
       "  'languages'],\n",
       " ['main',\n",
       "  'goal',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'actually',\n",
       "  'revert',\n",
       "  'process',\n",
       "  'generating',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['hope', 'able', 'uncover', 'aspect', 'process'],\n",
       " ['specifically', 'think', 'mining', 'example', 'knowledge', 'language'],\n",
       " ['means',\n",
       "  'looking',\n",
       "  'text',\n",
       "  'data',\n",
       "  'english',\n",
       "  'may',\n",
       "  'able',\n",
       "  'discover',\n",
       "  'something',\n",
       "  'english',\n",
       "  'usage',\n",
       "  'english',\n",
       "  'patterns',\n",
       "  'english'],\n",
       " ['one',\n",
       "  'type',\n",
       "  'mining',\n",
       "  'problems',\n",
       "  'result',\n",
       "  'knowledge',\n",
       "  'language',\n",
       "  'may',\n",
       "  'useful',\n",
       "  'various',\n",
       "  'ways'],\n",
       " ['look', 'picture', 'also', 'mine', 'knowledge', 'observed', 'world'],\n",
       " ['much', 'mining', 'content', 'text', 'data'],\n",
       " ['going',\n",
       "  'look',\n",
       "  'text',\n",
       "  'data',\n",
       "  'try',\n",
       "  'get',\n",
       "  'essence',\n",
       "  'extracting',\n",
       "  'high',\n",
       "  'quality',\n",
       "  'information',\n",
       "  'particular',\n",
       "  'aspect',\n",
       "  'world',\n",
       "  'interested'],\n",
       " ['example',\n",
       "  'everything',\n",
       "  'said',\n",
       "  'particular',\n",
       "  'person',\n",
       "  'particular',\n",
       "  'entity'],\n",
       " ['regarded',\n",
       "  'mining',\n",
       "  'content',\n",
       "  'describe',\n",
       "  'observed',\n",
       "  'world',\n",
       "  'users',\n",
       "  'mind',\n",
       "  'persons',\n",
       "  'mind'],\n",
       " ['look', 'also', 'imagine', 'mine', 'knowledge', 'observer'],\n",
       " ['also', 'using', 'text', 'data', 'infer', 'properties', 'person'],\n",
       " ['properties', 'could', 'include', 'mood', 'person', 'sentiment', 'person'],\n",
       " ['note',\n",
       "  'distinguish',\n",
       "  'observed',\n",
       "  'word',\n",
       "  'person',\n",
       "  'text',\n",
       "  'data',\n",
       "  'cant',\n",
       "  'describe',\n",
       "  'person',\n",
       "  'observed',\n",
       "  'objective',\n",
       "  'way'],\n",
       " ['description',\n",
       "  'also',\n",
       "  'subjected',\n",
       "  'sentiment',\n",
       "  'general',\n",
       "  'imagine',\n",
       "  'text',\n",
       "  'data',\n",
       "  'would',\n",
       "  'contain',\n",
       "  'factual',\n",
       "  'descriptions',\n",
       "  'world',\n",
       "  'plus',\n",
       "  'subjective',\n",
       "  'comments'],\n",
       " ['thats',\n",
       "  'also',\n",
       "  'possible',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'mine',\n",
       "  'knowledge',\n",
       "  'observer'],\n",
       " ['finally',\n",
       "  'look',\n",
       "  'picture',\n",
       "  'left',\n",
       "  'side',\n",
       "  'picture',\n",
       "  'see',\n",
       "  'certainly',\n",
       "  'also',\n",
       "  'say',\n",
       "  'something',\n",
       "  'real',\n",
       "  'world'],\n",
       " ['right', 'indeed', 'text', 'mining', 'infer', 'real', 'world', 'variables'],\n",
       " ['often', 'called', 'predictive', 'analytics'],\n",
       " ['want', 'predict', 'value', 'certain', 'interesting', 'variable'],\n",
       " ['picture',\n",
       "  'basically',\n",
       "  'covered',\n",
       "  'multiple',\n",
       "  'types',\n",
       "  'knowledge',\n",
       "  'mine',\n",
       "  'text',\n",
       "  'general'],\n",
       " ['infer',\n",
       "  'real',\n",
       "  'world',\n",
       "  'variables',\n",
       "  'could',\n",
       "  'also',\n",
       "  'use',\n",
       "  'results',\n",
       "  'mining',\n",
       "  'text',\n",
       "  'data',\n",
       "  'intermediate',\n",
       "  'results',\n",
       "  'help',\n",
       "  'prediction'],\n",
       " ['example',\n",
       "  'mine',\n",
       "  'content',\n",
       "  'text',\n",
       "  'data',\n",
       "  'might',\n",
       "  'generate',\n",
       "  'summary',\n",
       "  'content'],\n",
       " ['summary',\n",
       "  'could',\n",
       "  'used',\n",
       "  'help',\n",
       "  'us',\n",
       "  'predict',\n",
       "  'variables',\n",
       "  'real',\n",
       "  'world'],\n",
       " ['course',\n",
       "  'still',\n",
       "  'generated',\n",
       "  'original',\n",
       "  'text',\n",
       "  'data',\n",
       "  'want',\n",
       "  'emphasize',\n",
       "  'often',\n",
       "  'processing',\n",
       "  'text',\n",
       "  'data',\n",
       "  'generate',\n",
       "  'features',\n",
       "  'help',\n",
       "  'prediction',\n",
       "  'important'],\n",
       " ['thats',\n",
       "  'show',\n",
       "  'results',\n",
       "  'mining',\n",
       "  'tasks',\n",
       "  'including',\n",
       "  'mining',\n",
       "  'content',\n",
       "  'text',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'knowledge',\n",
       "  'observer',\n",
       "  'helpful',\n",
       "  'prediction'],\n",
       " ['fact',\n",
       "  'nontext',\n",
       "  'data',\n",
       "  'could',\n",
       "  'also',\n",
       "  'use',\n",
       "  'nontext',\n",
       "  'data',\n",
       "  'help',\n",
       "  'prediction',\n",
       "  'course',\n",
       "  'depends',\n",
       "  'problem'],\n",
       " ['general', 'nontext', 'data', 'important', 'prediction', 'tasks'],\n",
       " ['example',\n",
       "  'want',\n",
       "  'predict',\n",
       "  'stock',\n",
       "  'prices',\n",
       "  'changes',\n",
       "  'stock',\n",
       "  'prices',\n",
       "  'based',\n",
       "  'discussion',\n",
       "  'news',\n",
       "  'articles',\n",
       "  'social',\n",
       "  'media',\n",
       "  'example',\n",
       "  'using',\n",
       "  'text',\n",
       "  'data',\n",
       "  'predict',\n",
       "  'real',\n",
       "  'world',\n",
       "  'variables'],\n",
       " ['case',\n",
       "  'obviously',\n",
       "  'historical',\n",
       "  'stock',\n",
       "  'price',\n",
       "  'data',\n",
       "  'would',\n",
       "  'important',\n",
       "  'prediction'],\n",
       " ['thats', 'example', 'nontext', 'data', 'would', 'useful', 'prediction'],\n",
       " ['going', 'combine', 'kinds', 'data', 'make', 'prediction'],\n",
       " ['nontext',\n",
       "  'data',\n",
       "  'also',\n",
       "  'used',\n",
       "  'analyzing',\n",
       "  'text',\n",
       "  'supplying',\n",
       "  'context'],\n",
       " ['look',\n",
       "  'text',\n",
       "  'data',\n",
       "  'alone',\n",
       "  'well',\n",
       "  'mostly',\n",
       "  'looking',\n",
       "  'content',\n",
       "  'andor',\n",
       "  'opinions',\n",
       "  'expressed',\n",
       "  'text'],\n",
       " ['text', 'data', 'generally', 'also', 'context', 'associated'],\n",
       " ['example', 'time', 'location', 'associated', 'text', 'data'],\n",
       " ['useful', 'context', 'information'],\n",
       " ['context', 'provide', 'interesting', 'angles', 'analyzing', 'text', 'data'],\n",
       " ['example',\n",
       "  'might',\n",
       "  'partition',\n",
       "  'text',\n",
       "  'data',\n",
       "  'different',\n",
       "  'time',\n",
       "  'periods',\n",
       "  'availability',\n",
       "  'time'],\n",
       " ['analyze', 'text', 'data', 'time', 'period', 'make', 'comparison'],\n",
       " ['similarly',\n",
       "  'partition',\n",
       "  'text',\n",
       "  'data',\n",
       "  'based',\n",
       "  'locations',\n",
       "  'meta',\n",
       "  'data',\n",
       "  'thats',\n",
       "  'associated',\n",
       "  'form',\n",
       "  'interesting',\n",
       "  'comparisons',\n",
       "  'areas'],\n",
       " ['sense',\n",
       "  'nontext',\n",
       "  'data',\n",
       "  'actually',\n",
       "  'provide',\n",
       "  'interesting',\n",
       "  'angles',\n",
       "  'perspectives',\n",
       "  'text',\n",
       "  'data',\n",
       "  'analysis'],\n",
       " ['help',\n",
       "  'us',\n",
       "  'make',\n",
       "  'contextsensitive',\n",
       "  'analysis',\n",
       "  'content',\n",
       "  'language',\n",
       "  'usage',\n",
       "  'opinions',\n",
       "  'observer',\n",
       "  'authors',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['could', 'analyze', 'sentiment', 'different', 'contexts'],\n",
       " ['fairly', 'general', 'landscape', 'topics', 'text', 'mining', 'analytics'],\n",
       " ['course', 'going', 'selectively', 'cover', 'topics'],\n",
       " ['actually', 'hope', 'cover', 'general', 'topics'],\n",
       " ['first',\n",
       "  'going',\n",
       "  'cover',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'briefly',\n",
       "  'understanding',\n",
       "  'text',\n",
       "  'data',\n",
       "  'determines',\n",
       "  'represent',\n",
       "  'text',\n",
       "  'data',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['second', 'going', 'talk', 'mine', 'word', 'associations', 'text', 'data'],\n",
       " ['word', 'associations', 'form', 'use', 'lexical', 'knowledge', 'language'],\n",
       " ['third', 'going', 'talk', 'topic', 'mining', 'analysis'],\n",
       " ['one',\n",
       "  'way',\n",
       "  'analyze',\n",
       "  'content',\n",
       "  'text',\n",
       "  'useful',\n",
       "  'ways',\n",
       "  'analyzing',\n",
       "  'content'],\n",
       " ['also', 'one', 'useful', 'techniques', 'text', 'mining'],\n",
       " ['going', 'talk', 'opinion', 'mining', 'sentiment', 'analysis'],\n",
       " ['regarded', 'one', 'example', 'mining', 'knowledge', 'observer'],\n",
       " ['finally',\n",
       "  'going',\n",
       "  'cover',\n",
       "  'textbased',\n",
       "  'prediction',\n",
       "  'problems',\n",
       "  'try',\n",
       "  'predict',\n",
       "  'real',\n",
       "  'world',\n",
       "  'variable',\n",
       "  'based',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['slide', 'also', 'serves', 'road', 'map', 'course'],\n",
       " ['going', 'use', 'outline', 'topics', 'well', 'cover', 'rest', 'course'],\n",
       " ['sound', 'lecture', 'give', 'overview', 'text', 'mining', 'analytics'],\n",
       " ['first',\n",
       "  'lets',\n",
       "  'define',\n",
       "  'term',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'term',\n",
       "  'text',\n",
       "  'analytics'],\n",
       " ['title', 'course', 'called', 'text', 'mining', 'analytics'],\n",
       " ['two',\n",
       "  'terms',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'text',\n",
       "  'analytics',\n",
       "  'actually',\n",
       "  'roughly'],\n",
       " ['really',\n",
       "  'going',\n",
       "  'really',\n",
       "  'distinguish',\n",
       "  'going',\n",
       "  'use',\n",
       "  'interchangeably'],\n",
       " ['reason',\n",
       "  'chosen',\n",
       "  'use',\n",
       "  'terms',\n",
       "  'title',\n",
       "  'also',\n",
       "  'subtle',\n",
       "  'difference',\n",
       "  'look',\n",
       "  'two',\n",
       "  'phrases',\n",
       "  'literally'],\n",
       " ['mining', 'emphasizes', 'process'],\n",
       " ['gives', 'us', 'error', 'rate', 'medical', 'view', 'problem'],\n",
       " ['analytics', 'hand', 'emphasizes', 'result', 'problem', 'mind'],\n",
       " ['going', 'look', 'text', 'data', 'help', 'us', 'solve', 'problem'],\n",
       " ['said', 'treat', 'two', 'terms', 'roughly'],\n",
       " ['think', 'literature', 'probably', 'find'],\n",
       " ['going', 'really', 'distinguish', 'course'],\n",
       " ['text',\n",
       "  'mining',\n",
       "  'text',\n",
       "  'analytics',\n",
       "  'mean',\n",
       "  'want',\n",
       "  'turn',\n",
       "  'text',\n",
       "  'data',\n",
       "  'high',\n",
       "  'quality',\n",
       "  'information',\n",
       "  'actionable',\n",
       "  'knowledge'],\n",
       " ['cases', 'problem', 'dealing', 'lot', 'text', 'data', 'hope'],\n",
       " ['turn', 'text', 'data', 'something', 'useful', 'us', 'raw', 'text', 'data'],\n",
       " ['distinguish', 'two', 'different', 'results'],\n",
       " ['one', 'highquality', 'information', 'actionable', 'knowledge'],\n",
       " ['sometimes', 'boundary', 'two', 'clear'],\n",
       " ['also',\n",
       "  'want',\n",
       "  'say',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'two',\n",
       "  'different',\n",
       "  'angles',\n",
       "  'result',\n",
       "  'text',\n",
       "  'field',\n",
       "  'mining'],\n",
       " ['case',\n",
       "  'high',\n",
       "  'quality',\n",
       "  'information',\n",
       "  'refer',\n",
       "  'concise',\n",
       "  'information',\n",
       "  'topic'],\n",
       " ['might', 'much', 'easier', 'humans', 'digest', 'raw', 'text', 'data'],\n",
       " ['example', 'might', 'face', 'lot', 'reviews', 'product'],\n",
       " ['concise',\n",
       "  'form',\n",
       "  'information',\n",
       "  'would',\n",
       "  'concise',\n",
       "  'summary',\n",
       "  'major',\n",
       "  'opinions',\n",
       "  'features',\n",
       "  'product'],\n",
       " ['positive', 'lets', 'say', 'battery', 'life', 'laptop'],\n",
       " ['kind', 'results', 'useful', 'help', 'people', 'digest', 'text', 'data'],\n",
       " ['minimize', 'human', 'effort', 'consuming', 'text', 'data', 'sense'],\n",
       " ['kind', 'output', 'actually', 'knowledge'],\n",
       " ['emphasize',\n",
       "  'utility',\n",
       "  'information',\n",
       "  'knowledge',\n",
       "  'discover',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['actionable', 'knowledge', 'decision', 'problem', 'actions', 'take'],\n",
       " ['example',\n",
       "  'might',\n",
       "  'able',\n",
       "  'determine',\n",
       "  'product',\n",
       "  'appealing',\n",
       "  'us',\n",
       "  'better',\n",
       "  'choice',\n",
       "  'shocking',\n",
       "  'decision'],\n",
       " ['outcome',\n",
       "  'could',\n",
       "  'called',\n",
       "  'actionable',\n",
       "  'knowledge',\n",
       "  'consumer',\n",
       "  'take',\n",
       "  'knowledge',\n",
       "  'make',\n",
       "  'decision',\n",
       "  'act'],\n",
       " ['case',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'supplies',\n",
       "  'knowledge',\n",
       "  'optimal',\n",
       "  'decision',\n",
       "  'making'],\n",
       " ['two',\n",
       "  'clearly',\n",
       "  'distinguished',\n",
       "  'dont',\n",
       "  'necessarily',\n",
       "  'make',\n",
       "  'distinction'],\n",
       " ['text',\n",
       "  'mining',\n",
       "  'also',\n",
       "  'related',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'essential',\n",
       "  'component',\n",
       "  'many',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'systems'],\n",
       " ['text',\n",
       "  'retrieval',\n",
       "  'refers',\n",
       "  'finding',\n",
       "  'relevant',\n",
       "  'information',\n",
       "  'large',\n",
       "  'amount',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['ive',\n",
       "  'taught',\n",
       "  'another',\n",
       "  'separate',\n",
       "  'mooc',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'search',\n",
       "  'engines'],\n",
       " ['discussed', 'various', 'techniques', 'text', 'retrieval'],\n",
       " ['taken', 'mooc', 'find', 'overlap'],\n",
       " ['useful',\n",
       "  'know',\n",
       "  'background',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'understanding',\n",
       "  'topics',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['taken',\n",
       "  'mooc',\n",
       "  'also',\n",
       "  'fine',\n",
       "  'mooc',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'analytics',\n",
       "  'going',\n",
       "  'repeat',\n",
       "  'key',\n",
       "  'concepts',\n",
       "  'relevant',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['theyre',\n",
       "  'high',\n",
       "  'level',\n",
       "  'also',\n",
       "  'explain',\n",
       "  'relation',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'text',\n",
       "  'mining'],\n",
       " ['text', 'retrieval', 'useful', 'text', 'mining', 'two', 'ways'],\n",
       " ['first', 'text', 'retrieval', 'preprocessor', 'text', 'mining'],\n",
       " ['meaning',\n",
       "  'help',\n",
       "  'us',\n",
       "  'turn',\n",
       "  'big',\n",
       "  'text',\n",
       "  'data',\n",
       "  'relatively',\n",
       "  'small',\n",
       "  'amount',\n",
       "  'relevant',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['often', 'whats', 'needed', 'solving', 'particular', 'problem'],\n",
       " ['sense',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'also',\n",
       "  'helps',\n",
       "  'minimize',\n",
       "  'human',\n",
       "  'effort'],\n",
       " ['text', 'retrieval', 'also', 'needed', 'knowledge', 'provenance'],\n",
       " ['roughly',\n",
       "  'corresponds',\n",
       "  'interpretation',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'turning',\n",
       "  'text',\n",
       "  'data',\n",
       "  'actionable',\n",
       "  'knowledge'],\n",
       " ['find',\n",
       "  'patterns',\n",
       "  'text',\n",
       "  'data',\n",
       "  'actionable',\n",
       "  'knowledge',\n",
       "  'generally',\n",
       "  'would',\n",
       "  'verify',\n",
       "  'knowledge'],\n",
       " ['looking', 'original', 'text', 'data'],\n",
       " ['users',\n",
       "  'would',\n",
       "  'text',\n",
       "  'retrieval',\n",
       "  'support',\n",
       "  'go',\n",
       "  'back',\n",
       "  'original',\n",
       "  'text',\n",
       "  'data',\n",
       "  'interpret',\n",
       "  'pattern',\n",
       "  'better',\n",
       "  'understand',\n",
       "  'analogy',\n",
       "  'verify',\n",
       "  'whether',\n",
       "  'pattern',\n",
       "  'really',\n",
       "  'reliable'],\n",
       " ['high',\n",
       "  'level',\n",
       "  'introduction',\n",
       "  'concept',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'relationship',\n",
       "  'text',\n",
       "  'mining',\n",
       "  'retrieval'],\n",
       " ['next', 'lets', 'talk', 'text', 'data', 'special', 'kind', 'data'],\n",
       " ['interesting',\n",
       "  'view',\n",
       "  'text',\n",
       "  'data',\n",
       "  'data',\n",
       "  'generated',\n",
       "  'humans',\n",
       "  'subjective',\n",
       "  'sensors'],\n",
       " ['slide', 'shows', 'analogy', 'text', 'data', 'nontext', 'data'],\n",
       " ['humans',\n",
       "  'subjective',\n",
       "  'sensors',\n",
       "  'physical',\n",
       "  'sensors',\n",
       "  'network',\n",
       "  'sensor',\n",
       "  'thermometer'],\n",
       " ['general', 'sensor', 'would', 'monitor', 'real', 'world', 'way'],\n",
       " ['would',\n",
       "  'sense',\n",
       "  'signal',\n",
       "  'real',\n",
       "  'world',\n",
       "  'would',\n",
       "  'report',\n",
       "  'signal',\n",
       "  'data',\n",
       "  'various',\n",
       "  'forms'],\n",
       " ['example',\n",
       "  'thermometer',\n",
       "  'would',\n",
       "  'watch',\n",
       "  'temperature',\n",
       "  'real',\n",
       "  'world',\n",
       "  'report',\n",
       "  'temperature',\n",
       "  'particular',\n",
       "  'format'],\n",
       " ['similarly', 'geo', 'sensor', 'would', 'sense', 'location', 'report'],\n",
       " ['location',\n",
       "  'specification',\n",
       "  'example',\n",
       "  'form',\n",
       "  'longitude',\n",
       "  'value',\n",
       "  'latitude',\n",
       "  'value'],\n",
       " ['network',\n",
       "  'sends',\n",
       "  'monitor',\n",
       "  'network',\n",
       "  'traffic',\n",
       "  'activities',\n",
       "  'network',\n",
       "  'reported'],\n",
       " ['digital', 'format', 'data'],\n",
       " ['similarly', 'think', 'humans', 'subjective', 'sensors'],\n",
       " ['observe', 'real', 'world', 'perspective'],\n",
       " ['humans', 'express', 'observed', 'form', 'text', 'data'],\n",
       " ['sense',\n",
       "  'human',\n",
       "  'actually',\n",
       "  'subjective',\n",
       "  'sensor',\n",
       "  'would',\n",
       "  'also',\n",
       "  'sense',\n",
       "  'whats',\n",
       "  'happening',\n",
       "  'world',\n",
       "  'express',\n",
       "  'whats',\n",
       "  'observed',\n",
       "  'form',\n",
       "  'data',\n",
       "  'case',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['looking',\n",
       "  'text',\n",
       "  'data',\n",
       "  'way',\n",
       "  'advantage',\n",
       "  'able',\n",
       "  'integrate',\n",
       "  'types',\n",
       "  'data',\n",
       "  'together'],\n",
       " ['thats', 'indeed', 'needed', 'data', 'mining', 'problems'],\n",
       " ['looking', 'general', 'problem', 'data', 'mining'],\n",
       " ['general', 'would', 'dealing', 'lot', 'data', 'world', 'related', 'problem'],\n",
       " ['general', 'dealing', 'nontext', 'data', 'text', 'data'],\n",
       " ['course', 'nontext', 'data', 'usually', 'produced', 'physical', 'senses'],\n",
       " ['nontext', 'data', 'also', 'different', 'formats'],\n",
       " ['numerical',\n",
       "  'data',\n",
       "  'categorical',\n",
       "  'relational',\n",
       "  'data',\n",
       "  'multimedia',\n",
       "  'data',\n",
       "  'like',\n",
       "  'video',\n",
       "  'speech'],\n",
       " ['non', 'text', 'data', 'often', 'important', 'problems'],\n",
       " ['text',\n",
       "  'data',\n",
       "  'also',\n",
       "  'important',\n",
       "  'mostly',\n",
       "  'contain',\n",
       "  'lot',\n",
       "  'symmetrical',\n",
       "  'content'],\n",
       " ['often',\n",
       "  'contain',\n",
       "  'knowledge',\n",
       "  'users',\n",
       "  'especially',\n",
       "  'preferences',\n",
       "  'opinions',\n",
       "  'users'],\n",
       " ['treating',\n",
       "  'text',\n",
       "  'data',\n",
       "  'data',\n",
       "  'observed',\n",
       "  'human',\n",
       "  'sensors',\n",
       "  'treat',\n",
       "  'data',\n",
       "  'together',\n",
       "  'framework'],\n",
       " ['data',\n",
       "  'mining',\n",
       "  'problem',\n",
       "  'basically',\n",
       "  'turn',\n",
       "  'data',\n",
       "  'turn',\n",
       "  'data',\n",
       "  'actionable',\n",
       "  'knowledge',\n",
       "  'take',\n",
       "  'advantage',\n",
       "  'change',\n",
       "  'real',\n",
       "  'world',\n",
       "  'course',\n",
       "  'better'],\n",
       " ['means',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'problem',\n",
       "  'basically',\n",
       "  'taking',\n",
       "  'lot',\n",
       "  'data',\n",
       "  'input',\n",
       "  'giving',\n",
       "  'actionable',\n",
       "  'knowledge',\n",
       "  'output'],\n",
       " ['inside',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'module',\n",
       "  'also',\n",
       "  'see',\n",
       "  'number',\n",
       "  'different',\n",
       "  'kind',\n",
       "  'mining',\n",
       "  'algorithms'],\n",
       " ['different',\n",
       "  'kinds',\n",
       "  'data',\n",
       "  'generally',\n",
       "  'need',\n",
       "  'different',\n",
       "  'algorithms',\n",
       "  'mining',\n",
       "  'data'],\n",
       " ['example',\n",
       "  'video',\n",
       "  'data',\n",
       "  'might',\n",
       "  'require',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'understand',\n",
       "  'video',\n",
       "  'content'],\n",
       " ['would', 'facilitate', 'effective', 'mining'],\n",
       " ['also',\n",
       "  'lot',\n",
       "  'general',\n",
       "  'algorithms',\n",
       "  'applicable',\n",
       "  'kinds',\n",
       "  'data',\n",
       "  'algorithms',\n",
       "  'course',\n",
       "  'useful'],\n",
       " ['although',\n",
       "  'particular',\n",
       "  'kind',\n",
       "  'data',\n",
       "  'generally',\n",
       "  'want',\n",
       "  'also',\n",
       "  'develop',\n",
       "  'special',\n",
       "  'algorithm'],\n",
       " ['course',\n",
       "  'cover',\n",
       "  'specialized',\n",
       "  'algorithms',\n",
       "  'particularly',\n",
       "  'useful',\n",
       "  'mining',\n",
       "  'text',\n",
       "  'data'],\n",
       " ['sound', 'lecture', 'paradigmatics', 'relation', 'discovery'],\n",
       " ['lecture',\n",
       "  'going',\n",
       "  'talk',\n",
       "  'discover',\n",
       "  'particular',\n",
       "  'kind',\n",
       "  'word',\n",
       "  'association',\n",
       "  'called',\n",
       "  'paradigmatical',\n",
       "  'relation'],\n",
       " ['definition',\n",
       "  'two',\n",
       "  'words',\n",
       "  'paradigmatically',\n",
       "  'related',\n",
       "  'share',\n",
       "  'similar',\n",
       "  'context'],\n",
       " ['namely', 'occur', 'similar', 'positions', 'text'],\n",
       " ['naturally',\n",
       "  'idea',\n",
       "  'discovering',\n",
       "  'relation',\n",
       "  'look',\n",
       "  'context',\n",
       "  'word',\n",
       "  'try',\n",
       "  'compute',\n",
       "  'similarity',\n",
       "  'contexts'],\n",
       " ['example', 'context', 'word', 'cat'],\n",
       " ['taken',\n",
       "  'word',\n",
       "  'cat',\n",
       "  'context',\n",
       "  'see',\n",
       "  'seeing',\n",
       "  'remaining',\n",
       "  'words',\n",
       "  'sentences',\n",
       "  'contain',\n",
       "  'cat'],\n",
       " ['thing', 'another', 'word', 'like', 'dog'],\n",
       " ['general',\n",
       "  'would',\n",
       "  'like',\n",
       "  'capture',\n",
       "  'context',\n",
       "  'try',\n",
       "  'assess',\n",
       "  'similarity',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'context',\n",
       "  'word',\n",
       "  'like',\n",
       "  'dog'],\n",
       " ['question',\n",
       "  'formally',\n",
       "  'represent',\n",
       "  'context',\n",
       "  'define',\n",
       "  'similarity',\n",
       "  'function'],\n",
       " ['first', 'note', 'context', 'actually', 'contains', 'lot', 'words'],\n",
       " ['regarded',\n",
       "  'pseudo',\n",
       "  'document',\n",
       "  'imagine',\n",
       "  'document',\n",
       "  'also',\n",
       "  'different',\n",
       "  'ways',\n",
       "  'looking',\n",
       "  'context'],\n",
       " ['example', 'look', 'word', 'occurs', 'word', 'cat'],\n",
       " ['call', 'context', 'left1', 'context'],\n",
       " ['right', 'case', 'see', 'words', 'like', 'big', 'et', 'cetera'],\n",
       " ['words', 'occur', 'left', 'word', 'cat'],\n",
       " ['say', 'cat', 'cat', 'big', 'cat', 'cat', 'et', 'cetera'],\n",
       " ['similarly', 'also', 'collect', 'words', 'occur', 'right', 'word', 'cat'],\n",
       " ['call',\n",
       "  'context',\n",
       "  'right1',\n",
       "  'see',\n",
       "  'words',\n",
       "  'like',\n",
       "  'eats',\n",
       "  'ate',\n",
       "  'et',\n",
       "  'cetera'],\n",
       " ['generally', 'look', 'words', 'window', 'text', 'around', 'word', 'cat'],\n",
       " ['lets', 'say', 'take', 'window', 'NUMBER', 'words', 'around', 'word', 'cat'],\n",
       " ['call', 'context', 'window8'],\n",
       " ['course',\n",
       "  'see',\n",
       "  'words',\n",
       "  'left',\n",
       "  'right',\n",
       "  'well',\n",
       "  'bag',\n",
       "  'words',\n",
       "  'general',\n",
       "  'represent',\n",
       "  'context'],\n",
       " ['word',\n",
       "  'based',\n",
       "  'representation',\n",
       "  'would',\n",
       "  'actually',\n",
       "  'give',\n",
       "  'us',\n",
       "  'interesting',\n",
       "  'way',\n",
       "  'define',\n",
       "  'perspective',\n",
       "  'measuring',\n",
       "  'similarity'],\n",
       " ['look',\n",
       "  'similarity',\n",
       "  'left1',\n",
       "  'well',\n",
       "  'see',\n",
       "  'words',\n",
       "  'share',\n",
       "  'words',\n",
       "  'left',\n",
       "  'context',\n",
       "  'kind',\n",
       "  'ignored',\n",
       "  'words',\n",
       "  'also',\n",
       "  'general',\n",
       "  'context'],\n",
       " ['gives',\n",
       "  'us',\n",
       "  'one',\n",
       "  'perspective',\n",
       "  'measure',\n",
       "  'similarity',\n",
       "  'similarly',\n",
       "  'use',\n",
       "  'right1',\n",
       "  'context',\n",
       "  'capture',\n",
       "  'narrative',\n",
       "  'another',\n",
       "  'perspective'],\n",
       " ['using',\n",
       "  'left1',\n",
       "  'right1',\n",
       "  'course',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'us',\n",
       "  'capture',\n",
       "  'similarity',\n",
       "  'even',\n",
       "  'strict',\n",
       "  'criteria'],\n",
       " ['general',\n",
       "  'context',\n",
       "  'may',\n",
       "  'contain',\n",
       "  'adjacent',\n",
       "  'words',\n",
       "  'like',\n",
       "  'eats',\n",
       "  'see',\n",
       "  'nonadjacent',\n",
       "  'words',\n",
       "  'like',\n",
       "  'saturday',\n",
       "  'tuesday',\n",
       "  'words',\n",
       "  'context'],\n",
       " ['flexibility',\n",
       "  'also',\n",
       "  'allows',\n",
       "  'us',\n",
       "  'match',\n",
       "  'similarity',\n",
       "  'somewhat',\n",
       "  'different',\n",
       "  'ways'],\n",
       " ['sometimes',\n",
       "  'useful',\n",
       "  'might',\n",
       "  'want',\n",
       "  'capture',\n",
       "  'similarity',\n",
       "  'base',\n",
       "  'general',\n",
       "  'content'],\n",
       " ['would', 'give', 'us', 'loosely', 'related', 'paradigmatical', 'relations'],\n",
       " ['whereas',\n",
       "  'use',\n",
       "  'words',\n",
       "  'immediately',\n",
       "  'left',\n",
       "  'right',\n",
       "  'word',\n",
       "  'likely',\n",
       "  'capture',\n",
       "  'words',\n",
       "  'much',\n",
       "  'related',\n",
       "  'syntactical',\n",
       "  'categories',\n",
       "  'semantics'],\n",
       " ['general',\n",
       "  'idea',\n",
       "  'discovering',\n",
       "  'paradigmatical',\n",
       "  'relations',\n",
       "  'compute',\n",
       "  'similarity',\n",
       "  'context',\n",
       "  'two',\n",
       "  'words'],\n",
       " ['example',\n",
       "  'measure',\n",
       "  'similarity',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'based',\n",
       "  'similarity',\n",
       "  'context'],\n",
       " ['general', 'combine', 'kinds', 'views', 'context'],\n",
       " ['similarity',\n",
       "  'function',\n",
       "  'general',\n",
       "  'combination',\n",
       "  'similarities',\n",
       "  'different',\n",
       "  'context'],\n",
       " ['course',\n",
       "  'also',\n",
       "  'assign',\n",
       "  'weights',\n",
       "  'different',\n",
       "  'similarities',\n",
       "  'allow',\n",
       "  'us',\n",
       "  'focus',\n",
       "  'particular',\n",
       "  'kind',\n",
       "  'context'],\n",
       " ['would',\n",
       "  'naturally',\n",
       "  'application',\n",
       "  'specific',\n",
       "  'main',\n",
       "  'idea',\n",
       "  'discovering',\n",
       "  'pardigmatically',\n",
       "  'related',\n",
       "  'words',\n",
       "  'computer',\n",
       "  'similarity',\n",
       "  'context'],\n",
       " ['next', 'lets', 'see', 'exactly', 'compute', 'similarity', 'functions'],\n",
       " ['answer',\n",
       "  'question',\n",
       "  'useful',\n",
       "  'think',\n",
       "  'bag',\n",
       "  'words',\n",
       "  'representation',\n",
       "  'vectors',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model'],\n",
       " ['familiar',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'textual',\n",
       "  'retrieval',\n",
       "  'techniques',\n",
       "  'would',\n",
       "  'realize',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'used',\n",
       "  'frequently',\n",
       "  'modeling',\n",
       "  'documents',\n",
       "  'queries',\n",
       "  'search'],\n",
       " ['also',\n",
       "  'find',\n",
       "  'convenient',\n",
       "  'model',\n",
       "  'context',\n",
       "  'word',\n",
       "  'paradigmatic',\n",
       "  'relation',\n",
       "  'discovery'],\n",
       " ['idea',\n",
       "  'approach',\n",
       "  'view',\n",
       "  'word',\n",
       "  'vocabulary',\n",
       "  'defining',\n",
       "  'one',\n",
       "  'dimension',\n",
       "  'high',\n",
       "  'dimensional',\n",
       "  'space'],\n",
       " ['n', 'words', 'total', 'vocabulary', 'n', 'dimensions', 'illustrated'],\n",
       " ['bottom',\n",
       "  'see',\n",
       "  'frequency',\n",
       "  'vector',\n",
       "  'representing',\n",
       "  'context',\n",
       "  'see',\n",
       "  'eats',\n",
       "  'occurred',\n",
       "  'NUMBER',\n",
       "  'times',\n",
       "  'context',\n",
       "  'ate',\n",
       "  'occurred',\n",
       "  'NUMBER',\n",
       "  'times',\n",
       "  'et',\n",
       "  'cetera'],\n",
       " ['vector', 'placed', 'vector', 'space', 'model'],\n",
       " ['general',\n",
       "  'represent',\n",
       "  'pseudo',\n",
       "  'document',\n",
       "  'context',\n",
       "  'cat',\n",
       "  'one',\n",
       "  'vector',\n",
       "  'd1',\n",
       "  'another',\n",
       "  'word',\n",
       "  'dog',\n",
       "  'might',\n",
       "  'give',\n",
       "  'us',\n",
       "  'different',\n",
       "  'context',\n",
       "  'd2'],\n",
       " ['measure', 'similarity', 'two', 'vectors'],\n",
       " ['viewing',\n",
       "  'context',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'convert',\n",
       "  'problem',\n",
       "  'paradigmatical',\n",
       "  'relation',\n",
       "  'discovery',\n",
       "  'problem',\n",
       "  'computing',\n",
       "  'vectors',\n",
       "  'similarity'],\n",
       " ['two',\n",
       "  'questions',\n",
       "  'address',\n",
       "  'first',\n",
       "  'compute',\n",
       "  'vector',\n",
       "  'compute',\n",
       "  'xi',\n",
       "  'yi'],\n",
       " ['question', 'compute', 'similarity'],\n",
       " ['general',\n",
       "  'many',\n",
       "  'approaches',\n",
       "  'used',\n",
       "  'solve',\n",
       "  'problem',\n",
       "  'developed',\n",
       "  'information',\n",
       "  'retrieval'],\n",
       " ['shown',\n",
       "  'work',\n",
       "  'well',\n",
       "  'matching',\n",
       "  'query',\n",
       "  'vector',\n",
       "  'document',\n",
       "  'vector'],\n",
       " ['adapt',\n",
       "  'many',\n",
       "  'ideas',\n",
       "  'compute',\n",
       "  'similarity',\n",
       "  'context',\n",
       "  'documents',\n",
       "  'purpose'],\n",
       " ['lets',\n",
       "  'first',\n",
       "  'look',\n",
       "  'one',\n",
       "  'plausible',\n",
       "  'approach',\n",
       "  'try',\n",
       "  'match',\n",
       "  'similarity',\n",
       "  'context',\n",
       "  'based',\n",
       "  'expected',\n",
       "  'overlap',\n",
       "  'words',\n",
       "  'call',\n",
       "  'eowc'],\n",
       " ['idea',\n",
       "  'represent',\n",
       "  'context',\n",
       "  'word',\n",
       "  'vector',\n",
       "  'word',\n",
       "  'weight',\n",
       "  'thats',\n",
       "  'equal',\n",
       "  'probability',\n",
       "  'randomly',\n",
       "  'picked',\n",
       "  'word',\n",
       "  'document',\n",
       "  'vector',\n",
       "  'word'],\n",
       " ['words',\n",
       "  'xi',\n",
       "  'defined',\n",
       "  'normalized',\n",
       "  'account',\n",
       "  'word',\n",
       "  'wi',\n",
       "  'context',\n",
       "  'interpreted',\n",
       "  'probability',\n",
       "  'would',\n",
       "  'actually',\n",
       "  'pick',\n",
       "  'word',\n",
       "  'd1',\n",
       "  'randomly',\n",
       "  'picked',\n",
       "  'word'],\n",
       " ['course',\n",
       "  'xis',\n",
       "  'would',\n",
       "  'sum',\n",
       "  'one',\n",
       "  'normalized',\n",
       "  'frequencies',\n",
       "  'means',\n",
       "  'vector',\n",
       "  'actually',\n",
       "  'probability',\n",
       "  'distribution',\n",
       "  'words'],\n",
       " ['vector',\n",
       "  'd2',\n",
       "  'also',\n",
       "  'computed',\n",
       "  'way',\n",
       "  'would',\n",
       "  'give',\n",
       "  'us',\n",
       "  'two',\n",
       "  'probability',\n",
       "  'distributions',\n",
       "  'representing',\n",
       "  'two',\n",
       "  'contexts'],\n",
       " ['addresses',\n",
       "  'problem',\n",
       "  'compute',\n",
       "  'vectors',\n",
       "  'next',\n",
       "  'lets',\n",
       "  'see',\n",
       "  'define',\n",
       "  'similarity',\n",
       "  'approach'],\n",
       " ['well',\n",
       "  'simply',\n",
       "  'define',\n",
       "  'similarity',\n",
       "  'dot',\n",
       "  'product',\n",
       "  'two',\n",
       "  'vectors',\n",
       "  'defined',\n",
       "  'sum',\n",
       "  'products',\n",
       "  'corresponding',\n",
       "  'elements',\n",
       "  'two',\n",
       "  'vectors'],\n",
       " ['interesting',\n",
       "  'see',\n",
       "  'similarity',\n",
       "  'function',\n",
       "  'actually',\n",
       "  'nice',\n",
       "  'interpretation'],\n",
       " ['dot',\n",
       "  'product',\n",
       "  'fact',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'probability',\n",
       "  'two',\n",
       "  'randomly',\n",
       "  'picked',\n",
       "  'words',\n",
       "  'two',\n",
       "  'contexts',\n",
       "  'identical'],\n",
       " ['means',\n",
       "  'try',\n",
       "  'pick',\n",
       "  'word',\n",
       "  'one',\n",
       "  'context',\n",
       "  'try',\n",
       "  'pick',\n",
       "  'another',\n",
       "  'word',\n",
       "  'another',\n",
       "  'context',\n",
       "  'ask',\n",
       "  'question',\n",
       "  'identical',\n",
       "  'two',\n",
       "  'contexts',\n",
       "  'similar',\n",
       "  'expect',\n",
       "  'frequently',\n",
       "  'see',\n",
       "  'two',\n",
       "  'words',\n",
       "  'picked',\n",
       "  'two',\n",
       "  'contexts',\n",
       "  'identical'],\n",
       " ['different',\n",
       "  'chance',\n",
       "  'seeing',\n",
       "  'identical',\n",
       "  'words',\n",
       "  'picked',\n",
       "  'two',\n",
       "  'contexts',\n",
       "  'would',\n",
       "  'small'],\n",
       " ['intuitively',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  'right',\n",
       "  'measuring',\n",
       "  'similarity',\n",
       "  'contexts'],\n",
       " ['might',\n",
       "  'want',\n",
       "  'also',\n",
       "  'take',\n",
       "  'look',\n",
       "  'exact',\n",
       "  'formulas',\n",
       "  'see',\n",
       "  'interpreted',\n",
       "  'probability',\n",
       "  'two',\n",
       "  'randomly',\n",
       "  'picked',\n",
       "  'words',\n",
       "  'identical'],\n",
       " ['stare',\n",
       "  'formula',\n",
       "  'check',\n",
       "  'whats',\n",
       "  'inside',\n",
       "  'sum',\n",
       "  'see',\n",
       "  'basically',\n",
       "  'case',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'probability',\n",
       "  'see',\n",
       "  'overlap',\n",
       "  'particular',\n",
       "  'word',\n",
       "  'wi'],\n",
       " ['xi',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'probability',\n",
       "  'pick',\n",
       "  'particular',\n",
       "  'word',\n",
       "  'd1',\n",
       "  'yi',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'probability',\n",
       "  'picking',\n",
       "  'word',\n",
       "  'd2'],\n",
       " ['pick', 'word', 'two', 'contexts', 'identical', 'pick', 'right'],\n",
       " ['thats',\n",
       "  'one',\n",
       "  'possible',\n",
       "  'approach',\n",
       "  'eowc',\n",
       "  'extracted',\n",
       "  'overlap',\n",
       "  'words',\n",
       "  'context'],\n",
       " ['always',\n",
       "  'would',\n",
       "  'like',\n",
       "  'assess',\n",
       "  'whether',\n",
       "  'approach',\n",
       "  'would',\n",
       "  'work',\n",
       "  'well'],\n",
       " ['course',\n",
       "  'ultimately',\n",
       "  'test',\n",
       "  'approach',\n",
       "  'real',\n",
       "  'data',\n",
       "  'see',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'really',\n",
       "  'semantically',\n",
       "  'related',\n",
       "  'words'],\n",
       " ['really',\n",
       "  'give',\n",
       "  'us',\n",
       "  'paradigmatical',\n",
       "  'relations',\n",
       "  'analytically',\n",
       "  'also',\n",
       "  'analyze',\n",
       "  'formula',\n",
       "  'little',\n",
       "  'bit'],\n",
       " ['first',\n",
       "  'said',\n",
       "  'make',\n",
       "  'sense',\n",
       "  'right',\n",
       "  'formula',\n",
       "  'give',\n",
       "  'higher',\n",
       "  'score',\n",
       "  'overlap',\n",
       "  'two',\n",
       "  'contexts'],\n",
       " ['thats', 'exactly', 'want'],\n",
       " ['analyze',\n",
       "  'formula',\n",
       "  'carefully',\n",
       "  'also',\n",
       "  'see',\n",
       "  'might',\n",
       "  'potential',\n",
       "  'problems',\n",
       "  'specifically',\n",
       "  'two',\n",
       "  'potential',\n",
       "  'problems'],\n",
       " ['first',\n",
       "  'might',\n",
       "  'favor',\n",
       "  'matching',\n",
       "  'one',\n",
       "  'frequent',\n",
       "  'term',\n",
       "  'well',\n",
       "  'matching',\n",
       "  'distinct',\n",
       "  'terms'],\n",
       " ['dot',\n",
       "  'product',\n",
       "  'one',\n",
       "  'element',\n",
       "  'high',\n",
       "  'value',\n",
       "  'element',\n",
       "  'shared',\n",
       "  'contexts',\n",
       "  'contributes',\n",
       "  'lot',\n",
       "  'overall',\n",
       "  'sum',\n",
       "  'might',\n",
       "  'indeed',\n",
       "  'make',\n",
       "  'score',\n",
       "  'higher',\n",
       "  'another',\n",
       "  'case',\n",
       "  'two',\n",
       "  'vectors',\n",
       "  'actually',\n",
       "  'lot',\n",
       "  'overlap',\n",
       "  'different',\n",
       "  'terms'],\n",
       " ['term', 'relatively', 'low', 'frequency', 'may', 'desirable'],\n",
       " ['course', 'might', 'desirable', 'cases'],\n",
       " ['case',\n",
       "  'intuitively',\n",
       "  'prefer',\n",
       "  'case',\n",
       "  'match',\n",
       "  'different',\n",
       "  'terms',\n",
       "  'context',\n",
       "  'confidence',\n",
       "  'saying',\n",
       "  'two',\n",
       "  'words',\n",
       "  'indeed',\n",
       "  'occur',\n",
       "  'similar',\n",
       "  'context'],\n",
       " ['rely',\n",
       "  'one',\n",
       "  'term',\n",
       "  'thats',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'questionable',\n",
       "  'may',\n",
       "  'robust'],\n",
       " ['second', 'problem', 'treats', 'every', 'word', 'equally', 'right'],\n",
       " ['match',\n",
       "  'word',\n",
       "  'like',\n",
       "  'matching',\n",
       "  'word',\n",
       "  'like',\n",
       "  'eats',\n",
       "  'intuitively',\n",
       "  'know',\n",
       "  'matching',\n",
       "  'isnt',\n",
       "  'really',\n",
       "  'surprising',\n",
       "  'occurs',\n",
       "  'everywhere'],\n",
       " ['matching',\n",
       "  'strong',\n",
       "  'evidence',\n",
       "  'matching',\n",
       "  'word',\n",
       "  'like',\n",
       "  'eats',\n",
       "  'doesnt',\n",
       "  'occur',\n",
       "  'frequently'],\n",
       " ['another', 'problem', 'approach'],\n",
       " ['next', 'chapter', 'going', 'talk', 'address', 'problems'],\n",
       " ['sound',\n",
       "  'lecture',\n",
       "  'going',\n",
       "  'talk',\n",
       "  'improve',\n",
       "  'instantiation',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model'],\n",
       " ['continued', 'discussion', 'vector', 'space', 'model'],\n",
       " ['going', 'focus', 'improve', 'instantiation', 'model'],\n",
       " ['previous',\n",
       "  'lecture',\n",
       "  'seen',\n",
       "  'simple',\n",
       "  'instantiations',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'come',\n",
       "  'simple',\n",
       "  'scoring',\n",
       "  'function',\n",
       "  'would',\n",
       "  'give',\n",
       "  'us',\n",
       "  'basically',\n",
       "  'account',\n",
       "  'many',\n",
       "  'unique',\n",
       "  'query',\n",
       "  'terms',\n",
       "  'matched',\n",
       "  'document'],\n",
       " ['also', 'seen', 'function', 'problem', 'shown', 'slide'],\n",
       " ['particular',\n",
       "  'look',\n",
       "  'three',\n",
       "  'documents',\n",
       "  'get',\n",
       "  'score',\n",
       "  'match',\n",
       "  'three',\n",
       "  'unique',\n",
       "  'query',\n",
       "  'words'],\n",
       " ['intuitively',\n",
       "  'would',\n",
       "  'like',\n",
       "  'd4',\n",
       "  'ranked',\n",
       "  'd3',\n",
       "  'd2',\n",
       "  'really',\n",
       "  'relevant'],\n",
       " ['problem', 'function', 'couldnt', 'capture', 'following', 'heuristics'],\n",
       " ['first',\n",
       "  'would',\n",
       "  'like',\n",
       "  'give',\n",
       "  'credit',\n",
       "  'd4',\n",
       "  'matched',\n",
       "  'presidential',\n",
       "  'times',\n",
       "  'd3'],\n",
       " ['second',\n",
       "  'intuitively',\n",
       "  'matching',\n",
       "  'presidential',\n",
       "  'important',\n",
       "  'matching',\n",
       "  'common',\n",
       "  'word',\n",
       "  'occurs',\n",
       "  'everywhere'],\n",
       " ['doesnt', 'really', 'carry', 'much', 'content'],\n",
       " ['lecture', 'lets', 'see', 'improve', 'model', 'solve', 'two', 'problems'],\n",
       " ['worth',\n",
       "  'thinking',\n",
       "  'point',\n",
       "  'problems',\n",
       "  'look',\n",
       "  'back',\n",
       "  'assumptions',\n",
       "  'made',\n",
       "  'instantiating',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'well',\n",
       "  'realize',\n",
       "  'problem',\n",
       "  'really',\n",
       "  'coming',\n",
       "  'assumptions'],\n",
       " ['particular', 'placed', 'vectors', 'vector', 'space'],\n",
       " ['naturally', 'order', 'fix', 'problems', 'revisit', 'assumptions'],\n",
       " ['perhaps',\n",
       "  'use',\n",
       "  'different',\n",
       "  'ways',\n",
       "  'instantiate',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model'],\n",
       " ['particular', 'place', 'vectors', 'different', 'way'],\n",
       " ['lets', 'see', 'improve'],\n",
       " ['one',\n",
       "  'natural',\n",
       "  'thought',\n",
       "  'order',\n",
       "  'consider',\n",
       "  'multiple',\n",
       "  'times',\n",
       "  'term',\n",
       "  'document',\n",
       "  'consider',\n",
       "  'term',\n",
       "  'frequency',\n",
       "  'instead',\n",
       "  'absence',\n",
       "  'presence'],\n",
       " ['order',\n",
       "  'consider',\n",
       "  'difference',\n",
       "  'document',\n",
       "  'query',\n",
       "  'term',\n",
       "  'occurred',\n",
       "  'multiple',\n",
       "  'times',\n",
       "  'one',\n",
       "  'query',\n",
       "  'term',\n",
       "  'occurred',\n",
       "  'consider',\n",
       "  'term',\n",
       "  'frequency',\n",
       "  'count',\n",
       "  'term',\n",
       "  'document'],\n",
       " ['simplest', 'model', 'modeled', 'presence', 'absence', 'term'],\n",
       " ['ignored', 'actual', 'number', 'times', 'term', 'occurs', 'document'],\n",
       " ['lets', 'add', 'back'],\n",
       " ['going', 'represent', 'document', 'vector', 'term', 'frequency', 'element'],\n",
       " ['say',\n",
       "  'elements',\n",
       "  'query',\n",
       "  'vector',\n",
       "  'document',\n",
       "  'vector',\n",
       "  'NUMBER',\n",
       "  'NUMBER',\n",
       "  'instead',\n",
       "  'counts',\n",
       "  'word',\n",
       "  'query',\n",
       "  'document'],\n",
       " ['would',\n",
       "  'bring',\n",
       "  'additional',\n",
       "  'information',\n",
       "  'document',\n",
       "  'seen',\n",
       "  'accurate',\n",
       "  'representation',\n",
       "  'documents'],\n",
       " ['lets',\n",
       "  'see',\n",
       "  'formula',\n",
       "  'would',\n",
       "  'look',\n",
       "  'like',\n",
       "  'change',\n",
       "  'representation'],\n",
       " ['youll', 'see', 'slide', 'still', 'use', 'dot', 'product'],\n",
       " ['formula', 'looks', 'similar', 'form'],\n",
       " ['fact', 'looks', 'identical'],\n",
       " ['inside', 'sum', 'course', 'x', 'different'],\n",
       " ['counts', 'word', 'query', 'document'],\n",
       " ['point',\n",
       "  'also',\n",
       "  'suggest',\n",
       "  'pause',\n",
       "  'lecture',\n",
       "  'moment',\n",
       "  'think',\n",
       "  'interpret',\n",
       "  'score',\n",
       "  'new',\n",
       "  'function'],\n",
       " ['something', 'similar', 'simplest', 'vsm'],\n",
       " ['change', 'vector', 'new', 'score', 'different', 'interpretation'],\n",
       " ['see',\n",
       "  'difference',\n",
       "  'consideration',\n",
       "  'multiple',\n",
       "  'occurrences',\n",
       "  'term',\n",
       "  'document'],\n",
       " ['importantly',\n",
       "  'would',\n",
       "  'like',\n",
       "  'know',\n",
       "  'whether',\n",
       "  'would',\n",
       "  'fix',\n",
       "  'problems',\n",
       "  'simplest',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model'],\n",
       " ['lets', 'look', 'example'],\n",
       " ['suppose',\n",
       "  'change',\n",
       "  'vector',\n",
       "  'representation',\n",
       "  'term',\n",
       "  'frequency',\n",
       "  'vectors'],\n",
       " ['lets', 'look', 'three', 'documents'],\n",
       " ['query', 'vector', 'words', 'occurred', 'exactly', 'query'],\n",
       " ['vector', 'still', 'NUMBER', 'vector'],\n",
       " ['fact',\n",
       "  'd2',\n",
       "  'also',\n",
       "  'essentially',\n",
       "  'representing',\n",
       "  'way',\n",
       "  'none',\n",
       "  'words',\n",
       "  'repeated',\n",
       "  'many',\n",
       "  'times'],\n",
       " ['result', 'score', 'also', 'still', 'NUMBER'],\n",
       " ['true', 'd3', 'still', 'NUMBER'],\n",
       " ['d4', 'would', 'different', 'presidential', 'occurred', 'twice'],\n",
       " ['ending',\n",
       "  'presidential',\n",
       "  'document',\n",
       "  'vector',\n",
       "  'would',\n",
       "  'NUMBER',\n",
       "  'instead',\n",
       "  'NUMBER'],\n",
       " ['result', 'score', 'd4', 'higher'],\n",
       " ['NUMBER'],\n",
       " ['means', 'using', 'term', 'frequency', 'rank', 'd4', 'd2', 'd3', 'hoped'],\n",
       " ['solved', 'problem', 'd4'],\n",
       " ['also', 'see', 'd2', 'd3', 'still', 'filtering', 'way'],\n",
       " ['still', 'identical', 'scores', 'fix', 'problem'],\n",
       " ['fix',\n",
       "  'problem',\n",
       "  'intuitively',\n",
       "  'would',\n",
       "  'like',\n",
       "  'give',\n",
       "  'credit',\n",
       "  'matching',\n",
       "  'presidential',\n",
       "  'matching'],\n",
       " ['solve',\n",
       "  'problem',\n",
       "  'general',\n",
       "  'way',\n",
       "  'way',\n",
       "  'determine',\n",
       "  'word',\n",
       "  'treated',\n",
       "  'importantly',\n",
       "  'word',\n",
       "  'basically',\n",
       "  'ignored',\n",
       "  'word',\n",
       "  'really',\n",
       "  'carry',\n",
       "  'much',\n",
       "  'content'],\n",
       " ['essentially', 'ignore'],\n",
       " ['sometimes', 'call', 'word', 'stock', 'word'],\n",
       " ['generally', 'frequent', 'occur', 'everywhere'],\n",
       " ['matching', 'doesnt', 'really', 'mean', 'anything'],\n",
       " ['computationally', 'capture', 'encourage', 'think', 'little', 'bit'],\n",
       " ['came',\n",
       "  'statistical',\n",
       "  'approaches',\n",
       "  'somehow',\n",
       "  'distinguish',\n",
       "  'presidential',\n",
       "  'think',\n",
       "  'moment',\n",
       "  'youll',\n",
       "  'realize',\n",
       "  'one',\n",
       "  'difference',\n",
       "  'word',\n",
       "  'like',\n",
       "  'occurs',\n",
       "  'everywhere'],\n",
       " ['count',\n",
       "  'occurrence',\n",
       "  'word',\n",
       "  'whole',\n",
       "  'collection',\n",
       "  'see',\n",
       "  'much',\n",
       "  'higher',\n",
       "  'frequency',\n",
       "  'presidential',\n",
       "  'tends',\n",
       "  'occur',\n",
       "  'documents'],\n",
       " ['idea',\n",
       "  'suggests',\n",
       "  'could',\n",
       "  'somehow',\n",
       "  'use',\n",
       "  'global',\n",
       "  'statistics',\n",
       "  'terms',\n",
       "  'information',\n",
       "  'trying',\n",
       "  'downweight',\n",
       "  'element',\n",
       "  'vector',\n",
       "  'representation',\n",
       "  'd2'],\n",
       " ['time',\n",
       "  'hope',\n",
       "  'somehow',\n",
       "  'increase',\n",
       "  'weight',\n",
       "  'presidential',\n",
       "  'vector',\n",
       "  'd3'],\n",
       " ['expect',\n",
       "  'd2',\n",
       "  'get',\n",
       "  'overall',\n",
       "  'score',\n",
       "  'less',\n",
       "  'NUMBER',\n",
       "  'd3',\n",
       "  'get',\n",
       "  'score',\n",
       "  'NUMBER'],\n",
       " ['would', 'able', 'rank', 'd3', 'top', 'd2'],\n",
       " ['systematically', 'rely', 'statistical', 'count'],\n",
       " ['case', 'particular', 'idea', 'called', 'inverse', 'document', 'frequency'],\n",
       " ['seen',\n",
       "  'document',\n",
       "  'frequency',\n",
       "  'one',\n",
       "  'signal',\n",
       "  'used',\n",
       "  'modern',\n",
       "  'retrieval',\n",
       "  'functions'],\n",
       " ['discussed', 'previous', 'lecture'],\n",
       " ['specific', 'way', 'using'],\n",
       " ['document',\n",
       "  'frequency',\n",
       "  'count',\n",
       "  'documents',\n",
       "  'contain',\n",
       "  'particular',\n",
       "  'term'],\n",
       " ['say',\n",
       "  'inverse',\n",
       "  'document',\n",
       "  'frequency',\n",
       "  'actually',\n",
       "  'want',\n",
       "  'reward',\n",
       "  'word',\n",
       "  'doesnt',\n",
       "  'occur',\n",
       "  'many',\n",
       "  'documents'],\n",
       " ['way',\n",
       "  'incorporate',\n",
       "  'vector',\n",
       "  'representation',\n",
       "  'modify',\n",
       "  'frequency',\n",
       "  'count',\n",
       "  'multiplying',\n",
       "  'idf',\n",
       "  'corresponding',\n",
       "  'word',\n",
       "  'shown'],\n",
       " ['penalize',\n",
       "  'common',\n",
       "  'words',\n",
       "  'generally',\n",
       "  'lower',\n",
       "  'idf',\n",
       "  'reward',\n",
       "  'rare',\n",
       "  'words',\n",
       "  'higher',\n",
       "  'idf'],\n",
       " ['specifically',\n",
       "  'idf',\n",
       "  'defined',\n",
       "  'logarithm',\n",
       "  'm1',\n",
       "  'divided',\n",
       "  'k',\n",
       "  'total',\n",
       "  'number',\n",
       "  'documents',\n",
       "  'collection',\n",
       "  'k',\n",
       "  'df',\n",
       "  'document',\n",
       "  'frequency',\n",
       "  'total',\n",
       "  'number',\n",
       "  'documents',\n",
       "  'containing',\n",
       "  'word',\n",
       "  'w'],\n",
       " ['plot',\n",
       "  'function',\n",
       "  'varying',\n",
       "  'k',\n",
       "  'would',\n",
       "  'see',\n",
       "  'curve',\n",
       "  'would',\n",
       "  'look',\n",
       "  'like'],\n",
       " ['general',\n",
       "  'see',\n",
       "  'would',\n",
       "  'give',\n",
       "  'higher',\n",
       "  'value',\n",
       "  'low',\n",
       "  'df',\n",
       "  'word',\n",
       "  'rare',\n",
       "  'word'],\n",
       " ['also', 'see', 'maximum', 'value', 'function', 'log', 'm1'],\n",
       " ['would', 'interesting', 'think', 'whats', 'minimum', 'value', 'function'],\n",
       " ['could', 'interesting', 'exercise'],\n",
       " ['specific',\n",
       "  'function',\n",
       "  'may',\n",
       "  'important',\n",
       "  'heuristic',\n",
       "  'simply',\n",
       "  'penalize',\n",
       "  'popular',\n",
       "  'terms'],\n",
       " ['turns', 'particular', 'function', 'form', 'also', 'worked', 'well'],\n",
       " ['whether',\n",
       "  'theres',\n",
       "  'better',\n",
       "  'form',\n",
       "  'function',\n",
       "  'open',\n",
       "  'research',\n",
       "  'question'],\n",
       " ['also',\n",
       "  'clear',\n",
       "  'use',\n",
       "  'linear',\n",
       "  'penalization',\n",
       "  'like',\n",
       "  'whats',\n",
       "  'shown',\n",
       "  'line',\n",
       "  'may',\n",
       "  'reasonable',\n",
       "  'standard',\n",
       "  'idf'],\n",
       " ['particular',\n",
       "  'see',\n",
       "  'difference',\n",
       "  'standard',\n",
       "  'idf',\n",
       "  'somehow',\n",
       "  'turning',\n",
       "  'point'],\n",
       " ['point', 'going', 'say', 'terms', 'essentially', 'useful'],\n",
       " ['essentially', 'ignored'],\n",
       " ['makes',\n",
       "  'sense',\n",
       "  'term',\n",
       "  'occurs',\n",
       "  'frequently',\n",
       "  'lets',\n",
       "  'say',\n",
       "  'term',\n",
       "  'occurs',\n",
       "  'NUMBER',\n",
       "  'documents',\n",
       "  'term',\n",
       "  'unlikely',\n",
       "  'important',\n",
       "  'basically',\n",
       "  'common',\n",
       "  'term'],\n",
       " ['important', 'match', 'word'],\n",
       " ['standard', 'idf', 'see', 'basically', 'assumed', 'low', 'weights'],\n",
       " ['theres', 'difference'],\n",
       " ['look', 'linear', 'penalization', 'point', 'still', 'difference'],\n",
       " ['intuitively',\n",
       "  'wed',\n",
       "  'want',\n",
       "  'focus',\n",
       "  'discrimination',\n",
       "  'low',\n",
       "  'df',\n",
       "  'words',\n",
       "  'rather',\n",
       "  'common',\n",
       "  'words'],\n",
       " ['well',\n",
       "  'course',\n",
       "  'one',\n",
       "  'works',\n",
       "  'better',\n",
       "  'still',\n",
       "  'validated',\n",
       "  'using',\n",
       "  'empirically',\n",
       "  'correlated',\n",
       "  'dataset'],\n",
       " ['use', 'users', 'judge', 'results', 'better'],\n",
       " ['lets', 'see', 'solve', 'problem', 'NUMBER'],\n",
       " ['lets', 'look', 'two', 'documents'],\n",
       " ['without', 'idf', 'weighting', 'term', 'frequency', 'vectors'],\n",
       " ['idf', 'weighting', 'adjust', 'tf', 'weight', 'multiplying', 'idf', 'value'],\n",
       " ['example',\n",
       "  'see',\n",
       "  'adjustment',\n",
       "  'particular',\n",
       "  'theres',\n",
       "  'adjustment',\n",
       "  'using',\n",
       "  'idf',\n",
       "  'value',\n",
       "  'smaller',\n",
       "  'idf',\n",
       "  'value',\n",
       "  'presidential'],\n",
       " ['look', 'idf', 'distinguish', 'two', 'words'],\n",
       " ['result',\n",
       "  'adjustment',\n",
       "  'would',\n",
       "  'larger',\n",
       "  'would',\n",
       "  'make',\n",
       "  'weight',\n",
       "  'larger'],\n",
       " ['score',\n",
       "  'new',\n",
       "  'vectors',\n",
       "  'would',\n",
       "  'happen',\n",
       "  'course',\n",
       "  'share',\n",
       "  'weights',\n",
       "  'news',\n",
       "  'campaign',\n",
       "  'matching',\n",
       "  'discriminate'],\n",
       " ['result',\n",
       "  'idf',\n",
       "  'weighting',\n",
       "  'd3',\n",
       "  'ranked',\n",
       "  'd2',\n",
       "  'matched',\n",
       "  'rare',\n",
       "  'word',\n",
       "  'whereas',\n",
       "  'd2',\n",
       "  'matched',\n",
       "  'common',\n",
       "  'word'],\n",
       " ['shows', 'idf', 'weighting', 'solve', 'problem', 'NUMBER'],\n",
       " ['effective',\n",
       "  'model',\n",
       "  'general',\n",
       "  'used',\n",
       "  'tfidf',\n",
       "  'weighting',\n",
       "  'well',\n",
       "  'lets',\n",
       "  'look',\n",
       "  'documents',\n",
       "  'seen'],\n",
       " ['new', 'scores', 'new', 'documents'],\n",
       " ['effective',\n",
       "  'new',\n",
       "  'weighting',\n",
       "  'method',\n",
       "  'new',\n",
       "  'scoring',\n",
       "  'function',\n",
       "  'point',\n",
       "  'lets',\n",
       "  'see',\n",
       "  'overall',\n",
       "  'effective',\n",
       "  'new',\n",
       "  'ranking',\n",
       "  'function',\n",
       "  'tfidf',\n",
       "  'weighting'],\n",
       " ['show', 'five', 'documents', 'seen', 'scores'],\n",
       " ['see',\n",
       "  'scores',\n",
       "  'first',\n",
       "  'four',\n",
       "  'documents',\n",
       "  'seem',\n",
       "  'quite',\n",
       "  'reasonable'],\n",
       " ['expected'],\n",
       " ['however',\n",
       "  'also',\n",
       "  'see',\n",
       "  'new',\n",
       "  'problem',\n",
       "  'd5',\n",
       "  'high',\n",
       "  'score',\n",
       "  'simplest',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'actually',\n",
       "  'high',\n",
       "  'score'],\n",
       " ['fact', 'highest', 'score'],\n",
       " ['creates', 'new', 'problem'],\n",
       " ['actually', 'common', 'phenomenon', 'designing', 'retrieval', 'functions'],\n",
       " ['basically',\n",
       "  'try',\n",
       "  'fix',\n",
       "  'one',\n",
       "  'problem',\n",
       "  'tend',\n",
       "  'introduce',\n",
       "  'problems'],\n",
       " ['thats', 'tricky', 'design', 'effective', 'ranking', 'function'],\n",
       " ['whats', 'best', 'ranking', 'function', 'open', 'research', 'question'],\n",
       " ['researchers', 'still', 'working'],\n",
       " ['next',\n",
       "  'lectures',\n",
       "  'going',\n",
       "  'also',\n",
       "  'talk',\n",
       "  'additional',\n",
       "  'ideas',\n",
       "  'improve',\n",
       "  'model',\n",
       "  'try',\n",
       "  'fix',\n",
       "  'problem'],\n",
       " ['summarize',\n",
       "  'lecture',\n",
       "  'weve',\n",
       "  'talked',\n",
       "  'improve',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'weve',\n",
       "  'got',\n",
       "  'improve',\n",
       "  'instantiation',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'based',\n",
       "  'tdidf',\n",
       "  'weighting'],\n",
       " ['improvement',\n",
       "  'mostly',\n",
       "  'placement',\n",
       "  'vector',\n",
       "  'give',\n",
       "  'high',\n",
       "  'weight',\n",
       "  'term',\n",
       "  'occurred',\n",
       "  'many',\n",
       "  'times',\n",
       "  'document',\n",
       "  'infrequently',\n",
       "  'whole',\n",
       "  'collection'],\n",
       " ['seen',\n",
       "  'improved',\n",
       "  'model',\n",
       "  'indeed',\n",
       "  'looks',\n",
       "  'better',\n",
       "  'simplest',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model'],\n",
       " ['also', 'still', 'problems'],\n",
       " ['next', 'lecture', 'going', 'look', 'address', 'additional', 'problems'],\n",
       " ['sound',\n",
       "  'lecture',\n",
       "  'document',\n",
       "  'length',\n",
       "  'normalization',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model'],\n",
       " ['lecture', 'continue', 'discussion', 'vector', 'space', 'model'],\n",
       " ['particular',\n",
       "  'going',\n",
       "  'discuss',\n",
       "  'issue',\n",
       "  'document',\n",
       "  'length',\n",
       "  'normalization'],\n",
       " ['far',\n",
       "  'lectures',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'used',\n",
       "  'various',\n",
       "  'signals',\n",
       "  'document',\n",
       "  'assess',\n",
       "  'matching',\n",
       "  'document',\n",
       "  'query'],\n",
       " ['particular', 'considered', 'tone', 'frequency'],\n",
       " ['count', 'tone', 'document'],\n",
       " ['also',\n",
       "  'considered',\n",
       "  'global',\n",
       "  'statistics',\n",
       "  'idf',\n",
       "  'inverse',\n",
       "  'document',\n",
       "  'frequency'],\n",
       " ['considered', 'document', 'lengths'],\n",
       " ['show',\n",
       "  'two',\n",
       "  'example',\n",
       "  'documents',\n",
       "  'd4',\n",
       "  'much',\n",
       "  'shorter',\n",
       "  'NUMBER',\n",
       "  'words'],\n",
       " ['d6', 'hand', 'NUMBER', 'words'],\n",
       " ['look',\n",
       "  'matching',\n",
       "  'query',\n",
       "  'words',\n",
       "  'see',\n",
       "  'd6',\n",
       "  'matchings',\n",
       "  'query',\n",
       "  'words'],\n",
       " ['one',\n",
       "  'might',\n",
       "  'reason',\n",
       "  'd6',\n",
       "  'may',\n",
       "  'matched',\n",
       "  'query',\n",
       "  'words',\n",
       "  'scattered',\n",
       "  'manner'],\n",
       " ['maybe', 'topic', 'd6', 'really', 'topic', 'query'],\n",
       " ['discussion',\n",
       "  'campaign',\n",
       "  'beginning',\n",
       "  'document',\n",
       "  'may',\n",
       "  'nothing',\n",
       "  'managing',\n",
       "  'presidential',\n",
       "  'end'],\n",
       " ['general',\n",
       "  'think',\n",
       "  'long',\n",
       "  'documents',\n",
       "  'would',\n",
       "  'higher',\n",
       "  'chance',\n",
       "  'matching',\n",
       "  'query'],\n",
       " ['fact',\n",
       "  'generate',\n",
       "  'long',\n",
       "  'document',\n",
       "  'randomly',\n",
       "  'assembling',\n",
       "  'words',\n",
       "  'distribution',\n",
       "  'words',\n",
       "  'eventually',\n",
       "  'probably',\n",
       "  'match',\n",
       "  'inquiry'],\n",
       " ['sense',\n",
       "  'penalize',\n",
       "  'documents',\n",
       "  'naturally',\n",
       "  'better',\n",
       "  'chance',\n",
       "  'matching',\n",
       "  'query',\n",
       "  'idea',\n",
       "  'document',\n",
       "  'normalization'],\n",
       " ['also', 'need', 'careful', 'avoiding', 'penalize', 'long', 'documents'],\n",
       " ['one', 'hand', 'want', 'penalize', 'long', 'document'],\n",
       " ['hand', 'also', 'dont', 'want', 'overpenalize'],\n",
       " ['reasoning', 'document', 'may', 'long', 'different', 'reasons'],\n",
       " ['one', 'case', 'document', 'may', 'long', 'uses', 'words'],\n",
       " ['example', 'think', 'vortex', 'article', 'research', 'paper'],\n",
       " ['would', 'use', 'words', 'corresponding', 'abstract'],\n",
       " ['case',\n",
       "  'probably',\n",
       "  'penalize',\n",
       "  'matching',\n",
       "  'long',\n",
       "  'documents',\n",
       "  'full',\n",
       "  'paper'],\n",
       " ['compare',\n",
       "  'matching',\n",
       "  'words',\n",
       "  'long',\n",
       "  'document',\n",
       "  'matching',\n",
       "  'words',\n",
       "  'shop',\n",
       "  'abstract'],\n",
       " ['long',\n",
       "  'papers',\n",
       "  'general',\n",
       "  'higher',\n",
       "  'chance',\n",
       "  'matching',\n",
       "  'clearer',\n",
       "  'words',\n",
       "  'therefore',\n",
       "  'penalize'],\n",
       " ['however',\n",
       "  'another',\n",
       "  'case',\n",
       "  'document',\n",
       "  'long',\n",
       "  'document',\n",
       "  'simply',\n",
       "  'content'],\n",
       " ['consider',\n",
       "  'another',\n",
       "  'case',\n",
       "  'long',\n",
       "  'document',\n",
       "  'simply',\n",
       "  'concatenate',\n",
       "  'lot',\n",
       "  'abstracts',\n",
       "  'different',\n",
       "  'papers'],\n",
       " ['case', 'obviously', 'dont', 'want', 'overpenalize', 'long', 'document'],\n",
       " ['indeed', 'probably', 'dont', 'want', 'penalize', 'document', 'long'],\n",
       " ['thats', 'need', 'careful', 'using', 'right', 'degree', 'penalization'],\n",
       " ['method',\n",
       "  'working',\n",
       "  'well',\n",
       "  'based',\n",
       "  'recent',\n",
       "  'results',\n",
       "  'called',\n",
       "  'pivoted',\n",
       "  'length',\n",
       "  'normalization'],\n",
       " ['case',\n",
       "  'idea',\n",
       "  'use',\n",
       "  'average',\n",
       "  'document',\n",
       "  'length',\n",
       "  'pivot',\n",
       "  'reference',\n",
       "  'point'],\n",
       " ['means',\n",
       "  'well',\n",
       "  'assume',\n",
       "  'average',\n",
       "  'length',\n",
       "  'documents',\n",
       "  'score',\n",
       "  'right',\n",
       "  'normalizer',\n",
       "  'would',\n",
       "  'NUMBER'],\n",
       " ['document', 'longer', 'average', 'document', 'length', 'penalization'],\n",
       " ['whereas', 'shorter', 'even', 'reward'],\n",
       " ['illustrated',\n",
       "  'using',\n",
       "  'slide',\n",
       "  'axis',\n",
       "  'xaxis',\n",
       "  'see',\n",
       "  'length',\n",
       "  'document'],\n",
       " ['yaxis', 'show', 'normalizer'],\n",
       " ['case',\n",
       "  'pivoted',\n",
       "  'length',\n",
       "  'normalization',\n",
       "  'formula',\n",
       "  'normalizer',\n",
       "  'seeing',\n",
       "  'interpolation',\n",
       "  'NUMBER',\n",
       "  'normalize',\n",
       "  'document',\n",
       "  'length',\n",
       "  'controlled',\n",
       "  'parameter',\n",
       "  'b'],\n",
       " ['see',\n",
       "  'first',\n",
       "  'divide',\n",
       "  'length',\n",
       "  'document',\n",
       "  'average',\n",
       "  'documents',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'sense',\n",
       "  'document',\n",
       "  'compared',\n",
       "  'average',\n",
       "  'documents',\n",
       "  'also',\n",
       "  'gives',\n",
       "  'us',\n",
       "  'benefit',\n",
       "  'worrying',\n",
       "  'unit',\n",
       "  'length'],\n",
       " ['measure', 'length', 'words', 'characters'],\n",
       " ['anyway', 'normalizer', 'interesting', 'property'],\n",
       " ['first',\n",
       "  'see',\n",
       "  'set',\n",
       "  'parameter',\n",
       "  'b',\n",
       "  'NUMBER',\n",
       "  'value',\n",
       "  'would',\n",
       "  'NUMBER'],\n",
       " ['theres', 'lens', 'normalization'],\n",
       " ['b', 'sense', 'controls', 'lens', 'normalization'],\n",
       " ['whereas',\n",
       "  'set',\n",
       "  'b',\n",
       "  'nonzero',\n",
       "  'value',\n",
       "  'normalizer',\n",
       "  'would',\n",
       "  'look',\n",
       "  'like'],\n",
       " ['right',\n",
       "  'value',\n",
       "  'would',\n",
       "  'higher',\n",
       "  'documents',\n",
       "  'longer',\n",
       "  'average',\n",
       "  'document',\n",
       "  'lens'],\n",
       " ['whereas',\n",
       "  'value',\n",
       "  'normalizer',\n",
       "  'would',\n",
       "  'shorter',\n",
       "  'would',\n",
       "  'smaller',\n",
       "  'shorter',\n",
       "  'documents'],\n",
       " ['sense',\n",
       "  'see',\n",
       "  'penalization',\n",
       "  'long',\n",
       "  'documents',\n",
       "  'theres',\n",
       "  'reward',\n",
       "  'short',\n",
       "  'documents'],\n",
       " ['degree',\n",
       "  'penalization',\n",
       "  'controlled',\n",
       "  'b',\n",
       "  'set',\n",
       "  'b',\n",
       "  'larger',\n",
       "  'value',\n",
       "  'normalizer',\n",
       "  'would',\n",
       "  'look',\n",
       "  'like'],\n",
       " ['theres',\n",
       "  'even',\n",
       "  'penalization',\n",
       "  'long',\n",
       "  'documents',\n",
       "  'reward',\n",
       "  'short',\n",
       "  'documents'],\n",
       " ['adjusting',\n",
       "  'b',\n",
       "  'varies',\n",
       "  'NUMBER',\n",
       "  'NUMBER',\n",
       "  'control',\n",
       "  'degree',\n",
       "  'length',\n",
       "  'normalization'],\n",
       " ['plug',\n",
       "  'length',\n",
       "  'normalization',\n",
       "  'fact',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'ranking',\n",
       "  'functions',\n",
       "  'already',\n",
       "  'examined'],\n",
       " ['end', 'following', 'formulas'],\n",
       " ['fact', 'state', 'vector', 'space', 'model', 'formulas'],\n",
       " ['lets', 'take', 'look'],\n",
       " ['first',\n",
       "  'one',\n",
       "  'called',\n",
       "  'pivoted',\n",
       "  'length',\n",
       "  'normalization',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'reference',\n",
       "  'inaudible',\n",
       "  'duration',\n",
       "  'model'],\n",
       " ['see',\n",
       "  'basically',\n",
       "  'tfi',\n",
       "  'model',\n",
       "  'discussed',\n",
       "  'idea',\n",
       "  'component',\n",
       "  'familiar'],\n",
       " ['also', 'query', 'term', 'frequency', 'component'],\n",
       " ['middle',\n",
       "  'normalizer',\n",
       "  'tf',\n",
       "  'case',\n",
       "  'see',\n",
       "  'use',\n",
       "  'double',\n",
       "  'logarithm',\n",
       "  'discussed',\n",
       "  'achieve',\n",
       "  'sublinear',\n",
       "  'transformation'],\n",
       " ['also', 'put', 'document', 'length', 'normalizer', 'bottom'],\n",
       " ['right',\n",
       "  'would',\n",
       "  'cause',\n",
       "  'penalization',\n",
       "  'long',\n",
       "  'document',\n",
       "  'larger',\n",
       "  'denominator',\n",
       "  'smaller'],\n",
       " ['course', 'controlled', 'parameter', 'b'],\n",
       " ['see', 'b', 'set', 'NUMBER', 'length', 'normalization'],\n",
       " ['okay', 'one', 'two', 'effective', 'base', 'model', 'formulas'],\n",
       " ['next',\n",
       "  'one',\n",
       "  'called',\n",
       "  'bm25',\n",
       "  'okapi',\n",
       "  'also',\n",
       "  'similar',\n",
       "  'also',\n",
       "  'idf',\n",
       "  'component',\n",
       "  'query',\n",
       "  'idf',\n",
       "  'component'],\n",
       " ['middle', 'normal', 'issues', 'little', 'bit', 'different'],\n",
       " ['explained',\n",
       "  'copy',\n",
       "  'tf',\n",
       "  'transformation',\n",
       "  'sublinear',\n",
       "  'transformation',\n",
       "  'upper',\n",
       "  'bound'],\n",
       " ['case', 'put', 'length', 'normalization', 'factor'],\n",
       " ['adjusting',\n",
       "  'k',\n",
       "  'achieves',\n",
       "  'similar',\n",
       "  'factor',\n",
       "  'put',\n",
       "  'normalizer',\n",
       "  'denominator'],\n",
       " ['therefore', 'document', 'longer', 'term', 'weight', 'smaller'],\n",
       " ['see',\n",
       "  'gone',\n",
       "  'n',\n",
       "  'answers',\n",
       "  'talked',\n",
       "  'end',\n",
       "  'reached',\n",
       "  'basically',\n",
       "  'state',\n",
       "  'god',\n",
       "  'functions'],\n",
       " ['far', 'talked', 'mainly', 'place', 'document', 'vector', 'vector', 'space'],\n",
       " ['played',\n",
       "  'important',\n",
       "  'role',\n",
       "  'determining',\n",
       "  'effectiveness',\n",
       "  'simple',\n",
       "  'function'],\n",
       " ['also', 'dimensions', 'really', 'examine', 'details'],\n",
       " ['example',\n",
       "  'improve',\n",
       "  'instantiation',\n",
       "  'dimension',\n",
       "  'vector',\n",
       "  'space',\n",
       "  'model',\n",
       "  'weve',\n",
       "  'assumed',\n",
       "  'bag',\n",
       "  'words',\n",
       "  'representation',\n",
       "  'issue',\n",
       "  'dimension',\n",
       "  'word',\n",
       "  'obviously',\n",
       "  'see',\n",
       "  'many',\n",
       "  'choices'],\n",
       " ['example',\n",
       "  'stemmed',\n",
       "  'word',\n",
       "  'words',\n",
       "  'havent',\n",
       "  'transformed',\n",
       "  'root',\n",
       "  'form',\n",
       "  'computation',\n",
       "  'computing',\n",
       "  'become',\n",
       "  'match'],\n",
       " ['get', 'stop', 'word', 'removal'],\n",
       " ['remove', 'common', 'words', 'dont', 'carry', 'content', 'like'],\n",
       " ['get', 'use', 'phrases', 'define', 'dimensions'],\n",
       " ['even',\n",
       "  'use',\n",
       "  'later',\n",
       "  'semantical',\n",
       "  'analysis',\n",
       "  'find',\n",
       "  'clusters',\n",
       "  'words',\n",
       "  'represent',\n",
       "  'late',\n",
       "  'concept',\n",
       "  'one',\n",
       "  'engine'],\n",
       " ['also',\n",
       "  'use',\n",
       "  'smaller',\n",
       "  'unit',\n",
       "  'like',\n",
       "  'character',\n",
       "  'end',\n",
       "  'grams',\n",
       "  'sequences',\n",
       "  'characters',\n",
       "  'dimensions'],\n",
       " ['however',\n",
       "  'practice',\n",
       "  'people',\n",
       "  'found',\n",
       "  'bagofwords',\n",
       "  'representation',\n",
       "  'phrases',\n",
       "  'still',\n",
       "  'effective',\n",
       "  'one',\n",
       "  'also',\n",
       "  'efficient'],\n",
       " ['still', 'far', 'popular', 'dimension', 'instantiation', 'method'],\n",
       " ['used', 'major', 'search', 'engines'],\n",
       " ['also',\n",
       "  'mention',\n",
       "  'sometimes',\n",
       "  'need',\n",
       "  'language',\n",
       "  'specific',\n",
       "  'domain',\n",
       "  'specific',\n",
       "  'tokenization'],\n",
       " ['actually',\n",
       "  'important',\n",
       "  'might',\n",
       "  'variations',\n",
       "  'terms',\n",
       "  'might',\n",
       "  'prevent',\n",
       "  'us',\n",
       "  'matching',\n",
       "  'even',\n",
       "  'mean',\n",
       "  'thing'],\n",
       " ['languages',\n",
       "  'like',\n",
       "  'chinese',\n",
       "  'also',\n",
       "  'challenge',\n",
       "  'segmenting',\n",
       "  'text',\n",
       "  'obtain',\n",
       "  'word',\n",
       "  'band',\n",
       "  'rates',\n",
       "  'sequence',\n",
       "  'characters'],\n",
       " ['word',\n",
       "  'might',\n",
       "  'correspond',\n",
       "  'one',\n",
       "  'character',\n",
       "  'two',\n",
       "  'characters',\n",
       "  'even',\n",
       "  'three',\n",
       "  'characters'],\n",
       " ['easier', 'english', 'space', 'separate', 'words'],\n",
       " ['languages',\n",
       "  'may',\n",
       "  'need',\n",
       "  'americanize',\n",
       "  'processing',\n",
       "  'figure',\n",
       "  'way',\n",
       "  'boundaries',\n",
       "  'words'],\n",
       " ['also', 'possibility', 'improve', 'similarity', 'function'],\n",
       " ['far', 'used', 'top', 'product', 'one', 'imagine', 'measures'],\n",
       " ['example', 'measure', 'cosine', 'angle', 'two', 'vectors'],\n",
       " ['use', 'euclidean', 'distance', 'measure'],\n",
       " ['possible',\n",
       "  'dot',\n",
       "  'product',\n",
       "  'seems',\n",
       "  'still',\n",
       "  'best',\n",
       "  'one',\n",
       "  'reason',\n",
       "  'general'],\n",
       " ['fact',\n",
       "  'sufficiently',\n",
       "  'general',\n",
       "  'consider',\n",
       "  'possibilities',\n",
       "  'waiting',\n",
       "  'different',\n",
       "  'ways'],\n",
       " ['example',\n",
       "  'cosine',\n",
       "  'measure',\n",
       "  'thought',\n",
       "  'thought',\n",
       "  'product',\n",
       "  'two',\n",
       "  'normalized',\n",
       "  'factors'],\n",
       " ['means', 'first', 'normalize', 'factor', 'take', 'thought', 'product'],\n",
       " ['would', 'critical', 'cosine', 'measure'],\n",
       " ['mentioned', 'bm25', 'seems', 'one', 'effective', 'formulas'],\n",
       " ['also', 'developments', 'improving', 'bm25'],\n",
       " ['although', 'none', 'words', 'changed', 'bm25', 'fundamental'],\n",
       " ['one', 'line', 'work', 'people', 'divide', 'bm25', 'f'],\n",
       " ['f', 'stands', 'field', 'use', 'bm25', 'documents', 'structures'],\n",
       " ['example',\n",
       "  'might',\n",
       "  'consider',\n",
       "  'title',\n",
       "  'field',\n",
       "  'abstract',\n",
       "  'body',\n",
       "  'research',\n",
       "  'article'],\n",
       " ['even',\n",
       "  'anchor',\n",
       "  'text',\n",
       "  'web',\n",
       "  'page',\n",
       "  'text',\n",
       "  'fields',\n",
       "  'describe',\n",
       "  'links',\n",
       "  'pages',\n",
       "  'combined',\n",
       "  'proper',\n",
       "  'way',\n",
       "  'different',\n",
       "  'fields',\n",
       "  'help',\n",
       "  'improve',\n",
       "  'scoring',\n",
       "  'different',\n",
       "  'documents'],\n",
       " ['use',\n",
       "  'bm25',\n",
       "  'document',\n",
       "  'obvious',\n",
       "  'choice',\n",
       "  'apply',\n",
       "  'bm25',\n",
       "  'field',\n",
       "  'combine',\n",
       "  'scores'],\n",
       " ...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = []\n",
    "for sentence in all_text:\n",
    "    sentence = sentence.strip().translate(str.maketrans('', '', string.punctuation))\n",
    "    if 'bits' in sentence:\n",
    "        print(sentence)\n",
    "    sentence = re.sub(r\"\\b\\d+[s]{0,1}\\b\", 'NUMBER', sentence)     # replace numbers with this token\n",
    "    \n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    token_list.append(tokens)\n",
    "\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_n_grams(tokenized_sentences: List[List[str]], n: int) -> Counter:\n",
    "\n",
    "    n_grams_list = []\n",
    "    for tokens in tokenized_sentences:\n",
    "        n_grams_list.append(list(nltk.ngrams(tokens, n, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>')))\n",
    "\n",
    "    merged_n_grams = []\n",
    "    for sentence in n_grams_list:\n",
    "        for n_gram in sentence:\n",
    "            s ='_'.join(n_gram)\n",
    "            if '<s>' not in s and '</s>' not in s:\n",
    "                merged_n_grams.append(s)\n",
    "\n",
    "    return Counter(merged_n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use_maximum_likelihood_estimator', 9),\n",
       " ('natural_language_processing_techniques', 8),\n",
       " ('simplest_vector_space_model', 8),\n",
       " ('like_vector_space_model', 8),\n",
       " ('lecture_going_continue_discussing', 8),\n",
       " ('opinion_mining_sentiment_analysis', 7),\n",
       " ('lecture_going_continue_talking', 7),\n",
       " ('query_vector_document_vector', 6),\n",
       " ('lecture_going_continue_discussion', 6),\n",
       " ('natural_language_content_analysis', 5),\n",
       " ('text_retrieval_text_mining', 5),\n",
       " ('lecture_going_talk_text', 5),\n",
       " ('distribution_used_generate_document', 5),\n",
       " ('take_away_probability_mass', 5),\n",
       " ('natural_language_processing_difficult', 4),\n",
       " ('matching_one_frequent_term', 4),\n",
       " ('next_lecture_going_talk', 4),\n",
       " ('text_data_actionable_knowledge', 4),\n",
       " ('nontext_data_text_data', 4),\n",
       " ('discussion_vector_space_model', 4),\n",
       " ('unique_query_terms_matched', 4),\n",
       " ('query_terms_matched_document', 4),\n",
       " ('instantiate_vector_space_model', 4),\n",
       " ('weighting_document_length_normalization', 4),\n",
       " ('lets_take_look_specific', 4),\n",
       " ('talked_push_versus_pull', 4),\n",
       " ('evaluation_text_retrieval_systems', 4),\n",
       " ('want_think_pause_video', 4),\n",
       " ('slide_seen_earlier_lecture', 4),\n",
       " ('query_likelihood_retrieval_function', 4),\n",
       " ('get_rid_common_words', 4),\n",
       " ('use_background_language_model', 4),\n",
       " ('lets_take_look_simple', 4),\n",
       " ('take_look_simple_example', 4),\n",
       " ('conditional_probability_label_given', 4),\n",
       " ('probability_label_given_data', 4),\n",
       " ('distribution_used_generate_word', 4),\n",
       " ('compute_maximum_likelihood_estimate', 4),\n",
       " ('probabilistic_latent_semantic_analysis', 4),\n",
       " ('sound_lecture_continued_discussion', 4),\n",
       " ('simplest_language_model_called', 4),\n",
       " ('language_model_called_unigram', 4),\n",
       " ('model_called_unigram_language', 4),\n",
       " ('called_unigram_language_model', 4),\n",
       " ('query_words_matching_document', 4),\n",
       " ('latent_aspect_rating_analysis', 4),\n",
       " ('weighted_average_aspect_ratings', 4),\n",
       " ('called_maximum_likelihood_estimate', 4),\n",
       " ('man_saw_boy_telescope', 3),\n",
       " ('lets_take_look_example', 3),\n",
       " ('similar_context_cat_context', 3),\n",
       " ('whenever_eats_occurs_words', 3),\n",
       " ('eats_occurs_words_also', 3),\n",
       " ('occurs_words_also_tend', 3),\n",
       " ('words_also_tend_occur', 3),\n",
       " ('two_words_occur_together', 3),\n",
       " ('probability_two_randomly_picked', 3),\n",
       " ('two_randomly_picked_words', 3),\n",
       " ('idf_stands_inverse_document', 3),\n",
       " ('stands_inverse_document_frequency', 3),\n",
       " ('total_number_documents_collection', 3),\n",
       " ('help_us_solve_problem', 3),\n",
       " ('many_unique_query_terms', 3),\n",
       " ('continue_discussion_vector_space', 3),\n",
       " ('vector_space_model_special', 3),\n",
       " ('using_vector_space_model', 3),\n",
       " ('sum_matched_query_terms', 3),\n",
       " ('would_give_us_something', 3),\n",
       " ('take_look_specific_example', 3),\n",
       " ('fetch_documents_match_term', 3),\n",
       " ('talked_vector_space_model', 3),\n",
       " ('language_processing_difficult_computers', 3),\n",
       " ('need_deeper_natural_language', 3),\n",
       " ('deeper_natural_language_processing', 3),\n",
       " ('used_modern_search_engines', 3),\n",
       " ('help_users_get_access', 3),\n",
       " ('high_level_strategies_text', 3),\n",
       " ('level_strategies_text_access', 3),\n",
       " ('retrieval_empirically_defined_problem', 3),\n",
       " ('would_give_us_different', 3),\n",
       " ('many_random_documents_possible', 3),\n",
       " ('lecture_continue_discussion_evaluation', 3),\n",
       " ('evaluate_text_retrieval_system', 3),\n",
       " ('NUMBER_NUMBER_NUMBER_NUMBER', 3),\n",
       " ('estimate_document_language_model', 3),\n",
       " ('function_would_look_like', 3),\n",
       " ('feedback_vector_space_model', 3),\n",
       " ('important_applications_text_retrieval', 3),\n",
       " ('going_talk_text_clustering', 3),\n",
       " ('two_component_mixture_model', 3),\n",
       " ('make_decision_regarding_distribution', 3),\n",
       " ('infer_distribution_used_generate', 3),\n",
       " ('document_product_probability_word', 3),\n",
       " ('discussion_generative_probabilistic_models', 3),\n",
       " ('generative_probabilistic_models_text', 3),\n",
       " ('distribution_likely_generated_document', 3),\n",
       " ('two_things_must_happen', 3),\n",
       " ('going_talk_text_categorization', 3),\n",
       " ('one_way_solve_problem', 3),\n",
       " ('k_unigram_language_models', 3)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_4_grams = count_n_grams(token_list, n=4)\n",
    "count_4_grams.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vector_space_model', 81),\n",
       " ('natural_language_processing', 32),\n",
       " ('lets_take_look', 31),\n",
       " ('would_allow_us', 31),\n",
       " ('would_give_us', 30),\n",
       " ('maximum_likelihood_estimate', 26),\n",
       " ('lecture_going_talk', 25),\n",
       " ('background_language_model', 22),\n",
       " ('lecture_going_continue', 21),\n",
       " ('maximum_likelihood_estimator', 19),\n",
       " ('many_different_ways', 17),\n",
       " ('distribution_used_generate', 17),\n",
       " ('contextual_text_mining', 16),\n",
       " ('would_look_like', 12),\n",
       " ('particular_going_talk', 12),\n",
       " ('collection_language_model', 12),\n",
       " ('sum_query_words', 12),\n",
       " ('topic_mining_analysis', 11),\n",
       " ('use_maximum_likelihood', 11),\n",
       " ('unigram_language_model', 11),\n",
       " ('topic_word_distribution', 11),\n",
       " ('would_help_us', 10),\n",
       " ('lets_first_look', 10),\n",
       " ('count_word_document', 10),\n",
       " ('lecture_continue_discussion', 10),\n",
       " ('system_b_better', 10),\n",
       " ('documents_match_term', 9),\n",
       " ('lot_text_data', 9),\n",
       " ('gives_us_probability', 9),\n",
       " ('NUMBER_NUMBER_NUMBER', 9),\n",
       " ('document_language_model', 9),\n",
       " ('probability_word_given', 9),\n",
       " ('unigram_language_models', 9),\n",
       " ('theta_sub_b', 9),\n",
       " ('probability_observing_word', 9),\n",
       " ('language_processing_techniques', 8),\n",
       " ('inverse_document_frequency', 8),\n",
       " ('bag_words_representation', 8),\n",
       " ('simplest_vector_space', 8),\n",
       " ('like_vector_space', 8),\n",
       " ('query_likelihood_retrieval', 8),\n",
       " ('high_probability_words', 8),\n",
       " ('used_generate_document', 8),\n",
       " ('going_continue_discussing', 8),\n",
       " ('probabilistic_topic_models', 8),\n",
       " ('system_says_yes', 8),\n",
       " ('correlated_time_series', 8),\n",
       " ('part_speech_tags', 7),\n",
       " ('text_data_mining', 7),\n",
       " ('use_machine_learning', 7),\n",
       " ('discover_syntagmatic_relations', 7),\n",
       " ('text_mining_analytics', 7),\n",
       " ('opinion_mining_sentiment', 7),\n",
       " ('mining_sentiment_analysis', 7),\n",
       " ('document_length_normalization', 7),\n",
       " ('going_talk_text', 7),\n",
       " ('method_works_better', 7),\n",
       " ('slide_seen_earlier', 7),\n",
       " ('way_solve_problem', 7),\n",
       " ('must_sum_NUMBER', 7),\n",
       " ('naive_bayes_classifier', 7),\n",
       " ('going_continue_talking', 7),\n",
       " ('topic_theta_sub', 7),\n",
       " ('k_minus_one', 7),\n",
       " ('text_mining_paper', 7),\n",
       " ('probabilistic_retrieval_model', 7),\n",
       " ('common_sense_knowledge', 6),\n",
       " ('mining_text_data', 6),\n",
       " ('machine_learning_techniques', 6),\n",
       " ('help_us_predict', 6),\n",
       " ('going_say_well', 6),\n",
       " ('total_number_documents', 6),\n",
       " ('common_words_like', 6),\n",
       " ('next_lecture_going', 6),\n",
       " ('big_text_data', 6),\n",
       " ('data_text_data', 6),\n",
       " ('give_us_different', 6),\n",
       " ('query_vector_document', 6),\n",
       " ('vector_document_vector', 6),\n",
       " ('going_continue_discussion', 6),\n",
       " ('text_retrieval_systems', 6),\n",
       " ('main_topic_lecture', 6),\n",
       " ('think_pause_video', 6),\n",
       " ('push_versus_pull', 6),\n",
       " ('mean_average_position', 6),\n",
       " ('assign_high_probabilities', 6),\n",
       " ('beyond_scope_course', 6),\n",
       " ('precisely_one_topic', 6),\n",
       " ('seen_previous_slide', 6),\n",
       " ('maximize_probability_observed', 6),\n",
       " ('makes_lot_sense', 6),\n",
       " ('thats_basic_idea', 6),\n",
       " ('total_number_words', 6),\n",
       " ('two_random_variables', 6),\n",
       " ('completely_biased_coin', 6),\n",
       " ('natural_language_content', 5),\n",
       " ('language_content_analysis', 5),\n",
       " ('mine_text_data', 5),\n",
       " ('part_speech_tagging', 5),\n",
       " ('represent_text_data', 5),\n",
       " ('analyze_text_data', 5),\n",
       " ('context_cat_context', 5),\n",
       " ('count_many_times', 5),\n",
       " ('k_plus_one', 5),\n",
       " ('data_actionable_knowledge', 5),\n",
       " ('real_world_variables', 5),\n",
       " ('text_data_help', 5),\n",
       " ('data_help_us', 5),\n",
       " ('text_retrieval_text', 5),\n",
       " ('retrieval_text_mining', 5),\n",
       " ('go_back_original', 5),\n",
       " ('vectors_vector_space', 5),\n",
       " ('unique_query_terms', 5),\n",
       " ('pivoted_length_normalization', 5),\n",
       " ('matched_query_terms', 5),\n",
       " ('lets_say_NUMBER', 5),\n",
       " ('many_different_methods', 5),\n",
       " ('floor_log_x', 5),\n",
       " ('flow_log_x', 5),\n",
       " ('take_look_specific', 5),\n",
       " ('text_retrieval_system', 5),\n",
       " ('search_engine_system', 5),\n",
       " ('modern_search_engines', 5),\n",
       " ('formula_looks_like', 5),\n",
       " ('lets_first_think', 5),\n",
       " ('two_different_ways', 5),\n",
       " ('whether_document_relevant', 5),\n",
       " ('document_relevant_query', 5),\n",
       " ('left_side_see', 5),\n",
       " ('binary_random_variable', 5),\n",
       " ('right_side_see', 5),\n",
       " ('language_model_called', 5),\n",
       " ('likelihood_function_would', 5),\n",
       " ('move_query_vector', 5),\n",
       " ('key_value_pairs', 5),\n",
       " ('random_surfer_would', 5),\n",
       " ('would_sum_NUMBER', 5),\n",
       " ('group_similar_objects', 5),\n",
       " ('probability_x_given', 5),\n",
       " ('conditional_probability_label', 5),\n",
       " ('label_given_data', 5),\n",
       " ('using_bayes_rule', 5),\n",
       " ('used_generate_word', 5),\n",
       " ('generate_words_document', 5),\n",
       " ('distribution_theta_sub', 5),\n",
       " ('function_looks_like', 5),\n",
       " ('product_probability_word', 5),\n",
       " ('generative_probabilistic_models', 5),\n",
       " ('compute_maximum_likelihood', 5),\n",
       " ('take_away_probability', 5),\n",
       " ('away_probability_mass', 5),\n",
       " ('probability_theta_sub', 5),\n",
       " ('background_word_distribution', 5),\n",
       " ('theta_sub_j', 5),\n",
       " ('given_theta_sub', 5),\n",
       " ('latent_semantic_analysis', 5),\n",
       " ('lambda_sub_b', 5),\n",
       " ('theta_sub_k', 5),\n",
       " ('probabilities_must_sum', 5),\n",
       " ('must_sum_one', 5),\n",
       " ('also_would_like', 5),\n",
       " ('simplest_language_model', 5),\n",
       " ('higher_probabilities_others', 5),\n",
       " ('called_maximum_likelihood', 5),\n",
       " ('user_likes_document', 5),\n",
       " ('aspect_rating_analysis', 5),\n",
       " ('text_data_associated', 5),\n",
       " ('average_aspect_ratings', 5),\n",
       " ('syntagmatic_relation_discovery', 5),\n",
       " ('language_processing_difficult', 4),\n",
       " ('understand_natural_language', 4),\n",
       " ('way_representing_text', 4),\n",
       " ('text_data_data', 4),\n",
       " ('actually_give_us', 4),\n",
       " ('analyzing_text_data', 4),\n",
       " ('deeper_natural_language', 4),\n",
       " ('word_association_mining', 4),\n",
       " ('applications_text_retrieval', 4),\n",
       " ('words_tend_occur', 4),\n",
       " ('two_contexts_identical', 4),\n",
       " ('matching_one_frequent', 4),\n",
       " ('one_frequent_term', 4),\n",
       " ('going_talk_two', 4),\n",
       " ('form_looks_like', 4),\n",
       " ('take_sum_words', 4),\n",
       " ('text_mining_algorithms', 4),\n",
       " ('turn_text_data', 4),\n",
       " ('text_data_actionable', 4),\n",
       " ('text_nontext_data', 4),\n",
       " ('content_text_data', 4),\n",
       " ('using_text_data', 4),\n",
       " ('original_text_data', 4),\n",
       " ('partition_text_data', 4),\n",
       " ('first_text_retrieval', 4),\n",
       " ('humans_subjective_sensors', 4),\n",
       " ('nontext_data_text', 4),\n",
       " ('intuitively_makes_sense', 4),\n",
       " ('would_work_well', 4),\n",
       " ('discussion_vector_space', 4),\n",
       " ('query_terms_matched', 4)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_3_grams = count_n_grams(token_list, n=3)\n",
    "count_3_grams.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text_data', 229),\n",
       " ('language_model', 111),\n",
       " ('text_mining', 106),\n",
       " ('vector_space', 97),\n",
       " ('space_model', 82),\n",
       " ('text_retrieval', 81),\n",
       " ('going_talk', 80),\n",
       " ('word_distribution', 74),\n",
       " ('NUMBER_NUMBER', 73),\n",
       " ('help_us', 71),\n",
       " ('relevant_documents', 67),\n",
       " ('lecture_going', 66),\n",
       " ('search_engine', 65),\n",
       " ('give_us', 61),\n",
       " ('lets_say', 60),\n",
       " ('solve_problem', 59),\n",
       " ('natural_language', 58),\n",
       " ('mixture_model', 57),\n",
       " ('theta_sub', 57),\n",
       " ('different_ways', 56),\n",
       " ('likelihood_function', 54),\n",
       " ('maximum_likelihood', 53),\n",
       " ('take_look', 52),\n",
       " ('allow_us', 52),\n",
       " ('ranking_function', 52),\n",
       " ('training_data', 51),\n",
       " ('probability_word', 49),\n",
       " ('lets_look', 47),\n",
       " ('topic_model', 46),\n",
       " ('text_categorization', 46),\n",
       " ('would_allow', 45),\n",
       " ('sound_lecture', 44),\n",
       " ('would_like', 44),\n",
       " ('going_use', 44),\n",
       " ('gives_us', 43),\n",
       " ('search_engines', 43),\n",
       " ('machine_learning', 41),\n",
       " ('allows_us', 41),\n",
       " ('looks_like', 40),\n",
       " ('time_series', 40),\n",
       " ('would_give', 39),\n",
       " ('inverted_index', 38),\n",
       " ('also_see', 37),\n",
       " ('scoring_function', 37),\n",
       " ('query_vector', 37),\n",
       " ('little_bit', 36),\n",
       " ('common_words', 36),\n",
       " ('language_processing', 35),\n",
       " ('text_clustering', 35),\n",
       " ('lets_take', 34),\n",
       " ('word_like', 33),\n",
       " ('data_mining', 33),\n",
       " ('nontext_data', 33),\n",
       " ('query_words', 33),\n",
       " ('query_likelihood', 33),\n",
       " ('mutual_information', 33),\n",
       " ('conditional_entropy', 33),\n",
       " ('precision_recall', 32),\n",
       " ('words_document', 31),\n",
       " ('example_might', 30),\n",
       " ('word_document', 30),\n",
       " ('similarity_function', 30),\n",
       " ('topic_models', 30),\n",
       " ('theta_NUMBER', 30),\n",
       " ('many_different', 29),\n",
       " ('basic_idea', 29),\n",
       " ('going_say', 29),\n",
       " ('lets_see', 29),\n",
       " ('information_retrieval', 29),\n",
       " ('web_search', 29),\n",
       " ('background_model', 29),\n",
       " ('two_words', 28),\n",
       " ('relevant_document', 27),\n",
       " ('work_well', 26),\n",
       " ('likelihood_estimate', 26),\n",
       " ('used_generate', 26),\n",
       " ('real_world', 25),\n",
       " ('text_objects', 25),\n",
       " ('total_number', 25),\n",
       " ('going_look', 25),\n",
       " ('look_like', 25),\n",
       " ('particular_going', 25),\n",
       " ('user_would', 25),\n",
       " ('random_variable', 25),\n",
       " ('generative_model', 25),\n",
       " ('estimate_parameters', 25),\n",
       " ('tells_us', 24),\n",
       " ('words_like', 24),\n",
       " ('going_assume', 24),\n",
       " ('retrieval_function', 24),\n",
       " ('conditional_probability', 24),\n",
       " ('might_also', 23),\n",
       " ('count_word', 23),\n",
       " ('two_groups', 23),\n",
       " ('system_b', 23),\n",
       " ('one_topic', 23),\n",
       " ('high_probability', 23),\n",
       " ('probability_observing', 23),\n",
       " ('well_see', 22),\n",
       " ('syntagmatic_relations', 22),\n",
       " ('retrieval_model', 22),\n",
       " ('sum_one', 22),\n",
       " ('general_idea', 22),\n",
       " ('topic_mining', 22),\n",
       " ('query_terms', 22),\n",
       " ('would_mean', 22),\n",
       " ('background_language', 22),\n",
       " ('zero_probability', 22),\n",
       " ('would_make', 21),\n",
       " ('even_though', 21),\n",
       " ('one_word', 21),\n",
       " ('lets_first', 21),\n",
       " ('ask_question', 21),\n",
       " ('document_vector', 21),\n",
       " ('document_frequency', 21),\n",
       " ('say_well', 21),\n",
       " ('going_continue', 21),\n",
       " ('high_probabilities', 21),\n",
       " ('sum_NUMBER', 21),\n",
       " ('em_algorithm', 21),\n",
       " ('two_kinds', 20),\n",
       " ('makes_sense', 20),\n",
       " ('one_way', 20),\n",
       " ('function_would', 20),\n",
       " ('query_term', 20),\n",
       " ('length_normalization', 20),\n",
       " ('distribution_used', 20),\n",
       " ('unigram_language', 20),\n",
       " ('language_models', 20),\n",
       " ('word_distributions', 20),\n",
       " ('sequence_words', 19),\n",
       " ('right_side', 19),\n",
       " ('also_use', 19),\n",
       " ('many_times', 19),\n",
       " ('one_document', 19),\n",
       " ('bag_words', 19),\n",
       " ('inside_sum', 19),\n",
       " ('also_need', 19),\n",
       " ('two_distributions', 19),\n",
       " ('generate_word', 19),\n",
       " ('likelihood_estimator', 19),\n",
       " ('probability_words', 19),\n",
       " ('data_set', 18),\n",
       " ('many_applications', 18),\n",
       " ('youll_see', 18),\n",
       " ('words_occur', 18),\n",
       " ('see_words', 18),\n",
       " ('would_also', 18),\n",
       " ('would_look', 18),\n",
       " ('would_happen', 18),\n",
       " ('document_length', 18),\n",
       " ('special_case', 18),\n",
       " ('words_would', 18),\n",
       " ('rank_documents', 18),\n",
       " ('ranked_list', 18),\n",
       " ('tell_us', 18),\n",
       " ('probability_NUMBER', 18),\n",
       " ('probabilities_words', 18),\n",
       " ('objective_function', 18),\n",
       " ('generate_document', 18),\n",
       " ('logistical_regression', 18),\n",
       " ('k_topics', 18),\n",
       " ('one_distribution', 18),\n",
       " ('parameter_values', 18),\n",
       " ('sentiment_analysis', 17),\n",
       " ('related_words', 17),\n",
       " ('want_know', 17),\n",
       " ('would_help', 17),\n",
       " ('doesnt_really', 17),\n",
       " ('continue_discussion', 17),\n",
       " ('dont_want', 17),\n",
       " ('lets_think', 17),\n",
       " ('course_project', 17),\n",
       " ('compute_probability', 17),\n",
       " ('two_categories', 17),\n",
       " ('opinion_holder', 17),\n",
       " ('weve_got', 16),\n",
       " ('semantic_analysis', 16),\n",
       " ('mining_analysis', 16),\n",
       " ('paradigmatic_relation', 16),\n",
       " ('idf_weighting', 16),\n",
       " ('take_sum', 16),\n",
       " ('opinion_mining', 16),\n",
       " ('lot_text', 16),\n",
       " ('first_one', 16),\n",
       " ('words_vocabulary', 16),\n",
       " ('probabilistic_models', 16),\n",
       " ('take_average', 16),\n",
       " ('two_probabilities', 16),\n",
       " ('data_points', 16),\n",
       " ('probability_text', 16),\n",
       " ('categorization_problem', 16),\n",
       " ('category_one', 16),\n",
       " ('naive_bayes', 16),\n",
       " ('many_parameters', 16),\n",
       " ('lower_bound', 16),\n",
       " ('contextual_text', 16),\n",
       " ('make_sense', 15),\n",
       " ('two_ways', 15),\n",
       " ('might_want', 15)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_2_grams = count_n_grams(token_list, n=2)\n",
    "count_2_grams.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1k',\n",
       " '32bits',\n",
       " '8bits',\n",
       " 'NUMBER',\n",
       " 'aa',\n",
       " 'aand',\n",
       " 'ab',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abortion',\n",
       " 'abounded',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absents',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abstract',\n",
       " 'abstracts',\n",
       " 'accelerate',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accidental',\n",
       " 'accommodate',\n",
       " 'accompanying',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulative',\n",
       " 'accumulator',\n",
       " 'accumulators',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'acl',\n",
       " 'acoustic',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adaptive',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additives',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adjacency',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adopt',\n",
       " 'adultation',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliation',\n",
       " 'affiliations',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agent',\n",
       " 'ages',\n",
       " 'agglomerative',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregating',\n",
       " 'aggregation',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airlines',\n",
       " 'airport',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'algebra',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'align',\n",
       " 'alleviate',\n",
       " 'alleviated',\n",
       " 'alliance',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allocating',\n",
       " 'allocation',\n",
       " 'allocations',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alpha',\n",
       " 'alphas',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'ama',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'american',\n",
       " 'americanize',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'analogy',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'analytically',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzing',\n",
       " 'anaphora',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'ancients',\n",
       " 'andor',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'annotate',\n",
       " 'annotating',\n",
       " 'annotation',\n",
       " 'annotations',\n",
       " 'annual',\n",
       " 'anome',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anticipate',\n",
       " 'antithesis',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'applet',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applicationspecific',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoint',\n",
       " 'appoints',\n",
       " 'appreciate',\n",
       " 'appreciating',\n",
       " 'apprised',\n",
       " 'approace',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approximate',\n",
       " 'approximated',\n",
       " 'approximating',\n",
       " 'approximation',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'architecture',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arent',\n",
       " 'arg',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arithmatic',\n",
       " 'arithmetic',\n",
       " 'arithmetically',\n",
       " 'around',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrive',\n",
       " 'arrow',\n",
       " 'arrows',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'ascending',\n",
       " 'ascii',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspect',\n",
       " 'aspectlevel',\n",
       " 'aspects',\n",
       " 'aspectspecific',\n",
       " 'assault',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assembling',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assess',\n",
       " 'assessed',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assessors',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assigning',\n",
       " 'assignment',\n",
       " 'assignments',\n",
       " 'assigns',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'associativearray',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assumptions',\n",
       " 'ate',\n",
       " 'atoms',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attaching',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempts',\n",
       " 'attention',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'attribution',\n",
       " 'audio',\n",
       " 'audition',\n",
       " 'augment',\n",
       " 'augmentation',\n",
       " 'augmented',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authors',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automobiles',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'average',\n",
       " 'averagelink',\n",
       " 'averaging',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'await',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awkward',\n",
       " 'axiomatic',\n",
       " 'axis',\n",
       " 'b',\n",
       " 'b1',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backwards',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bagofwords',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balances',\n",
       " 'balancing',\n",
       " 'band',\n",
       " 'bar',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'baseline',\n",
       " 'bases',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'batch',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bayes',\n",
       " 'bayesian',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'beginning',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behavior',\n",
       " 'behaviors',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'bend',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bestperforming',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betagamma',\n",
       " 'betas',\n",
       " 'better',\n",
       " 'beverage',\n",
       " 'beyond',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bibliographic',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigram',\n",
       " 'bill',\n",
       " 'binary',\n",
       " 'bind',\n",
       " 'bing',\n",
       " 'biologist',\n",
       " 'biologists',\n",
       " 'biomedical',\n",
       " 'biproduct',\n",
       " 'bit',\n",
       " 'bits',\n",
       " 'black',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'block',\n",
       " 'blocks',\n",
       " 'blog',\n",
       " 'blogs',\n",
       " 'blue',\n",
       " 'bm',\n",
       " 'bm25',\n",
       " 'bm25f',\n",
       " 'board',\n",
       " 'body',\n",
       " 'boil',\n",
       " 'boils',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'books',\n",
       " 'bookstore',\n",
       " 'boolean',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'bottles',\n",
       " 'bottom',\n",
       " 'bottomup',\n",
       " 'bound',\n",
       " 'boundaries',\n",
       " 'boundary',\n",
       " 'bounded',\n",
       " 'bounds',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'bracket',\n",
       " 'brain',\n",
       " 'branching',\n",
       " 'brand',\n",
       " 'breadthfirst',\n",
       " 'breaking',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brisk',\n",
       " 'broad',\n",
       " 'broadly',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'browse',\n",
       " 'browser',\n",
       " 'browses',\n",
       " 'browsing',\n",
       " 'bs',\n",
       " 'btree',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'burden',\n",
       " 'buried',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'bye',\n",
       " 'bypass',\n",
       " 'byproduct',\n",
       " 'c',\n",
       " 'c0',\n",
       " 'c1',\n",
       " 'cabled',\n",
       " 'cache',\n",
       " 'caching',\n",
       " 'calculate',\n",
       " 'calculated',\n",
       " 'calculating',\n",
       " 'calculation',\n",
       " 'calculus',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'campaign',\n",
       " 'campaigns',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'cant',\n",
       " 'capabilities',\n",
       " 'capability',\n",
       " 'capacities',\n",
       " 'capture',\n",
       " 'captured',\n",
       " 'captures',\n",
       " 'capturing',\n",
       " 'car',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cares',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'casuality',\n",
       " 'cat',\n",
       " 'categoration',\n",
       " 'categorical',\n",
       " 'categories',\n",
       " 'categorization',\n",
       " 'categorizations',\n",
       " 'categorize',\n",
       " 'categorized',\n",
       " 'categorizer',\n",
       " 'categorizing',\n",
       " 'category',\n",
       " 'causal',\n",
       " 'causality',\n",
       " 'causally',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causes',\n",
       " 'causing',\n",
       " 'cell',\n",
       " 'cellphone',\n",
       " 'cells',\n",
       " 'cement',\n",
       " 'cementric',\n",
       " 'census',\n",
       " 'center',\n",
       " 'centers',\n",
       " 'centralized',\n",
       " 'centroid',\n",
       " 'centroids',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'cetera',\n",
       " 'cgi',\n",
       " 'chain',\n",
       " 'chains',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'channels',\n",
       " 'chapter',\n",
       " 'chapters',\n",
       " 'character',\n",
       " 'characterised',\n",
       " 'characteristics',\n",
       " 'characterization',\n",
       " 'characterize',\n",
       " 'characterized',\n",
       " 'characterizes',\n",
       " 'characterizing',\n",
       " 'characters',\n",
       " 'charged',\n",
       " 'charted',\n",
       " 'chased',\n",
       " 'chasing',\n",
       " 'chasings',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheng',\n",
       " 'chengxiang',\n",
       " 'chicago',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chips',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'chooses',\n",
       " 'choosing',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'chunk',\n",
       " 'chunks',\n",
       " 'ci',\n",
       " 'circle',\n",
       " 'circles',\n",
       " 'citation',\n",
       " 'citations',\n",
       " 'cite',\n",
       " 'cited',\n",
       " 'cities',\n",
       " 'citing',\n",
       " 'city',\n",
       " 'ciwd',\n",
       " 'ck',\n",
       " 'claim',\n",
       " 'claritative',\n",
       " 'clashing',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'classification',\n",
       " 'classifications',\n",
       " 'classified',\n",
       " 'classifier',\n",
       " 'classifiers',\n",
       " 'classifies',\n",
       " 'classify',\n",
       " 'classifying',\n",
       " 'classroom',\n",
       " 'clatch',\n",
       " 'clauses',\n",
       " 'cleanliness',\n",
       " 'cleanness',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'click',\n",
       " 'clicked',\n",
       " 'clicking',\n",
       " 'clickthrough',\n",
       " 'clickthroughs',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'climbing',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closeness',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'clue',\n",
       " 'clues',\n",
       " 'cluster',\n",
       " 'clustered',\n",
       " 'clustering',\n",
       " 'clusters',\n",
       " 'clutch',\n",
       " 'cluttered',\n",
       " 'code',\n",
       " 'coded',\n",
       " 'coder',\n",
       " 'codes',\n",
       " 'coding',\n",
       " 'codings',\n",
       " 'coefficient',\n",
       " 'coefficients',\n",
       " 'coffee',\n",
       " 'coherence',\n",
       " 'coherent',\n",
       " 'coin',\n",
       " 'coins',\n",
       " 'cold',\n",
       " 'collaborate',\n",
       " 'collaborating',\n",
       " 'collaboration',\n",
       " 'collaborations',\n",
       " 'collaborative',\n",
       " 'collaboratively',\n",
       " 'collaborators',\n",
       " 'collated',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'collections',\n",
       " 'collective',\n",
       " 'collectively',\n",
       " 'collector',\n",
       " 'collocations',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'column',\n",
       " 'columns',\n",
       " 'com',\n",
       " 'combating',\n",
       " 'combination',\n",
       " 'combinations',\n",
       " 'combine',\n",
       " 'combined',\n",
       " 'combines',\n",
       " 'combining',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'command',\n",
       " 'commands',\n",
       " 'commend',\n",
       " 'comment',\n",
       " 'commented',\n",
       " 'comments',\n",
       " 'commercial',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'commutative',\n",
       " 'companies',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'comparability',\n",
       " 'comparable',\n",
       " 'comparative',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'comparisons',\n",
       " 'compensate',\n",
       " 'competing',\n",
       " 'competition',\n",
       " 'competitive',\n",
       " 'competitors',\n",
       " 'compiling',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completelink',\n",
       " 'completely',\n",
       " 'completeness',\n",
       " 'completes',\n",
       " 'completing',\n",
       " 'completion',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'complicated',\n",
       " 'complication',\n",
       " 'complimentary',\n",
       " 'component',\n",
       " 'components',\n",
       " 'compose',\n",
       " 'composer',\n",
       " 'compound',\n",
       " 'comprehensive',\n",
       " 'compress',\n",
       " 'compressed',\n",
       " 'compressing',\n",
       " 'compression',\n",
       " 'compromise',\n",
       " 'computation',\n",
       " 'computational',\n",
       " 'computationally',\n",
       " 'compute',\n",
       " 'computed',\n",
       " 'computer',\n",
       " 'computers',\n",
       " 'computes',\n",
       " 'computing',\n",
       " 'concatenate',\n",
       " 'concatenates',\n",
       " 'concentrated',\n",
       " 'concept',\n",
       " 'concepts',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concise',\n",
       " 'concisely',\n",
       " 'conclude',\n",
       " 'concludes',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'concrete',\n",
       " 'condition',\n",
       " 'conditional',\n",
       " 'conditioning',\n",
       " 'conditions',\n",
       " 'conference',\n",
       " 'conferences',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'confuses',\n",
       " 'confusion',\n",
       " 'conjugate',\n",
       " 'conjunctive',\n",
       " 'conjured',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connecticut',\n",
       " 'connecting',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'connects',\n",
       " 'cons',\n",
       " 'consequence',\n",
       " 'consequences',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'considers',\n",
       " 'consist',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'consists',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constrained',\n",
       " 'constraint',\n",
       " 'constraints',\n",
       " 'construct',\n",
       " 'constructed',\n",
       " 'construction',\n",
       " 'consume',\n",
       " 'consumed',\n",
       " 'consumer',\n",
       " 'consumers',\n",
       " 'consuming',\n",
       " 'contacts',\n",
       " 'contain',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'content',\n",
       " 'contentbased',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'contexts',\n",
       " 'contextsensitive',\n",
       " 'contextual',\n",
       " 'contextualized',\n",
       " 'contingency',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continuing',\n",
       " 'continuous',\n",
       " 'contradict',\n",
       " 'contradictory',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'contributed',\n",
       " 'contributes',\n",
       " 'contributing',\n",
       " 'contribution',\n",
       " 'contributions',\n",
       " 'control',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'controls',\n",
       " 'convenience',\n",
       " 'convenient',\n",
       " 'converge',\n",
       " 'convergence',\n",
       " 'converges',\n",
       " 'conversation',\n",
       " 'conversion',\n",
       " 'convert',\n",
       " 'converted',\n",
       " 'converting',\n",
       " 'convey',\n",
       " 'convince',\n",
       " 'cooccur',\n",
       " 'cooccurence',\n",
       " 'cooccurrences',\n",
       " 'cooccurrency',\n",
       " 'cooccurrent',\n",
       " 'cooccurring',\n",
       " 'copied',\n",
       " 'copy',\n",
       " 'copying',\n",
       " 'core',\n",
       " 'corpus',\n",
       " 'correct',\n",
       " 'corrected',\n",
       " 'correcting',\n",
       " 'correction',\n",
       " 'correctly',\n",
       " 'correlate',\n",
       " 'correlated',\n",
       " 'correlating',\n",
       " 'correlation',\n",
       " 'correlations',\n",
       " 'correspond',\n",
       " 'corresponding',\n",
       " 'corresponds',\n",
       " 'cosine',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'cough',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counted',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'countspull',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'coursera',\n",
       " 'courses',\n",
       " 'courtesy',\n",
       " 'covariance',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'coverages',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'covers',\n",
       " 'cplsa',\n",
       " 'cprsa',\n",
       " 'cpu',\n",
       " 'crack',\n",
       " 'cracked',\n",
       " 'cranfield',\n",
       " 'crash',\n",
       " 'crawl',\n",
       " 'crawler',\n",
       " 'crawling',\n",
       " 'crawls',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creates',\n",
       " 'creating',\n",
       " 'credit',\n",
       " 'criteria',\n",
       " 'criterion',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'croft',\n",
       " 'cross',\n",
       " 'crosscollection',\n",
       " 'crosses',\n",
       " 'crossing',\n",
       " 'crossvalidation',\n",
       " 'crucial',\n",
       " 'cruel',\n",
       " 'cs410',\n",
       " 'cs410dso',\n",
       " 'culture',\n",
       " 'cumulative',\n",
       " 'cures',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'curves',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'customization',\n",
       " 'customize',\n",
       " 'customized',\n",
       " 'customizing',\n",
       " 'cut',\n",
       " 'cutoff',\n",
       " 'cutoffs',\n",
       " 'cutting',\n",
       " 'd1',\n",
       " 'd1s',\n",
       " 'd2',\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set()\n",
    "for tokens in token_list:\n",
    "    vocab.update(tokens)\n",
    "vocab = sorted(list(vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4652\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1k',\n",
       " '32bit',\n",
       " '8bit',\n",
       " 'aa',\n",
       " 'aand',\n",
       " 'ab',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abort',\n",
       " 'abound',\n",
       " 'absenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'abstract',\n",
       " 'acceler',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accommod',\n",
       " 'accompani',\n",
       " 'accord',\n",
       " 'accordingli',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'achiev',\n",
       " 'acl',\n",
       " 'acoust',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adequ',\n",
       " 'adjac',\n",
       " 'adject',\n",
       " 'adjust',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'affect',\n",
       " 'affili',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'agglom',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airlin',\n",
       " 'airport',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'algebra',\n",
       " 'algorithm',\n",
       " 'align',\n",
       " 'allevi',\n",
       " 'allianc',\n",
       " 'alloc',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alpha',\n",
       " 'alreadi',\n",
       " 'also',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'altogeth',\n",
       " 'alway',\n",
       " 'ama',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'ambigu',\n",
       " 'american',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'analog',\n",
       " 'analys',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'analyt',\n",
       " 'analyz',\n",
       " 'anaphora',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'andor',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'anim',\n",
       " 'annot',\n",
       " 'annual',\n",
       " 'anom',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'anticip',\n",
       " 'antithesi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'apolog',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'applet',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'applicationspecif',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'appris',\n",
       " 'approac',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approxim',\n",
       " 'arbitrari',\n",
       " 'arbitrarili',\n",
       " 'architectur',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'arg',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'arithmat',\n",
       " 'arithmet',\n",
       " 'around',\n",
       " 'arrang',\n",
       " 'array',\n",
       " 'arriv',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'artifici',\n",
       " 'ascend',\n",
       " 'ascii',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'aspectlevel',\n",
       " 'aspectspecif',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'assess',\n",
       " 'assessor',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'associativearray',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'ate',\n",
       " 'atom',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attent',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'augment',\n",
       " 'author',\n",
       " 'automat',\n",
       " 'automobil',\n",
       " 'avail',\n",
       " 'averag',\n",
       " 'averagelink',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awkward',\n",
       " 'axi',\n",
       " 'axiomat',\n",
       " 'b',\n",
       " 'b1',\n",
       " 'back',\n",
       " 'backbon',\n",
       " 'background',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bagofword',\n",
       " 'balanc',\n",
       " 'band',\n",
       " 'bar',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'baselin',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basketbal',\n",
       " 'batch',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bay',\n",
       " 'bayesian',\n",
       " 'becom',\n",
       " 'begin',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'belong',\n",
       " 'bend',\n",
       " 'benefici',\n",
       " 'benefit',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bestperform',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betagamma',\n",
       " 'better',\n",
       " 'beverag',\n",
       " 'beyond',\n",
       " 'bia',\n",
       " 'bias',\n",
       " 'bibliograph',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigram',\n",
       " 'bill',\n",
       " 'binari',\n",
       " 'bind',\n",
       " 'bing',\n",
       " 'biologist',\n",
       " 'biomed',\n",
       " 'biproduct',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'blind',\n",
       " 'blindli',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blue',\n",
       " 'bm',\n",
       " 'bm25',\n",
       " 'bm25f',\n",
       " 'board',\n",
       " 'bodi',\n",
       " 'boil',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'bookstor',\n",
       " 'boolean',\n",
       " 'bore',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bottomup',\n",
       " 'bound',\n",
       " 'boundari',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'bracket',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'breadthfirst',\n",
       " 'break',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'bring',\n",
       " 'brisk',\n",
       " 'broad',\n",
       " 'broadli',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'bs',\n",
       " 'btree',\n",
       " 'build',\n",
       " 'built',\n",
       " 'burden',\n",
       " 'buri',\n",
       " 'busi',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'bye',\n",
       " 'bypass',\n",
       " 'byproduct',\n",
       " 'c',\n",
       " 'c0',\n",
       " 'c1',\n",
       " 'cabl',\n",
       " 'cach',\n",
       " 'calcul',\n",
       " 'calculu',\n",
       " 'call',\n",
       " 'came',\n",
       " 'campaign',\n",
       " 'candid',\n",
       " 'cant',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'care',\n",
       " 'carri',\n",
       " 'case',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'categor',\n",
       " 'categori',\n",
       " 'caus',\n",
       " 'causal',\n",
       " 'cell',\n",
       " 'cellphon',\n",
       " 'cement',\n",
       " 'cementr',\n",
       " 'censu',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centroid',\n",
       " 'certain',\n",
       " 'certainli',\n",
       " 'cetera',\n",
       " 'cgi',\n",
       " 'chain',\n",
       " 'challeng',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'charact',\n",
       " 'character',\n",
       " 'characteris',\n",
       " 'characterist',\n",
       " 'charg',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'cheng',\n",
       " 'chengxiang',\n",
       " 'chicago',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'choic',\n",
       " 'choos',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chri',\n",
       " 'chunk',\n",
       " 'ci',\n",
       " 'circl',\n",
       " 'citat',\n",
       " 'cite',\n",
       " 'citi',\n",
       " 'ciwd',\n",
       " 'ck',\n",
       " 'claim',\n",
       " 'clarit',\n",
       " 'clash',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classif',\n",
       " 'classifi',\n",
       " 'classroom',\n",
       " 'clatch',\n",
       " 'claus',\n",
       " 'clean',\n",
       " 'cleanli',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearli',\n",
       " 'click',\n",
       " 'clickthrough',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'clue',\n",
       " 'cluster',\n",
       " 'clutch',\n",
       " 'clutter',\n",
       " 'code',\n",
       " 'coder',\n",
       " 'coeffici',\n",
       " 'coffe',\n",
       " 'coher',\n",
       " 'coin',\n",
       " 'cold',\n",
       " 'collabor',\n",
       " 'collat',\n",
       " 'collect',\n",
       " 'collector',\n",
       " 'colloc',\n",
       " 'color',\n",
       " 'column',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comfort',\n",
       " 'command',\n",
       " 'commend',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'committe',\n",
       " 'common',\n",
       " 'commonli',\n",
       " 'commun',\n",
       " 'commut',\n",
       " 'compani',\n",
       " 'companion',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compens',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'competitor',\n",
       " 'compil',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'completelink',\n",
       " 'complex',\n",
       " 'complic',\n",
       " 'complimentari',\n",
       " 'compon',\n",
       " 'compos',\n",
       " 'compound',\n",
       " 'comprehens',\n",
       " 'compress',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'con',\n",
       " 'concaten',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concis',\n",
       " 'conclud',\n",
       " 'conclus',\n",
       " 'concret',\n",
       " 'condit',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'confus',\n",
       " 'conjug',\n",
       " 'conjunct',\n",
       " 'conjur',\n",
       " 'connect',\n",
       " 'connecticut',\n",
       " 'consequ',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'constant',\n",
       " 'constantli',\n",
       " 'constrain',\n",
       " 'constraint',\n",
       " 'construct',\n",
       " 'consum',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'content',\n",
       " 'contentbas',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'contextsensit',\n",
       " 'contextu',\n",
       " 'conting',\n",
       " 'continu',\n",
       " 'contradict',\n",
       " 'contradictori',\n",
       " 'contrast',\n",
       " 'contribut',\n",
       " 'control',\n",
       " 'conveni',\n",
       " 'converg',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convey',\n",
       " 'convinc',\n",
       " 'cooccur',\n",
       " 'cooccurr',\n",
       " 'copi',\n",
       " 'core',\n",
       " 'corpu',\n",
       " 'correct',\n",
       " 'correctli',\n",
       " 'correl',\n",
       " 'correspond',\n",
       " 'cosin',\n",
       " 'cost',\n",
       " 'cough',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'countri',\n",
       " 'countspul',\n",
       " 'coupl',\n",
       " 'cours',\n",
       " 'coursera',\n",
       " 'courtesi',\n",
       " 'covari',\n",
       " 'cover',\n",
       " 'coverag',\n",
       " 'cplsa',\n",
       " 'cprsa',\n",
       " 'cpu',\n",
       " 'crack',\n",
       " 'cranfield',\n",
       " 'crash',\n",
       " 'crawl',\n",
       " 'crawler',\n",
       " 'creat',\n",
       " 'credit',\n",
       " 'criteria',\n",
       " 'criterion',\n",
       " 'critic',\n",
       " 'croft',\n",
       " 'cross',\n",
       " 'crosscollect',\n",
       " 'crossvalid',\n",
       " 'crucial',\n",
       " 'cruel',\n",
       " 'cs410',\n",
       " 'cs410dso',\n",
       " 'cultur',\n",
       " 'cumul',\n",
       " 'cure',\n",
       " 'current',\n",
       " 'curv',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cutoff',\n",
       " 'd1',\n",
       " 'd2',\n",
       " 'd3',\n",
       " 'd4',\n",
       " 'd5',\n",
       " 'd6',\n",
       " 'd8',\n",
       " 'damag',\n",
       " 'damp',\n",
       " 'data',\n",
       " 'databas',\n",
       " 'datadriven',\n",
       " 'datapoint',\n",
       " 'dataset',\n",
       " 'datauserservic',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dblp',\n",
       " 'dcg',\n",
       " 'deadlin',\n",
       " 'deal',\n",
       " 'debat',\n",
       " 'decad',\n",
       " 'decemb',\n",
       " 'decid',\n",
       " 'deciph',\n",
       " 'decis',\n",
       " 'decisionmak',\n",
       " 'decod',\n",
       " 'decompos',\n",
       " 'decomposit',\n",
       " 'decreas',\n",
       " 'dedic',\n",
       " 'deduct',\n",
       " 'deem',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'default',\n",
       " 'defici',\n",
       " 'defin',\n",
       " 'definit',\n",
       " 'degener',\n",
       " 'degre',\n",
       " 'delet',\n",
       " 'deliv',\n",
       " 'deliver',\n",
       " 'deliveri',\n",
       " 'delta',\n",
       " 'demand',\n",
       " 'denomin',\n",
       " 'denomina',\n",
       " 'denot',\n",
       " 'depend',\n",
       " 'depict',\n",
       " 'deposit',\n",
       " 'depth',\n",
       " 'deriv',\n",
       " 'descend',\n",
       " 'describ',\n",
       " 'descript',\n",
       " 'design',\n",
       " 'desir',\n",
       " 'desk',\n",
       " 'despit',\n",
       " 'detail',\n",
       " 'detect',\n",
       " 'determin',\n",
       " 'determinist',\n",
       " 'detour',\n",
       " 'develop',\n",
       " 'deviat',\n",
       " 'devic',\n",
       " 'devot',\n",
       " 'df',\n",
       " 'dgap',\n",
       " 'di',\n",
       " 'diagnos',\n",
       " 'diagram',\n",
       " 'diamond',\n",
       " 'dictat',\n",
       " 'dictionari',\n",
       " 'didnt',\n",
       " 'differ',\n",
       " 'differenti',\n",
       " 'difficult',\n",
       " 'difficulti',\n",
       " 'difficultli',\n",
       " 'digest',\n",
       " 'digit',\n",
       " 'dilemma',\n",
       " 'dim',\n",
       " 'dimens',\n",
       " 'dimension',\n",
       " 'diminish',\n",
       " 'dimmer',\n",
       " 'diplomaci',\n",
       " 'direct',\n",
       " 'directli',\n",
       " 'director',\n",
       " 'directori',\n",
       " 'dirichlet',\n",
       " 'disadvantag',\n",
       " 'disambigu',\n",
       " 'disappear',\n",
       " 'disast',\n",
       " 'disc',\n",
       " 'discard',\n",
       " 'discount',\n",
       " 'discourag',\n",
       " 'discours',\n",
       " 'discov',\n",
       " 'discoveri',\n",
       " 'discret',\n",
       " 'discrimin',\n",
       " 'discuss',\n",
       " 'disgust',\n",
       " 'disintegr',\n",
       " 'disjoint',\n",
       " 'disjunct',\n",
       " 'disk',\n",
       " 'dislik',\n",
       " 'dispatch',\n",
       " 'display',\n",
       " 'dispos',\n",
       " 'dissert',\n",
       " 'distanc',\n",
       " 'distinct',\n",
       " 'distinguish',\n",
       " 'distract',\n",
       " 'distribut',\n",
       " 'diverg',\n",
       " 'divers',\n",
       " 'diversifi',\n",
       " 'divid',\n",
       " 'divis',\n",
       " 'dj',\n",
       " 'dm',\n",
       " 'dn',\n",
       " 'doc',\n",
       " 'dock',\n",
       " 'document',\n",
       " 'documentid',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dollar',\n",
       " 'domain',\n",
       " 'domainspecif',\n",
       " 'domin',\n",
       " 'donat',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'dot',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'dow',\n",
       " 'downsid',\n",
       " 'downweight',\n",
       " 'draw',\n",
       " 'drawn',\n",
       " 'drift',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'drop',\n",
       " 'dso',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'duplic',\n",
       " 'durat',\n",
       " 'dynam',\n",
       " 'e',\n",
       " 'e1',\n",
       " 'e2',\n",
       " 'earli',\n",
       " 'earlier',\n",
       " 'earn',\n",
       " 'easi',\n",
       " 'easier',\n",
       " 'easili',\n",
       " 'eat',\n",
       " 'ect',\n",
       " 'edg',\n",
       " 'edit',\n",
       " 'editor',\n",
       " 'educ',\n",
       " 'effect',\n",
       " 'effici',\n",
       " 'effort',\n",
       " 'eigenvalu',\n",
       " 'eigenvector',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'elect',\n",
       " 'electron',\n",
       " 'eleg',\n",
       " 'elegantli',\n",
       " 'element',\n",
       " 'elimin',\n",
       " 'els',\n",
       " 'em',\n",
       " 'email',\n",
       " 'emb',\n",
       " 'embed',\n",
       " 'emot',\n",
       " 'emphas',\n",
       " 'emphasi',\n",
       " 'empir',\n",
       " 'employe',\n",
       " 'enabl',\n",
       " 'enact',\n",
       " 'encod',\n",
       " 'encount',\n",
       " 'encourag',\n",
       " 'end',\n",
       " 'energi',\n",
       " 'engag',\n",
       " 'engin',\n",
       " 'england',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enlarg',\n",
       " 'enough',\n",
       " 'enrich',\n",
       " 'ensur',\n",
       " 'enter',\n",
       " 'enterpris',\n",
       " 'entir',\n",
       " 'entiti',\n",
       " 'entityrel',\n",
       " 'entri',\n",
       " 'entrophi',\n",
       " 'entropi',\n",
       " 'enumer',\n",
       " 'environ',\n",
       " 'envis',\n",
       " 'eowc',\n",
       " 'equal',\n",
       " 'equat',\n",
       " 'equival',\n",
       " 'era',\n",
       " 'error',\n",
       " 'especi',\n",
       " 'essenc',\n",
       " 'essenti',\n",
       " 'establish',\n",
       " 'estep',\n",
       " 'estim',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'etcetera',\n",
       " 'euclidean',\n",
       " 'evalu',\n",
       " 'even',\n",
       " 'event',\n",
       " 'eventu',\n",
       " 'ever',\n",
       " 'everi',\n",
       " 'everyday',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'everywher',\n",
       " 'evid',\n",
       " 'evok',\n",
       " 'exact',\n",
       " 'exactli',\n",
       " 'exam',\n",
       " 'examin',\n",
       " 'exampl',\n",
       " 'exceed',\n",
       " 'excel',\n",
       " 'except',\n",
       " 'exchang',\n",
       " 'exclud',\n",
       " 'exclus',\n",
       " 'excus',\n",
       " 'execut',\n",
       " 'exemplari',\n",
       " 'exercis',\n",
       " 'exhaust',\n",
       " 'exist',\n",
       " 'expand',\n",
       " 'expans',\n",
       " 'expect',\n",
       " 'expectationmaxim',\n",
       " 'expens',\n",
       " 'experi',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explan',\n",
       " 'explicit',\n",
       " 'explicitli',\n",
       " 'exploit',\n",
       " 'explor',\n",
       " 'explorationexploit',\n",
       " 'exploratori',\n",
       " 'expos',\n",
       " 'express',\n",
       " 'expressli',\n",
       " 'extend',\n",
       " 'extens',\n",
       " 'extent',\n",
       " 'extern',\n",
       " 'extra',\n",
       " 'extract',\n",
       " 'extran',\n",
       " 'extrem',\n",
       " 'f',\n",
       " 'f1',\n",
       " 'fa',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'facilit',\n",
       " 'fact',\n",
       " 'faction',\n",
       " 'factor',\n",
       " 'factual',\n",
       " 'fade',\n",
       " 'fair',\n",
       " 'fairli',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'fals',\n",
       " 'famili',\n",
       " 'familiar',\n",
       " 'familiarli',\n",
       " 'fan',\n",
       " 'far',\n",
       " 'farthest',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fastest',\n",
       " 'fault',\n",
       " 'favor',\n",
       " 'fear',\n",
       " 'feasibl',\n",
       " 'featur',\n",
       " 'fed',\n",
       " 'feed',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'fetch',\n",
       " 'fewer',\n",
       " 'fi',\n",
       " 'field',\n",
       " 'fifth',\n",
       " 'figur',\n",
       " 'file',\n",
       " 'fill',\n",
       " 'filter',\n",
       " 'final',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'first',\n",
       " 'firstli',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'fixedlength',\n",
       " 'flat',\n",
       " 'flavor',\n",
       " 'flexibl',\n",
       " 'flight',\n",
       " 'flip',\n",
       " 'flood',\n",
       " 'floor',\n",
       " 'flow',\n",
       " 'fluctuat',\n",
       " 'fmeasur',\n",
       " 'fn',\n",
       " 'focu',\n",
       " 'focus',\n",
       " 'folder',\n",
       " 'follow',\n",
       " 'font',\n",
       " 'food',\n",
       " 'footbal',\n",
       " 'forc',\n",
       " 'fore',\n",
       " 'foreign',\n",
       " 'form',\n",
       " 'formal',\n",
       " 'format',\n",
       " 'former',\n",
       " 'formerli',\n",
       " 'formul',\n",
       " 'formula',\n",
       " 'forth',\n",
       " 'fortun',\n",
       " 'foru',\n",
       " 'forum',\n",
       " 'forumbas',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'foundat',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'fp',\n",
       " 'fraction',\n",
       " 'fragil',\n",
       " 'frame',\n",
       " 'framework',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'frequenc',\n",
       " 'frequent',\n",
       " 'fresh',\n",
       " 'friend',\n",
       " 'friendship',\n",
       " 'front',\n",
       " 'frontier',\n",
       " 'fulfil',\n",
       " 'full',\n",
       " 'fullfledg',\n",
       " 'fulli',\n",
       " 'fun',\n",
       " 'function',\n",
       " 'fundament',\n",
       " 'furthermor',\n",
       " 'futur',\n",
       " 'fuzzi',\n",
       " 'fw',\n",
       " 'g',\n",
       " 'g1',\n",
       " 'g2',\n",
       " 'gain',\n",
       " 'gambl',\n",
       " 'game',\n",
       " 'gamma',\n",
       " 'gap',\n",
       " ...]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "vocab_stemmed = sorted(list(set(stemmer.stem(word) for word in vocab)))\n",
    "vocab_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_stemmed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tis-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85a5c2dc979ec021335ff2758cc7fbdc3d2baa50f6cf88c303f22e6e76e98821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
